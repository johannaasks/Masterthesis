{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPLEX IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cplex\n",
    "from cplex import Cplex\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define fixed sets: Time periods and Road widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_fixed_sets():\n",
    "    \"\"\"\n",
    "    Defines and returns fixed sets for time periods and road widths.\n",
    "\n",
    "    Returns:\n",
    "    - T: tuple of time periods\n",
    "    - W: tuple of road widths\n",
    "    \"\"\"\n",
    "    T = tuple([1, 2, 3, 4, 5])  # 5 time periods\n",
    "    W = tuple(['timber', 'wide'])  # Road widths\n",
    "    return T, W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to get component-dependent sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚óè Load nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nodes(component_dir, filename=\"4withsources_nodes.csv\"):\n",
    "    \"\"\"\n",
    "    Load nodes from CSV and return source nodes, exit nodes, and all node coordinates.\n",
    "\n",
    "    Parameters:\n",
    "        component_dir (str): Directory containing the nodes CSV.\n",
    "        filename (str): Name of the nodes CSV file (default: '4withsources_nodes.csv').\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            V_source (DataFrame): Subset of nodes_df where is_source == True\n",
    "            V_exit (DataFrame): Subset of nodes_df where is_exit == True\n",
    "            V (list): List of (x, y) tuples for all nodes\n",
    "            nodes_df (DataFrame): Full nodes dataframe\n",
    "    \"\"\"\n",
    "    file_path = f\"{component_dir}\\\\{filename}\"\n",
    "    nodes_df = pd.read_csv(file_path)\n",
    "\n",
    "    # filter nodes\n",
    "    V_source = nodes_df[nodes_df[\"is_source\"] == True]\n",
    "    V_exit = nodes_df[nodes_df[\"is_exit\"] == True]\n",
    "\n",
    "    # all node coordinates\n",
    "    V = list(zip(nodes_df[\"x\"], nodes_df[\"y\"]))\n",
    "\n",
    "    return V_source, V_exit, V, nodes_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map nodes to ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_node_mappings(V, V_source, V_exit):\n",
    "    \"\"\"\n",
    "    Build node ID mappings and extract node IDs for source and exit nodes.\n",
    "\n",
    "    Parameters:\n",
    "        V (list): List of (x, y) coordinates for all nodes.\n",
    "        V_source (DataFrame): Source nodes (must have 'x' and 'y').\n",
    "        V_exit (DataFrame): Exit nodes (must have 'x' and 'y').\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            node_ID_mapping (dict): Mapping {'nodeX': (x, y)}.\n",
    "            reversed_node_ID_mapping (dict): Mapping {(x, y): 'nodeX'}.\n",
    "            V_nodeIDs (list): List of node IDs for all nodes.\n",
    "            V_source_nIDs (list): List of node IDs for source nodes.\n",
    "            V_exit_nIDs (list): List of node IDs for exit nodes.\n",
    "    \"\"\"\n",
    "    # forward mapping: node name ‚Üí coordinates\n",
    "    node_ID_mapping = {f\"node{i + 1}\": V[i] for i in range(len(V))}\n",
    "\n",
    "    # reverse mapping: coordinates ‚Üí node name\n",
    "    reversed_node_ID_mapping = {v: k for k, v in node_ID_mapping.items()}\n",
    "\n",
    "    # all node IDs\n",
    "    V_nodeIDs = [reversed_node_ID_mapping[v] for v in V]\n",
    "\n",
    "    # source and exit node IDs\n",
    "    V_source_nIDs = [reversed_node_ID_mapping[v] for v in zip(V_source[\"x\"], V_source[\"y\"])]\n",
    "    V_exit_nIDs = [reversed_node_ID_mapping[v] for v in zip(V_exit[\"x\"], V_exit[\"y\"])]\n",
    "\n",
    "    return node_ID_mapping, reversed_node_ID_mapping, V_nodeIDs, V_source_nIDs, V_exit_nIDs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transit nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transit_nodes(V_nodeIDs, V_source_nIDs, V_exit_nIDs):\n",
    "    \"\"\"\n",
    "    Compute the set of transit nodes (neither source nor exit).\n",
    "\n",
    "    Parameters:\n",
    "        V_nodeIDs (iterable): All node IDs in the graph.\n",
    "        V_source_dict (dict): Mapping {stand_id: node_id} for source nodes.\n",
    "        V_exit (iterable): Collection of exit node IDs.\n",
    "\n",
    "    Returns:\n",
    "        set: The set of transit node IDs.\n",
    "    \"\"\"\n",
    "    V_transit = set(V_nodeIDs) - set(V_source_nIDs) - set(V_exit_nIDs)\n",
    "\n",
    "    # Debug: print counts for verification\n",
    "    print(\"Total nodes:\", len(V_nodeIDs))\n",
    "    print(\"Transit nodes:\", len(V_transit))\n",
    "    print(\"Source nodes:\", len(V_source_nIDs))\n",
    "    print(\"Exit nodes:\", len(V_exit_nIDs))\n",
    "    return V_transit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arcs & Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_verify_arcs(component_dir):\n",
    "    # Load the arcs from the CSV files\n",
    "    arcs_fw_df = pd.read_csv(f'{component_dir}/arcsforward.csv', header=0)\n",
    "    arcs_bw_df = pd.read_csv(f'{component_dir}/arcsbackward.csv', header=0)\n",
    "    arcs_df = pd.read_csv(f'{component_dir}/arcs.csv', header=0)\n",
    "    edge_attr_df = pd.read_csv(f'{component_dir}/arcs_with_attributes.csv', header=0)\n",
    "\n",
    "    # Assign the data to the respective variable\n",
    "    A = arcs_df.values\n",
    "\n",
    "    # Print lengths\n",
    "    print(f\"Total arcs: {len(A)}, Forward arcs: {len(arcs_fw_df)}, Backward arcs: {len(arcs_bw_df)}\")\n",
    "\n",
    "    # Check if number of forward arcs equals number of backward arcs\n",
    "    if len(arcs_fw_df) != len(arcs_bw_df):\n",
    "        print(\"Warning: Number of forward arcs is NOT equal to number of backward arcs!\")\n",
    "\n",
    "    # Check if forward arcs are the reverse of backward arcs\n",
    "    fw_arcs = arcs_fw_df.values\n",
    "    bw_arcs = arcs_bw_df.values\n",
    "\n",
    "    if len(fw_arcs) == len(bw_arcs):\n",
    "        reversed_bw = np.flip(bw_arcs, axis=1)  # Reverse each arc [to, from] -> [from, to]\n",
    "        if np.array_equal(fw_arcs, reversed_bw):\n",
    "            print(\"‚úÖ Forward arcs are the reverse of backward arcs.\")\n",
    "        else:\n",
    "            print(\"‚ùå Forward arcs are NOT the reverse of backward arcs.\")\n",
    "    else:\n",
    "        print(\"Cannot check reverse relationship due to different lengths.\")\n",
    "\n",
    "    return A, arcs_fw_df, arcs_bw_df, edge_attr_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use nodes IDs in arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map coordinates to short names\n",
    "def map_coordinates_to_nodeIDs(coords):\n",
    "    try:\n",
    "        coords_tuple = tuple(map(float, coords.strip('()').split(', ')))\n",
    "    except:\n",
    "        return None  # handle invalid format\n",
    "    for nodeID, node_coords in node_ID_mapping.items():\n",
    "        if coords_tuple == node_coords:\n",
    "            return nodeID\n",
    "    return None  # Return None if the coordinates are not found\n",
    "\n",
    "def replace_coord_with_IDs(A, arcs_fw, arcs_bw):\n",
    "    # Replace coordinates with their short names\n",
    "    A = [[map_coordinates_to_nodeIDs(pair[0]), map_coordinates_to_nodeIDs(pair[1])] for pair in A]\n",
    "    A_fw = [[map_coordinates_to_nodeIDs(pair[0]), map_coordinates_to_nodeIDs(pair[1])] \n",
    "            for pair in arcs_fw.values]\n",
    "    A_bw = [[map_coordinates_to_nodeIDs(pair[0]), map_coordinates_to_nodeIDs(pair[1])] \n",
    "            for pair in arcs_bw.values]\n",
    "    return A, A_fw, A_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_edge_pairs(A, A_fw, A_bw, verify=True):\n",
    "    \"\"\"\n",
    "    Convert edge pairs into string tuples and verify forward/backward split.\n",
    "\n",
    "    Parameters:\n",
    "        A (iterable): Original collection of edge pairs (tuples/lists of chars/strings).\n",
    "        A_fw (iterable): Forward edge pairs.\n",
    "        A_bw (iterable): Backward edge pairs.\n",
    "        verify (bool): If True, checks that A == A_fw ‚à™ A_bw.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with transformed tuples and verification result.\n",
    "    \"\"\"\n",
    "    # Convert each set of pairs into tuple of concatenated strings\n",
    "    A = tuple(\"\".join(pair) for pair in A)\n",
    "    A_fw = tuple(\"\".join(pair) for pair in A_fw)\n",
    "    A_bw = tuple(\"\".join(pair) for pair in A_bw)\n",
    "    E = A_fw  # alias for forward edges\n",
    "\n",
    "    result = {\n",
    "        \"A\": A,\n",
    "        \"A_fw\": A_fw,\n",
    "        \"A_bw\": A_bw,\n",
    "        \"E\": E,\n",
    "        \"sample_fw\": A_fw[1] if len(A_fw) > 1 else None,\n",
    "    }\n",
    "\n",
    "    # Optional verification\n",
    "    if verify:\n",
    "        result[\"verified\"] = (set(A) == set(A_fw) | set(A_bw))\n",
    "\n",
    "    return A, A_fw, A_bw, E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [helper functions] swap halves and split edge into nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to swap halves\n",
    "def swap_direction(arc):\n",
    "    \"\"\"\n",
    "    Swap direction of an arc.\n",
    "    If arc is a tuple/list (u, v), return (v, u).\n",
    "    If arc is a string like 'node1node2', split it.\n",
    "    \"\"\"\n",
    "    if isinstance(arc, (tuple, list)) and len(arc) == 2:\n",
    "        return (arc[1], arc[0])\n",
    "    elif isinstance(arc, str):\n",
    "        mid = arc.find('node', 4)  \n",
    "        return arc[mid:] + arc[:mid] \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported arc format: {arc}\")\n",
    "\n",
    "def split_edge_to_nodes(edge):\n",
    "    if isinstance(edge, str):\n",
    "        mid = edge.find('node', 4)  # guaranteed to exist\n",
    "        return [edge[:mid], edge[mid:]]\n",
    "    else:\n",
    "        raise TypeError(\"Input must be a string.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_forward_backward_mapping(A_fw, A_bw, swap_direction):\n",
    "    \"\"\"\n",
    "    Creates a mapping between forward arcs and backward arcs using a swap function.\n",
    "\n",
    "    Parameters:\n",
    "    - A_fw: iterable of forward arcs\n",
    "    - A_bw: iterable of backward arcs\n",
    "    - swap_direction: function that takes an arc and returns its swapped version\n",
    "\n",
    "    Returns:\n",
    "    - fw_to_bw_map: dict mapping forward arcs to backward arcs\n",
    "    - bw_to_fw_map: dict mapping backward arcs to forward arcs\n",
    "    \"\"\"\n",
    "    fw_to_bw_map = {}\n",
    "    for arc in A_fw:\n",
    "        swapped = swap_direction(arc)\n",
    "        if swapped in A_bw:\n",
    "            fw_to_bw_map[arc] = swapped\n",
    "\n",
    "    bw_to_fw_map = {v: k for k, v in fw_to_bw_map.items()}\n",
    "    return fw_to_bw_map, bw_to_fw_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dict to map StandID: SourceNodeID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_source_dict(source_nodes, reversed_node_ID_mapping):\n",
    "    \"\"\"\n",
    "    Build a dictionary mapping stands -> node IDs using source node coordinates.\n",
    "\n",
    "    Parameters:\n",
    "        source_nodes (pd.DataFrame): DataFrame with at least 'stands', 'x', 'y' columns.\n",
    "        reversed_node_ID_mapping (dict): Mapping from (x, y) -> node ID.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            V_source_dict (dict): Mapping {stand_id: node_id}.\n",
    "            S (set): Set of stand IDs.\n",
    "    \"\"\"\n",
    "    # Initial mapping: stand -> (x, y)\n",
    "    V_source_dict = {\n",
    "        int(row['stands']): (row['x'], row['y'])\n",
    "        for _, row in source_nodes.iterrows()\n",
    "    }\n",
    "\n",
    "    # Replace coordinates with node IDs\n",
    "    for key, node in V_source_dict.items():\n",
    "        V_source_dict[key] = reversed_node_ID_mapping[node]\n",
    "\n",
    "    # Define S = stands in V_source\n",
    "    S = set(V_source_dict.keys())\n",
    "\n",
    "    return V_source_dict, S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source_arcs(A, V_source_dict):\n",
    "    \"\"\"\n",
    "    Collect arcs that go into source nodes and out of them.\n",
    "\n",
    "    Parameters:\n",
    "        A (iterable): List of arcs, each as a list [u, v] or tuple (u, v).\n",
    "        V_source_dict (dict): Mapping {stand_id: node_id}.\n",
    "\n",
    "    Returns:\n",
    "        dict: {stand_id: set of arcs (ingoing to source)}\n",
    "        dict: same as above for outgoing\n",
    "    \"\"\"\n",
    "    source_arcs_ingoing = {}\n",
    "    source_arcs_outgoing = {}\n",
    "\n",
    "    for standID, sourcenode in V_source_dict.items():\n",
    "        ingoing = set()\n",
    "        outgoing = set()\n",
    "        for arc in A:\n",
    "            u, v = split_edge_to_nodes(arc)  # unpack list or tuple\n",
    "            if v == sourcenode:   # incoming arc if target matches source node\n",
    "                ingoing.add(arc)\n",
    "            elif u == sourcenode:   # outgoing arc if source matches\n",
    "                outgoing.add(arc)\n",
    "        source_arcs_ingoing[standID] = ingoing\n",
    "        source_arcs_outgoing[standID] = outgoing\n",
    "\n",
    "    total_in_arcs = sum(len(v) for v in source_arcs_ingoing.values())\n",
    "    print(total_in_arcs, \"ingoing to source nodes in total\")\n",
    "\n",
    "    total_out_arcs = sum(len(v) for v in source_arcs_outgoing.values())\n",
    "    print(total_out_arcs, \"outgoing from source nodes in total\")\n",
    "\n",
    "    return source_arcs_ingoing, source_arcs_outgoing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exit arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_exit_arcs(V_exit_nodeIDs, A):\n",
    "    \"\"\"\n",
    "    Build dictionaries of outgoing and ingoing arcs for each exit node.\n",
    "    \"\"\"\n",
    "    exit_arcs_ingoing = {}\n",
    "    exit_arcs_outgoing = {}\n",
    "\n",
    "    for exitnode in V_exit_nodeIDs:\n",
    "        ingoing = set()\n",
    "        outgoing = set()\n",
    "        for arc in A:\n",
    "            u, v = split_edge_to_nodes(arc)  # unpack arc from string\n",
    "            if u == exitnode:\n",
    "                outgoing.add(arc)\n",
    "            if v == exitnode:\n",
    "                ingoing.add(arc)\n",
    "        # assign sets to dictionaries\n",
    "        exit_arcs_ingoing[exitnode] = ingoing\n",
    "        exit_arcs_outgoing[exitnode] = outgoing\n",
    "\n",
    "    total_in_arcs = sum(len(v) for v in exit_arcs_ingoing.values())\n",
    "    total_out_arcs = sum(len(v) for v in exit_arcs_outgoing.values())\n",
    "    return exit_arcs_ingoing, total_in_arcs, exit_arcs_outgoing, total_out_arcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transit arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transitnode_arcs(V_transit, A):\n",
    "    \"\"\"\n",
    "    Build ingoing/outgoing arc dictionaries for transit nodes,\n",
    "    where arcs are strings like 'node1node245'.\n",
    "    \n",
    "    Parameters:\n",
    "        V_transit (iterable): Transit node IDs, e.g., ['node5', 'node8', ...]\n",
    "        A (iterable): Arcs as strings, e.g., 'node1node245'\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (ingoing_per_transitnode, outgoing_per_transitnode, total_ingoing, total_outgoing)\n",
    "    \"\"\"\n",
    "    ingoing_per_transitnode = {}\n",
    "    outgoing_per_transitnode = {}\n",
    "\n",
    "    for tnode in V_transit:\n",
    "        ingoing = {arc for arc in A if split_edge_to_nodes(arc)[1] == tnode}\n",
    "        outgoing = {arc for arc in A if split_edge_to_nodes(arc)[0] == tnode}\n",
    "        ingoing_per_transitnode[tnode] = ingoing\n",
    "        outgoing_per_transitnode[tnode] = outgoing\n",
    "\n",
    "    total_ingoing = sum(len(v) for v in ingoing_per_transitnode.values())\n",
    "    total_outgoing = sum(len(v) for v in outgoing_per_transitnode.values())\n",
    "\n",
    "    return ingoing_per_transitnode, outgoing_per_transitnode, total_ingoing, total_outgoing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load parameters and actual values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí∞ Load Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_edge_attributes(csv_path, reverse_mapping):\n",
    "    \"\"\"\n",
    "    Load edge attribute CSV and create EdgeID using node reverse mapping.\n",
    "\n",
    "    Parameters:\n",
    "        csv_path (str): Path to the CSV file containing edge attributes.\n",
    "        reverse_mapping (dict): Mapping from (x, y) coordinates to node IDs.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Edge attribute DataFrame with added 'node1_ID', 'node2_ID', and 'EdgeID' columns.\n",
    "    \"\"\"\n",
    "    # Load CSV\n",
    "    edge_attr_df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Map Node1 and Node2 coordinates to node IDs\n",
    "    edge_attr_df['node1_ID'] = edge_attr_df['Source(x,y)'].map(reverse_mapping)\n",
    "    edge_attr_df['node2_ID'] = edge_attr_df['Target(x,y)'].map(reverse_mapping)\n",
    "\n",
    "    # Ensure both are strings and create EdgeID\n",
    "    edge_attr_df['EdgeID'] = edge_attr_df['node1_ID'].astype(str) + edge_attr_df['node2_ID'].astype(str)\n",
    "\n",
    "    return edge_attr_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set costs parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cost_dicts(E, W, edge_attr_df):\n",
    "    \"\"\"\n",
    "    Build cost dictionaries for construction, maintenance, and upgrade.\n",
    "\n",
    "    Parameters:\n",
    "        E (iterable): Collection of edge IDs.\n",
    "        W (list/tuple): List of weight categories (e.g., [5, 10]).\n",
    "        edge_attr_df (pd.DataFrame): DataFrame with columns:\n",
    "            'EdgeID', 'Build5m', 'Build10m', 'Maintain5m', 'Maintain10m', 'Upgrade'.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            CostC (dict): {(edge, weight): construction cost}.\n",
    "            CostM (dict): {(edge, weight): maintenance cost}.\n",
    "            CostU (dict): {edge: upgrade cost}.\n",
    "    \"\"\"\n",
    "    # Initialize dictionaries\n",
    "    CostC = {(e, w): None for e in E for w in W}\n",
    "    CostM = {(e, w): None for e in E for w in W}\n",
    "    CostU = {e: None for e in E}\n",
    "\n",
    "    # prepare the edge attributed df\n",
    "    edge_attr_df['node1_ID'] = edge_attr_df['Source(x,y)'].map(reverse_mapping)\n",
    "    edge_attr_df['node2_ID'] = edge_attr_df['Target(x,y)'].map(reverse_mapping)\n",
    "    edge_attr_df['EdgeID'] = edge_attr_df['node1_ID'].astype(str) + edge_attr_df['node2_ID'].astype(str)\n",
    "\n",
    "    # Assign actual cost values from DataFrame\n",
    "    for _, row in edge_attr_df.iterrows():\n",
    "        e = row['EdgeID']\n",
    "\n",
    "        CostC[(e, W[0])] = round(row['Build5m'], 2)\n",
    "        CostC[(e, W[1])] = round(row['Build10m'], 2)\n",
    "\n",
    "        CostM[(e, W[0])] = round(row['Maintain5m'], 2)\n",
    "        CostM[(e, W[1])] = round(row['Maintain10m'], 2)\n",
    "\n",
    "        CostU[e] = round(row['Upgrade'], 2)\n",
    "\n",
    "    return CostC, CostM, CostU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Access Needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_access_needs(csv_path, filter_stands=None, split_columns=True, n_split=5):\n",
    "    \"\"\"\n",
    "    Load a stands access needs CSV, set 'ID_UG' as the index, optionally filter by a set of stand IDs,\n",
    "    modify column names to integers, and optionally split into two parts.\n",
    "\n",
    "    Parameters:\n",
    "        csv_path (str): Path to the CSV file.\n",
    "        filter_stands (set, optional): Set of stand IDs (ID_UG) to keep. Defaults to None.\n",
    "        split_columns (bool, optional): Whether to split the dataframe into two parts. Defaults to True.\n",
    "        n_split (int, optional): Number of columns for the split. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (df1, df2) if split_columns is True, else df\n",
    "            - df1: First n_split columns (original)\n",
    "            - df2: Last n_split columns (wide/extended)\n",
    "    \"\"\"\n",
    "    # Load CSV and set index\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.set_index('ID_UG', inplace=True)\n",
    "\n",
    "    # Filter for given stand IDs\n",
    "    if filter_stands is not None:\n",
    "        df = df[df.index.isin(filter_stands)]\n",
    "\n",
    "    # Modify column names to integers based on suffix after '_'\n",
    "    df.columns = df.columns.str.split('_').str[-1].astype(int)\n",
    "\n",
    "    # Optionally split into two parts\n",
    "    if split_columns:\n",
    "        df1 = df.iloc[:, :n_split]  # First n_split columns\n",
    "        df2 = df.iloc[:, -n_split:]  # Last n_split columns\n",
    "        return df1, df2\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set needroad parameters, for all stands ID in S\n",
    "$$needroad_{s,t}^\\text{timber}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$needroad_{s,t}^\\text{wide}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_needroad_parameters(S, T, accessneeds_df_dict):\n",
    "    \"\"\"\n",
    "    Create a dictionary of need road parameters for different access types.\n",
    "\n",
    "    Parameters:\n",
    "        S (iterable): Source nodes.\n",
    "        T (iterable): Target nodes.\n",
    "        accessneeds_df_dict (dict): Mapping {access_type: DataFrame} with needs from sources to targets.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with keys (access_type, s, t) and corresponding need values.\n",
    "    \"\"\"\n",
    "    needroad = {}\n",
    "    for access_type, df in accessneeds_df_dict.items():\n",
    "        for s in S:\n",
    "            for t in T:\n",
    "                needroad[(access_type, s, t)] = df.loc[s, t] if s in df.index else 0\n",
    "    return needroad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate maxflow parameters\n",
    "$$maxflow_t^\\text{timber} = \\sum_{s\\in S}needroad_{s,t}^\\text{timber}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_maxflow_params(S, T, needroad_w_s_t, access_types):\n",
    "    \"\"\"\n",
    "    Create maxflow dictionaries for given access types.\n",
    "\n",
    "    Parameters:\n",
    "        S (iterable): Source nodes.\n",
    "        T (iterable): Target nodes.\n",
    "        needroad_w_s_t (dict): Dictionary {(access_type, s, t): need}.\n",
    "        access_types (list): List of access types to compute ('timber', 'wide', etc.).\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary of maxflow dicts for each access type, e.g.,\n",
    "              {'timber': maxflow_timber_dict, 'wide': maxflow_wide_dict}\n",
    "    \"\"\"\n",
    "    maxflow_dicts = {}\n",
    "    \n",
    "    for w in access_types:\n",
    "        maxflow = {\n",
    "            (w, t): sum(needroad_w_s_t[(w, s, t)] for s in S for t in T)\n",
    "            for t in T\n",
    "        }\n",
    "        maxflow_dicts[w] = maxflow\n",
    "    \n",
    "    return maxflow_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$maxflow_t^\\text{wide} = \\sum_{s\\in S}needroad_{s,t}^\\text{wide}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define binary decision variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define binary variables for construction maintenance upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binary_decision_variables(E, W, T):\n",
    "    \"\"\"\n",
    "    Create dictionaries of binary decision variable names for construction, maintenance, and upgrade.\n",
    "\n",
    "    Parameters:\n",
    "        E (iterable): Edge IDs.\n",
    "        W (iterable): Weight categories (e.g., [5, 10]).\n",
    "        T (iterable): Time steps (integers).\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            C (dict): {(edge, weight, t): variable_name} for construction.\n",
    "            M (dict): {(edge, weight, t): variable_name} for maintenance.\n",
    "            U (dict): {(edge, t): variable_name} for upgrade.\n",
    "    \"\"\"\n",
    "    C = {(e, w, t): f\"C_{w}_{e}_t{t}\" for e in E for w in W for t in (0,) + tuple(T)}\n",
    "    M = {(e, w, t): f\"M_{w}_{e}_t{t}\" for e in E for w in W for t in (0,) + tuple(T)}\n",
    "    U = {(e, t): f\"U_{e}_t{t}\" for e in E for t in (0,) + tuple(T)}\n",
    "\n",
    "    print(\"Decision variables for C, M, U created.\")\n",
    "    return C, M, U\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### verify the created decision variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define integer variables for flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_integer_flow_variables(A, W, T):\n",
    "    \"\"\"\n",
    "    Create dictionary of integer flow variable names.\n",
    "\n",
    "    Parameters:\n",
    "        A (iterable): List of arcs.\n",
    "        W (iterable): Weight categories.\n",
    "        T (iterable): Time steps.\n",
    "\n",
    "    Returns:\n",
    "        dict: {(arc, weight, t): variable_name}\n",
    "    \"\"\"\n",
    "    flow = {(a, w, t): f\"flow_{w}_{a}_t{t}\" for a in A for w in W for t in T}\n",
    "    return flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add binary decision variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_binary_variables_to_model(model, C, M, U, CostC, CostM, CostU):\n",
    "    \"\"\"\n",
    "    Add binary decision variables (C, M, U) to a CPLEX model and prepare objective terms and coefficients.\n",
    "\n",
    "    Parameters:\n",
    "        model: CPLEX model object.\n",
    "        C, M, U (dict): Binary variable dictionaries {(edge, weight, t) or (edge, t): name}.\n",
    "        CostC, CostM, CostU (dict): Cost dictionaries corresponding to the variables.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (objective_terms, objective_coeffs)\n",
    "            - objective_terms: list of variable names\n",
    "            - objective_coeffs: list of corresponding cost coefficients\n",
    "    \"\"\"\n",
    "    objective_terms = []\n",
    "    objective_coeffs = []\n",
    "\n",
    "    # Add C_vars\n",
    "    for (e, w, t), name in C.items():\n",
    "        lb, ub = (0, 0) if t == 0 else (0, 1)\n",
    "        model.variables.add(names=[name], lb=[lb], ub=[ub], types=[\"B\"])\n",
    "        objective_terms.append(name)\n",
    "        objective_coeffs.append(CostC[(e, w)])\n",
    "\n",
    "    # Add M_vars\n",
    "    for (e, w, t), name in M.items():\n",
    "        lb, ub = (0, 0) if t == 0 else (0, 1)\n",
    "        model.variables.add(names=[name], lb=[lb], ub=[ub], types=[\"B\"])\n",
    "        objective_terms.append(name)\n",
    "        objective_coeffs.append(CostM[(e, w)])\n",
    "\n",
    "    # Add U_vars\n",
    "    for (e, t), name in U.items():\n",
    "        lb, ub = (0, 0) if t == 0 else (0, 1)\n",
    "        model.variables.add(names=[name], lb=[lb], ub=[ub], types=[\"B\"])\n",
    "        objective_terms.append(name)\n",
    "        objective_coeffs.append(CostU[e])\n",
    "    \n",
    "    print(\"Decision variables for C, M, U added to model.\")\n",
    "\n",
    "    return objective_terms, objective_coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### verify & store\n",
    "should be len(E) x (len (T)+1) x 5\n",
    "because 5 different actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_binary_variables(model, E, T, objective_coeffs, n_actions=5):\n",
    "    \"\"\"\n",
    "    Verify that the number of action variables and objective coefficients is correct.\n",
    "\n",
    "    Parameters:\n",
    "        model: CPLEX model object.\n",
    "        E (iterable): List of edges.\n",
    "        T (iterable): List of time steps.\n",
    "        objective_coeffs (list): List of objective function coefficients.\n",
    "        n_actions (int): Number of different actions per edge-time (default 5).\n",
    "\n",
    "    Prints:\n",
    "        Verification messages for variable count and objective coefficients.\n",
    "    \"\"\"\n",
    "    n_action_variables = len(model.variables.get_names())\n",
    "    expected_vars = len(E) * (len(T)+1) * n_actions\n",
    "\n",
    "    print(n_action_variables, \"action variables\")\n",
    "    print(f\"{n_actions}*len(E)*(len(T)+1) =\", expected_vars)\n",
    "    print(len(objective_coeffs), \"objective coefficients\")\n",
    "\n",
    "    if n_action_variables == expected_vars:\n",
    "        print(\"‚úÖ Verification passed: variable count match expected\")\n",
    "    else:\n",
    "        print(\"‚ùå Verification failed: variable count does not match expected\")\n",
    "    \n",
    "    if len(objective_coeffs) == expected_vars:\n",
    "        print(\"‚úÖ Verification passed: coefficient count match expected\")\n",
    "    else:\n",
    "        print(\"‚ùå Verification failed: coefficient count does not match expected\")\n",
    "\n",
    "    return n_action_variables\n",
    "\n",
    "def save_binary_variables_info(model, CostC, CostM, CostU, model_dir):\n",
    "    \"\"\"\n",
    "    Save information about binary decision variables to a text file.\n",
    "\n",
    "    Parameters:\n",
    "        model: CPLEX model object.\n",
    "        CostC, CostM, CostU (dict): Cost dictionaries for construction, maintenance, and upgrade.\n",
    "        model_dir (str): Directory where the file will be saved.\n",
    "    \"\"\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    file_path = os.path.join(model_dir, \"binary_decision_variables.txt\")\n",
    "\n",
    "    with open(file_path, \"w\") as f:\n",
    "        var_names = model.variables.get_names()\n",
    "        for name in var_names:\n",
    "            lb = model.variables.get_lower_bounds([name])[0]\n",
    "            ub = model.variables.get_upper_bounds([name])[0]\n",
    "            var_type = model.variables.get_types([name])[0]\n",
    "\n",
    "            # Determine edge/arc and weight\n",
    "            e_match = re.search(r\"node[\\w]+(?=_t\\d+)\", name)\n",
    "            e = e_match.group(0) if e_match else \"N/A\"\n",
    "\n",
    "            if name[0] != \"U\":\n",
    "                w_match = re.search(r\"[CMU]_(\\w+)(?=_node)\", name)\n",
    "                w = w_match.group(1) if w_match else \"N/A\"\n",
    "                if name[0] == \"C\":\n",
    "                    cost_coeff = CostC.get((e, w), \"N/A\")\n",
    "                else:\n",
    "                    cost_coeff = CostM.get((e, w), \"N/A\")\n",
    "            else:\n",
    "                cost_coeff = CostU.get(e, \"N/A\")\n",
    "\n",
    "            f.write(f\"{name}: lb={lb}, ub={ub}, type={var_type}, cost={cost_coeff}\\n\")\n",
    "\n",
    "    print(f\"Binary variable info saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_objective_dataframe(objective_terms, objective_coeffs):\n",
    "    \"\"\"\n",
    "    Create a pandas DataFrame with variable names and corresponding objective costs.\n",
    "\n",
    "    Parameters:\n",
    "        objective_terms (list): List of variable names.\n",
    "        objective_coeffs (list): Corresponding cost coefficients.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with columns ['variable name', 'Cost'].\n",
    "    \"\"\"\n",
    "    obj_df = pd.DataFrame({\n",
    "        'variable name': objective_terms,\n",
    "        'Cost': objective_coeffs\n",
    "    })\n",
    "    return obj_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_objective(model, objective_terms, objective_coeffs):\n",
    "\n",
    "    # Assign linear objective\n",
    "    model.objective.set_linear(list(zip(objective_terms, objective_coeffs)))\n",
    "\n",
    "    model.objective.set_sense(model.objective.sense.minimize) \n",
    "    # Confirm action\n",
    "    print(f\"Linear objective function assigned and set to minimize.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### store objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_objective_function_to_file(model, file_path):\n",
    "    \"\"\"\n",
    "    Save the linear objective function of a CPLEX model to a text file.\n",
    "\n",
    "    Parameters:\n",
    "        model: CPLEX model object.\n",
    "        file_path (str): Full path to the text file where the objective will be saved.\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "\n",
    "    objective_expr = model.objective.get_linear()\n",
    "    \n",
    "    with open(file_path, \"w\") as f:\n",
    "        for i, coeff in enumerate(objective_expr):\n",
    "            var_name = model.variables.get_names(i)\n",
    "            f.write(f\"{coeff} * {var_name}\\n\")\n",
    "    \n",
    "    print(f\"Objective function saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add flow variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_flow_variables(model, flow, lb=0, ub=9):\n",
    "    \"\"\"\n",
    "    Add integer flow variables to a CPLEX model.\n",
    "\n",
    "    Parameters:\n",
    "        model: CPLEX model object.\n",
    "        flow (dict): Dictionary of flow variables {(arc, weight, t): name}.\n",
    "        lb (int, optional): Lower bound for variables. Default is 0.\n",
    "        ub (int, optional): Upper bound for variables. Default is 9.\n",
    "    \"\"\"\n",
    "    for (e, w, t), name in flow.items():\n",
    "        model.variables.add(names=[name], lb=[lb], ub=[ub], types=[\"I\"])\n",
    "    \n",
    "    print(f\"{len(flow)} flow variables added to the model.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### verify adding of flow variables\n",
    "should be 2 x len(E) x len(T) variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_flow_variables(model, n_action_variables, A, W, T):\n",
    "    \"\"\"\n",
    "    Verify the number of flow variables in a CPLEX model.\n",
    "\n",
    "    Parameters:\n",
    "        model: CPLEX model object.\n",
    "        n_action_variables (int): Number of previously added action variables.\n",
    "        A (iterable): List of arcs.\n",
    "        W (iterable): List of weight categories.\n",
    "        T (iterable): List of time steps.\n",
    "    \"\"\"\n",
    "    n_variables = len(model.variables.get_names())\n",
    "    n_flow_variables = n_variables - n_action_variables\n",
    "    expected_flow_variables = len(A) * len(T) * len(W)\n",
    "\n",
    "    print(n_variables, \"total variables\")\n",
    "    print(n_flow_variables, \"flow variables\")\n",
    "    print(f\"Expected flow variables (len(A)*len(T)*len(W)) = {expected_flow_variables}\")\n",
    "\n",
    "    if n_flow_variables == expected_flow_variables:\n",
    "        print(\"‚úÖ Flow variable count matches expected\")\n",
    "    else:\n",
    "        print(\"‚ùå Flow variable count does NOT match expected\")\n",
    "\n",
    "    return n_flow_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_flow_variables_info(model, n_flow_variables, save_dir):\n",
    "    \"\"\"\n",
    "    Save information about flow variables to a text file.\n",
    "\n",
    "    Parameters:\n",
    "        model: CPLEX model object.\n",
    "        n_flow_variables (int): Number of flow variables to consider (from the end of variable list).\n",
    "        save_dir (str): Full path to the output text file.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    file_path = os.path.join(save_dir, \"integer_flow_variables.txt\")\n",
    "\n",
    "    var_names = model.variables.get_names()[-n_flow_variables:]\n",
    "\n",
    "    with open(file_path, \"w\") as f:\n",
    "        for name in var_names:\n",
    "            lb = model.variables.get_lower_bounds([name])[0]\n",
    "            ub = model.variables.get_upper_bounds([name])[0]\n",
    "            var_type = model.variables.get_types([name])[0]\n",
    "            f.write(f\"{name}: lb={lb}, ub={ub}, type={var_type}\\n\")\n",
    "\n",
    "    print(f\"Flow variable info saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_transitnode_arcs(flow, ingoing_per_transitnode, outgoing_per_transitnode, verbose=True):\n",
    "    \"\"\"\n",
    "    Verifies that all arcs referenced in ingoing/outgoing transit nodes exist in the flow variables.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    flow : dict\n",
    "        Dictionary of flow variables indexed by (arc, road_type, period).\n",
    "    ingoing_per_transitnode : dict\n",
    "        Dictionary mapping transit nodes to lists of ingoing arcs.\n",
    "    outgoing_per_transitnode : dict\n",
    "        Dictionary mapping transit nodes to lists of outgoing arcs.\n",
    "    verbose : bool, default True\n",
    "        Whether to print detailed results.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary containing sets of missing arcs: {'missing_in': set, 'missing_out': set}\n",
    "    \"\"\"\n",
    "    # Set of all arcs in the flow variables\n",
    "    A_for_flow = {a for (a, _, _) in flow.keys()}\n",
    "\n",
    "    # Find missing arcs\n",
    "    missing_in_arcs = {\n",
    "        a for arcs in ingoing_per_transitnode.values() \n",
    "        for a in arcs \n",
    "        if a not in A_for_flow\n",
    "    }\n",
    "    missing_out_arcs = {\n",
    "        a for arcs in outgoing_per_transitnode.values() \n",
    "        for a in arcs \n",
    "        if a not in A_for_flow\n",
    "    }\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n=== Transit Node Arc Verification ===\")\n",
    "        print(f\"Missing arcs in ingoing per transit node: {len(missing_in_arcs)}\")\n",
    "        if missing_in_arcs:\n",
    "            print(sorted(missing_in_arcs))\n",
    "        print(f\"Missing arcs in outgoing per transit node: {len(missing_out_arcs)}\")\n",
    "        if missing_out_arcs:\n",
    "            print(sorted(missing_out_arcs))\n",
    "\n",
    "        if not missing_in_arcs and not missing_out_arcs:\n",
    "            print(\"‚úÖ All transit node arcs are properly represented in the flow variables.\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Some arcs are missing. See above.\")\n",
    "\n",
    "    return {\"missing_in\": missing_in_arcs, \"missing_out\": missing_out_arcs}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow (wide) enforces road existence (wide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\forall t \\in T \\quad \\forall e\\in E: \\qquad\n",
    "flow_{(u,v),t}^{\\text{wide}} + flow_{(v,u),t}^{\\text{wide}}  \\leq maxflow_t^{\\text{wide}} \\big(C _{e,t}^{\\text{wide}} + M_{e,t}^{\\text{wide}} +  U_{e,t}\\big)$$\n",
    "$$\\Leftrightarrow$$\n",
    "$$flow_{(u,v),t}^{\\text{wide}} + flow_{(v,u),t}^{\\text{wide}} - maxflow_t^{\\text{wide}} \\big(C _{e,t}^{\\text{wide}} + M_{e,t}^{\\text{wide}} +  U_{e,t}\\big)  \\leq 0$$\n",
    "$$\\Leftrightarrow$$\n",
    "$$\n",
    "flow_{(u,v),t}^{\\text{wide}} + flow_{(v,u),t}^{\\text{wide}} - maxflow_t^{\\text{wide}}C _{e,t}^{\\text{wide}} - maxflow_t^{\\text{wide}}M_{e,t}^{\\text{wide}} - maxflow_t^{\\text{wide}}U_{e,t} \\leq 0\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_wide_flow_constraints(model, flow, C, M, U, maxflow_w_t, fw_to_bw_map, T, A_fw, road_type='wide', verification_log=None):\n",
    "    \"\"\"\n",
    "    Adds constraints to enforce that flow only occurs on wide roads and optionally logs verification data.\n",
    "\n",
    "    Prints a single checkmark when all constraints are added.\n",
    "    \"\"\"\n",
    "    if verification_log is None:\n",
    "        verification_log = []\n",
    "\n",
    "    for t in T:\n",
    "        for a_fw in A_fw:\n",
    "            a_bw = fw_to_bw_map[a_fw]\n",
    "            e = a_fw\n",
    "            try:\n",
    "                expr_vars = [flow[(a_fw, road_type, t)],\n",
    "                             flow[(a_bw, road_type, t)],\n",
    "                             C[(e, road_type, t)],\n",
    "                             M[(e, road_type, t)],\n",
    "                             U[(e, t)]]\n",
    "                \n",
    "                coeff = int(maxflow_w_t[(road_type, t)])\n",
    "                expr_coeffs = [1, 1, -coeff, -coeff, -coeff]\n",
    "                \n",
    "                constraint_name = f\"Constraint_flow_enforcing_road_{road_type}_{e}_{t}\"\n",
    "                \n",
    "                # Add constraint\n",
    "                model.linear_constraints.add(\n",
    "                    lin_expr=[[expr_vars, expr_coeffs]],\n",
    "                    senses=[\"L\"],\n",
    "                    rhs=[0],\n",
    "                    names=[constraint_name]\n",
    "                )\n",
    "                \n",
    "                # Store verification data\n",
    "                verification_log.append({\n",
    "                    \"constraint_name\": constraint_name,\n",
    "                    \"variables\": expr_vars,\n",
    "                    \"coefficients\": expr_coeffs\n",
    "                })\n",
    "                \n",
    "            except KeyError as ke:\n",
    "                verification_log.append({\n",
    "                    \"constraint_name\": f\"Missing_{road_type}_{e}_{t}\",\n",
    "                    \"error\": str(ke)\n",
    "                })\n",
    "                print(\"problem\")\n",
    "\n",
    "    # Single confirmation after all constraints are added\n",
    "    print(\"Done.\")\n",
    "    return verification_log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [helper function] verify and store constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_and_store_constraints(model, verification_data, group_name, expected_count, output_file):\n",
    "    \"\"\"\n",
    "    Verify constraints for a specific group, and store them in a file.\n",
    "\n",
    "    Parameters:\n",
    "        model: CPLEX model object.\n",
    "        verification_data (list of dict): Log of constraints, each with \"constraint_name\".\n",
    "        group_name (str): Identifier substring for the constraint group.\n",
    "        expected_count (int): Expected number of constraints in this group.\n",
    "        output_file (str): Path to store constraints belonging to this group.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the check passed, False otherwise.\n",
    "    \"\"\"\n",
    "    # Count total constraints in the model\n",
    "    total_constraints = model.linear_constraints.get_num()\n",
    "\n",
    "    # Filter constraints of this group\n",
    "    group_constraints = [\n",
    "        v for v in verification_data\n",
    "        if group_name in v.get(\"constraint_name\", \"\")\n",
    "    ]\n",
    "    n_constraints_group = len(group_constraints)\n",
    "\n",
    "    # --- Report ---\n",
    "    print(f\"\\n=== Constraint Verification: {group_name} ===\")\n",
    "    print(f\"Total constraints in model: {total_constraints}\")\n",
    "    print(f\"Constraints added in this group: {n_constraints_group}\")\n",
    "    print(f\"Expected number of constraints for this group: {expected_count}\")\n",
    "\n",
    "    if n_constraints_group == expected_count:\n",
    "        print(f\"‚úÖ Check passed: {n_constraints_group} constraints added as expected.\")\n",
    "        status = True\n",
    "    else:\n",
    "        print(f\"‚ùå Check failed: {n_constraints_group} constraints added, expected {expected_count}.\")\n",
    "        status = False\n",
    "\n",
    "    # --- Store constraints in file ---\n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.write(f\"Constraint group: {group_name}\\n\")\n",
    "        f.write(f\"Total in this group: {n_constraints_group}\\n\")\n",
    "        f.write(f\"Expected: {expected_count}\\n\\n\")\n",
    "        f.write(\"Constraints:\\n\")\n",
    "        for c in group_constraints:\n",
    "            f.write(str(c) + \"\\n\")\n",
    "\n",
    "    print(f\"Constraints written to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should be 5 x len(E) constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow (timber) enforcing road existence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "flow_{(u,v),t}^{\\text{timber}} + flow_{(v,u),t}^{\\text{timber}}\\leq maxflow_{t}^{\\text{timber}} \\big(C_{e,t}^{\\text{timber}}+ M_{e,t}^{\\text{timber}} + C _{e,t}^{\\text{wide}} + M_{e,t}^{\\text{wide}} +  U_{e,t}\\big)$$\n",
    "$$\n",
    "\\Leftrightarrow$$\n",
    "$$flow_{(u,v),t}^{\\text{timber}} + flow_{(v,u),t}^{\\text{timber}}- maxflow_{t}^{\\text{timber}} \\big(C_{e,t}^{\\text{timber}}+ M_{e,t}^{\\text{timber}} + C _{e,t}^{\\text{wide}} + M_{e,t}^{\\text{wide}} +  U_{e,t}\\big) \\leq 0$$\n",
    "$$\\Leftrightarrow$$\n",
    "$$flow_{(u,v),t}^{\\text{timber}} + flow_{(v,u),t}^{\\text{timber}}- maxflow_{t}^{\\text{timber}} C_{e,t}^{\\text{timber}}-maxflow_{t}^{\\text{timber}}  M_{e,t}^{\\text{timber}} -maxflow_{t}^{\\text{timber}}  C _{e,t}^{\\text{wide}} -maxflow_{t}^{\\text{timber}}  M_{e,t}^{\\text{wide}} -maxflow_{t}^{\\text{timber}}  U_{e,t} \\leq 0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_timber_flow_constraints(model, flow, C, M, U, maxflow_w_t, fw_to_bw_map, T, E, road_type='timber', verification_log=None):\n",
    "    \"\"\"\n",
    "    Adds constraints to enforce that flow only occurs on timber roads (or at least timber roads).\n",
    "\n",
    "    Stores verification data instead of printing each constraint individually.\n",
    "    Prints a single confirmation after all constraints are added.\n",
    "    \"\"\"\n",
    "    if verification_log is None:\n",
    "        verification_log = []\n",
    "\n",
    "    for t in T:\n",
    "        for a_fw in E:\n",
    "            a_bw = fw_to_bw_map[a_fw]\n",
    "            e = a_fw\n",
    "\n",
    "            # Validate keys exist (fail fast if missing)\n",
    "            assert (a_fw, 'timber', t) in flow, f\"Missing flow var: {(a_fw, 'timber', t)}\"\n",
    "            assert (a_bw, 'timber', t) in flow, f\"Missing flow var: {(a_bw, 'timber', t)}\"\n",
    "            assert (e, 'timber', t) in C, f\"Missing C var: {(e, 'timber', t)}\"\n",
    "            assert (e, 'timber', t) in M, f\"Missing M var: {(e, 'timber', t)}\"\n",
    "            assert (e, 'wide', t) in C, f\"Missing C var: {(e, 'wide', t)}\"\n",
    "            assert (e, 'wide', t) in M, f\"Missing M var: {(e, 'wide', t)}\"\n",
    "            assert (e, t) in U, f\"Missing U var: {(e, t)}\"\n",
    "            assert ('timber', t) in maxflow_w_t, f\"Missing maxflow param: {('timber', t)}\"\n",
    "\n",
    "            # Define linear expression variables\n",
    "            expr_vars = [\n",
    "                flow[(a_fw, 'timber', t)],\n",
    "                flow[(a_bw, 'timber', t)],\n",
    "                C[(e, 'timber', t)],\n",
    "                M[(e, 'timber', t)],\n",
    "                C[(e, 'wide', t)],\n",
    "                M[(e, 'wide', t)],\n",
    "                U[(e, t)]\n",
    "            ]\n",
    "\n",
    "            coeff = int(maxflow_w_t[('timber', t)])\n",
    "            expr_coeffs = [1, 1, -coeff, -coeff, -coeff, -coeff, -coeff]\n",
    "\n",
    "            constraint_name = f\"Constraint_timberflow_enforcing_road_{e}_{t}\"\n",
    "\n",
    "            # Add the constraint\n",
    "            model.linear_constraints.add(\n",
    "                lin_expr=[[expr_vars, expr_coeffs]],\n",
    "                senses=[\"L\"],\n",
    "                rhs=[0],\n",
    "                names=[constraint_name]\n",
    "            )\n",
    "\n",
    "            # Store verification data\n",
    "            verification_log.append({\n",
    "                \"constraint_name\": constraint_name,\n",
    "                \"variables\": expr_vars,\n",
    "                \"coefficients\": expr_coeffs\n",
    "            })\n",
    "\n",
    "    # Single confirmation\n",
    "    print(\"Done.\")\n",
    "    return verification_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should be 5 x len(E) constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow conservation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\forall t \\in T \\quad \\forall v \\in V_{\\text{transit}}\\quad \\forall w \\in W$$\n",
    "$\n",
    "\\begin{align}\n",
    "       \\sum_{u \\in N(v)} flow_{(u,v),t}^{w} &= \\sum_{u \\in N(v)} flow_{(v,u),t}^{w}\\\\\n",
    "       &\\Leftrightarrow\n",
    "       \\\\\n",
    "       \\sum_{u \\in N(v)} flow_{(u,v),t}^{w} - \\sum_{u \\in N(v)} flow_{(v,u),t}^{w}&=0\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_flow_conservation_constraints(model, flow, ingoing_per_transitnode, outgoing_per_transitnode, W, T, verification_log=None):\n",
    "    \"\"\"\n",
    "    Adds flow conservation constraints for all transit nodes, road types, and periods.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : CPLEX model\n",
    "        Optimization model to which constraints are added.\n",
    "    flow : dict\n",
    "        Dictionary of flow variables indexed by (arc, road_type, period).\n",
    "    ingoing_per_transitnode : dict\n",
    "        Mapping transit nodes to lists of ingoing arcs.\n",
    "    outgoing_per_transitnode : dict\n",
    "        Mapping transit nodes to lists of outgoing arcs.\n",
    "    W : iterable\n",
    "        Road types.\n",
    "    T : iterable\n",
    "        Periods.\n",
    "    verification_log : list, optional\n",
    "        List to store verification data (variables, coefficients, constraint names).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Updated verification_log with new entries.\n",
    "    \"\"\"\n",
    "    if verification_log is None:\n",
    "        verification_log = []\n",
    "\n",
    "    for w in W:\n",
    "        for t in T:\n",
    "            for tnode, in_arcs in ingoing_per_transitnode.items():\n",
    "                out_arcs = outgoing_per_transitnode.get(tnode, [])\n",
    "\n",
    "                # Validate that all variables exist\n",
    "                for a_in in in_arcs:\n",
    "                    assert (a_in, w, t) in flow, f\"Missing flow variable: {(a_in, w, t)}\"\n",
    "                for a_out in out_arcs:\n",
    "                    assert (a_out, w, t) in flow, f\"Missing flow variable: {(a_out, w, t)}\"\n",
    "\n",
    "                # Linear expression\n",
    "                expr_vars = [flow[(a_in, w, t)] for a_in in in_arcs] + [flow[(a_out, w, t)] for a_out in out_arcs]\n",
    "                expr_coeffs = [1] * len(in_arcs) + [-1] * len(out_arcs)\n",
    "\n",
    "                constraint_name = f\"Constraint_flow_conservation_{w}_{t}_{tnode}\"\n",
    "\n",
    "                # Add constraint\n",
    "                model.linear_constraints.add(\n",
    "                    lin_expr=[[expr_vars, expr_coeffs]],\n",
    "                    senses=[\"E\"],  # equality\n",
    "                    rhs=[0],\n",
    "                    names=[constraint_name]\n",
    "                )\n",
    "\n",
    "                # Store verification data\n",
    "                verification_log.append({\n",
    "                    \"constraint_name\": constraint_name,\n",
    "                    \"variables\": expr_vars,\n",
    "                    \"coefficients\": expr_coeffs\n",
    "                })\n",
    "\n",
    "    print(f\"Done.\")\n",
    "    return verification_log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should be 2 x len(V_transit) x 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outflow if and only if stand needs road"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{align}\n",
    "\\forall t \\in T\\quad\\forall s\\in V_{source}\\quad\\forall w\\in W:\\quad\\\\\n",
    "   \\sum_{v\\in B(s)}flow_{(s,v),t}^{w} &= need\\_road_{s,t}^{w}\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_outflow_needroad_constraints(model, flow, needroad_w_s_t, source_arcs_outgoing, W, T, verification_log=None):\n",
    "    \"\"\"\n",
    "    Adds constraints to enforce that outflow occurs only from stands that need a road.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : CPLEX model\n",
    "        Optimization model to which constraints are added.\n",
    "    flow : dict\n",
    "        Dictionary of flow variables indexed by (arc, road_type, period).\n",
    "    needroad_w_s_t : dict\n",
    "        Dictionary of expected outflow from each stand: keyed by (road_type, stand, period).\n",
    "    source_arcs_outgoing : dict\n",
    "        Mapping from stand s to list of outgoing arcs.\n",
    "    W : iterable\n",
    "        Road types.\n",
    "    T : iterable\n",
    "        Periods.\n",
    "    verification_log : list, optional\n",
    "        List to store verification data (variables, coefficients, RHS, constraint names).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Updated verification_log with new entries.\n",
    "    \"\"\"\n",
    "    if verification_log is None:\n",
    "        verification_log = []\n",
    "\n",
    "    for w in W:\n",
    "        for t in T:\n",
    "            for s, out_arcs in source_arcs_outgoing.items():\n",
    "                # Validate keys exist\n",
    "                for e in out_arcs:\n",
    "                    assert (e, w, t) in flow, f\"Missing flow variable: {(e, w, t)}\"\n",
    "                assert (w, s, t) in needroad_w_s_t, f\"Missing needroad parameter: {(w, s, t)}\"\n",
    "\n",
    "                # Define linear expression\n",
    "                expr_vars = [flow[(e, w, t)] for e in out_arcs]\n",
    "                expr_coeffs = [1] * len(out_arcs)\n",
    "                rhs = int(needroad_w_s_t[(w, s, t)])\n",
    "\n",
    "                constraint_name = f\"Constraint_outflow_iff_needroad_{w}_{s}_t{t}\"\n",
    "\n",
    "                # Add constraint\n",
    "                model.linear_constraints.add(\n",
    "                    lin_expr=[[expr_vars, expr_coeffs]],\n",
    "                    senses=[\"E\"],  # equality\n",
    "                    rhs=[rhs],\n",
    "                    names=[constraint_name]\n",
    "                )\n",
    "\n",
    "                # Store verification data\n",
    "                verification_log.append({\n",
    "                    \"constraint_name\": constraint_name,\n",
    "                    \"variables\": expr_vars,\n",
    "                    \"coefficients\": expr_coeffs,\n",
    "                    \"rhs\": rhs\n",
    "                })\n",
    "\n",
    "    # Single confirmation\n",
    "    print(f\"Done.\")\n",
    "    return verification_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should be len(V_source) x 5 actions x 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Inflow to source nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{align}\n",
    "\\forall t \\in T\\quad\\forall s\\in V_{source}:\\quad\n",
    "    \\sum_{u\\in B(s)} \\Big(flow_{(u,s),t}^{\\text{wide}} + flow_{(u,s),t}^{\\text{timber}}\\Big) = 0\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_no_inflow_source_constraints(model, flow, source_arcs_ingoing, T, verification_log=None):\n",
    "    \"\"\"\n",
    "    Adds constraints to prevent inflow to source nodes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : CPLEX model\n",
    "        Optimization model to which constraints are added.\n",
    "    flow : dict\n",
    "        Dictionary of flow variables indexed by (arc, road_type, period).\n",
    "    source_arcs_ingoing : dict\n",
    "        Mapping from source node s to list of ingoing arcs.\n",
    "    T : iterable\n",
    "        Periods.\n",
    "    verification_log : list, optional\n",
    "        List to store verification data (variables, coefficients, constraint names).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Updated verification_log with new entries.\n",
    "    \"\"\"\n",
    "    if verification_log is None:\n",
    "        verification_log = []\n",
    "\n",
    "    for t in T:\n",
    "        for s, in_arcs in source_arcs_ingoing.items():\n",
    "            # Validate keys exist\n",
    "            for a in in_arcs:\n",
    "                assert (a, 'timber', t) in flow, f\"Missing flow variable: {(a, 'timber', t)}\"\n",
    "                assert (a, 'wide', t) in flow, f\"Missing flow variable: {(a, 'wide', t)}\"\n",
    "\n",
    "            # Linear expression: sum of all inflows (timber + wide)\n",
    "            expr_vars = [flow[(a, 'timber', t)] for a in in_arcs] + [flow[(a, 'wide', t)] for a in in_arcs]\n",
    "            expr_coeffs = [1] * len(in_arcs) + [1] * len(in_arcs)\n",
    "\n",
    "            constraint_name = f\"Constraint_no_inflow_source_{s}_{t}\"\n",
    "\n",
    "            # Add constraint\n",
    "            model.linear_constraints.add(\n",
    "                lin_expr=[[expr_vars, expr_coeffs]],\n",
    "                senses=[\"E\"],  # equality\n",
    "                rhs=[0],\n",
    "                names=[constraint_name]\n",
    "            )\n",
    "\n",
    "            # Store verification data\n",
    "            verification_log.append({\n",
    "                \"constraint_name\": constraint_name,\n",
    "                \"variables\": expr_vars,\n",
    "                \"coefficients\": expr_coeffs\n",
    "            })\n",
    "\n",
    "    # Single confirmation\n",
    "    print(f\"Done.\")\n",
    "    return verification_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should be len(V_source)*5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maintenance & Upgrade Constraints for timber roads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$M_{e,t}^{\\text{timber}} + U_{e,t} \\leq C_{e,t-1}^{\\text{timber}} + M_{e,t-1}^{\\text{timber}}$$\n",
    "$$\\Leftrightarrow$$\n",
    "$$M_{e,t}^{\\text{timber}} + U_{e,t} - C_{e,t-1}^{\\text{timber}} - M_{e,t-1}^{\\text{timber}} \\leq 0$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_maintain_upgrade_constraints(model, C, M, U, E, T, road_type='timber', verification_log=None):\n",
    "    \"\"\"\n",
    "    Adds constraints to ensure Maintenance or Upgrade on timber roads respects previous construction/maintenance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : CPLEX model\n",
    "        Optimization model to which constraints are added.\n",
    "    C : dict\n",
    "        Construction variables indexed by (edge, road_type, period).\n",
    "    M : dict\n",
    "        Maintenance variables indexed by (edge, road_type, period).\n",
    "    U : dict\n",
    "        Upgrade variables indexed by (edge, period).\n",
    "    E : iterable\n",
    "        List of edges.\n",
    "    T : iterable\n",
    "        List of periods.\n",
    "    road_type : str, default 'timber'\n",
    "        Type of road for the constraint.\n",
    "    verification_log : list, optional\n",
    "        List to store verification data (variables, coefficients, constraint names).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Updated verification_log with new entries.\n",
    "    \"\"\"\n",
    "    if verification_log is None:\n",
    "        verification_log = []\n",
    "\n",
    "    for t in T:\n",
    "        for e in E:\n",
    "            # Skip t=0 if you don‚Äôt want negative indices\n",
    "            if t == 0:\n",
    "                continue\n",
    "\n",
    "            # Validate keys exist\n",
    "            assert (e, road_type, t) in M, f\"Missing M variable: {(e, road_type, t)}\"\n",
    "            assert (e, t) in U, f\"Missing U variable: {(e, t)}\"\n",
    "            assert (e, road_type, t-1) in C, f\"Missing C variable: {(e, road_type, t-1)}\"\n",
    "            assert (e, road_type, t-1) in M, f\"Missing M variable: {(e, road_type, t-1)}\"\n",
    "\n",
    "            # Linear expression\n",
    "            expr_vars = [\n",
    "                M[(e, road_type, t)],\n",
    "                U[(e, t)],\n",
    "                C[(e, road_type, t-1)],\n",
    "                M[(e, road_type, t-1)]\n",
    "            ]\n",
    "            expr_coeffs = [1, 1, -1, -1]\n",
    "\n",
    "            constraint_name = f\"Constraint_maintain_upgrade_{road_type}_{e}_{t}\"\n",
    "\n",
    "            # Add constraint\n",
    "            model.linear_constraints.add(\n",
    "                lin_expr=[[expr_vars, expr_coeffs]],\n",
    "                senses=[\"L\"],  # <=\n",
    "                rhs=[0],\n",
    "                names=[constraint_name]\n",
    "            )\n",
    "\n",
    "            # Store verification data\n",
    "            verification_log.append({\n",
    "                \"constraint_name\": constraint_name,\n",
    "                \"variables\": expr_vars,\n",
    "                \"coefficients\": expr_coeffs\n",
    "            })\n",
    "\n",
    "    # Single confirmation\n",
    "    print(f\"Done for '{road_type}'.\")\n",
    "    return verification_log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should be 5x len(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maintenance/ Upgrade constraints for wide roads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{align}\n",
    "M_{e,t}^{wide} &\\leq C_{e,t-1}^{wide} + M_{e,t-1}^{wide} + U_{e,t-1}\\\\\n",
    "\\\\\n",
    "&\\Leftrightarrow\\\\\\\n",
    "\\\\\n",
    "M_{e,t}^{wide} - C_{e,t-1}^{wide} - M_{e,t-1}^{wide} - U_{e,t-1} &\\leq 0\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_maintain_upgrade_wide_constraints(model, C, M, U, E, T, road_type='wide', verification_log=None):\n",
    "    \"\"\"\n",
    "    Adds constraints to ensure Maintenance or Upgrade on wide roads respects previous construction/maintenance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : CPLEX model\n",
    "        Optimization model to which constraints are added.\n",
    "    C : dict\n",
    "        Construction variables indexed by (edge, road_type, period).\n",
    "    M : dict\n",
    "        Maintenance variables indexed by (edge, road_type, period).\n",
    "    U : dict\n",
    "        Upgrade variables indexed by (edge, period).\n",
    "    E : iterable\n",
    "        List of edges.\n",
    "    T : iterable\n",
    "        List of periods.\n",
    "    road_type : str, default 'wide'\n",
    "        Type of road for the constraint.\n",
    "    verification_log : list, optional\n",
    "        List to store verification data (variables, coefficients, constraint names).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Updated verification_log with new entries.\n",
    "    \"\"\"\n",
    "    if verification_log is None:\n",
    "        verification_log = []\n",
    "\n",
    "    for t in T:\n",
    "        for e in E:\n",
    "            # Skip t=0 if needed\n",
    "            if t == 0:\n",
    "                continue\n",
    "\n",
    "            # Validate all required keys exist\n",
    "            assert (e, road_type, t) in M, f\"Missing M variable: {(e, road_type, t)}\"\n",
    "            assert (e, road_type, t-1) in C, f\"Missing C variable: {(e, road_type, t-1)}\"\n",
    "            assert (e, road_type, t-1) in M, f\"Missing M variable: {(e, road_type, t-1)}\"\n",
    "            assert (e, t-1) in U, f\"Missing U variable: {(e, t-1)}\"\n",
    "\n",
    "            # Linear expression\n",
    "            expr_vars = [\n",
    "                M[(e, road_type, t)],\n",
    "                C[(e, road_type, t-1)],\n",
    "                M[(e, road_type, t-1)],\n",
    "                U[(e, t-1)]\n",
    "            ]\n",
    "            expr_coeffs = [1, -1, -1, -1]\n",
    "\n",
    "            constraint_name = f\"Constraint_maintain_upgrade_{road_type}_{e}_{t}\"\n",
    "\n",
    "            # Add constraint\n",
    "            model.linear_constraints.add(\n",
    "                lin_expr=[[expr_vars, expr_coeffs]],\n",
    "                senses=[\"L\"],  # <=\n",
    "                rhs=[0],\n",
    "                names=[constraint_name]\n",
    "            )\n",
    "\n",
    "            # Store verification data\n",
    "            verification_log.append({\n",
    "                \"constraint_name\": constraint_name,\n",
    "                \"variables\": expr_vars,\n",
    "                \"coefficients\": expr_coeffs\n",
    "            })\n",
    "\n",
    "    print(f\"Done for wide.\")\n",
    "    return verification_log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the result of adding constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_constraints(model, output_file=None, return_df=False):\n",
    "    \"\"\"\n",
    "    Inspect all linear constraints in a CPLEX model and optionally save to a text file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : CPLEX model\n",
    "        The optimization model to inspect.\n",
    "    output_file : str, optional\n",
    "        Path to a text file where all constraints will be saved.\n",
    "    return_df : bool, default False\n",
    "        If True, returns a DataFrame containing all constraints info.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame or None\n",
    "        DataFrame with columns: ['name', 'expression', 'sense', 'rhs', 'variables', 'coefficients'] if return_df=True.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    constraint_data = []\n",
    "\n",
    "    for i in range(model.linear_constraints.get_num()):\n",
    "        row = model.linear_constraints.get_rows(i)\n",
    "        indices = row.ind\n",
    "        coefs = row.val\n",
    "        name = model.linear_constraints.get_names(i) or f\"constraint_{i}\"\n",
    "        rhs = model.linear_constraints.get_rhs(i)\n",
    "        sense = model.linear_constraints.get_senses(i)\n",
    "\n",
    "        vars_in_constraint = [model.variables.get_names(idx) for idx in indices]\n",
    "        terms = [f\"{coef}*{var}\" for coef, var in zip(coefs, vars_in_constraint)]\n",
    "        expression = \" + \".join(terms)\n",
    "\n",
    "        # Store info for DataFrame or file\n",
    "        constraint_data.append({\n",
    "            \"name\": name,\n",
    "            \"expression\": expression,\n",
    "            \"sense\": sense,\n",
    "            \"rhs\": rhs,\n",
    "            \"variables\": vars_in_constraint,\n",
    "            \"coefficients\": coefs\n",
    "        })\n",
    "\n",
    "    # Save to file if requested\n",
    "    if output_file:\n",
    "        with open(output_file, \"w\") as f:\n",
    "            for row in constraint_data:\n",
    "                f.write(f\"{row['name']}: {row['expression']} {row['sense']} {row['rhs']}\\n\")\n",
    "        print(f\"All constraints saved to {output_file}\")\n",
    "\n",
    "    if return_df:\n",
    "        return pd.DataFrame(constraint_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíæ save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_solution_summary(model, top_n=20):\n",
    "    \"\"\"\n",
    "    Prints a summarized view of the CPLEX solution for large models.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : CPLEX model\n",
    "        Solved CPLEX model.\n",
    "    top_n : int, default 20\n",
    "        Number of largest non-zero variables to display.\n",
    "    save_csv : str or None\n",
    "        If provided, saves the full solution to a CSV file.\n",
    "    \"\"\"\n",
    "    solution = model.solution\n",
    "    if not solution.is_primal_feasible():\n",
    "        print(\"‚ùå No feasible solution found.\")\n",
    "        return\n",
    "\n",
    "    # Objective\n",
    "    obj_val = solution.get_objective_value()\n",
    "    print(f\"‚úÖ Objective value: {obj_val}\\n\")\n",
    "    print(f\"Optimal values: {model.solution.get_values()}\\n\")\n",
    "\n",
    "    # Get all variables and values\n",
    "    var_names = model.variables.get_names()\n",
    "    var_values = solution.get_values()\n",
    "\n",
    "    # Create DataFrame for easy filtering/sorting\n",
    "    df_sol = pd.DataFrame({\n",
    "        \"variable\": var_names,\n",
    "        \"value\": var_values\n",
    "    })\n",
    "\n",
    "    # Non-zero variables\n",
    "    non_zero = df_sol[df_sol[\"value\"] != 0].copy()\n",
    "    print(f\"Total variables: {len(var_names)}\")\n",
    "    print(f\"Non-zero variables: {len(non_zero)}\\n\")\n",
    "\n",
    "    # Print top N largest values\n",
    "    print(f\"Top {top_n} largest non-zero variables:\")\n",
    "    print(non_zero.sort_values(by=\"value\", ascending=False).head(top_n).to_string(index=False))\n",
    "    \n",
    "    return df_sol, solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ save the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_solution_df(model):\n",
    "    \"\"\"\n",
    "    Extracts the CPLEX solution into a tidy DataFrame with columns:\n",
    "    variable, value, period, action, type, edge.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : CPLEX model\n",
    "        Solved CPLEX model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with solution variables and metadata.\n",
    "    \"\"\"\n",
    "    # Get solution object\n",
    "    solution = model.solution\n",
    "\n",
    "    # Get variable names and values\n",
    "    variable_names = model.variables.get_names()\n",
    "    variable_values = solution.get_values()\n",
    "\n",
    "    # Create initial DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'variable': variable_names,\n",
    "        'value': variable_values\n",
    "    })\n",
    "\n",
    "    # --- Extract period safely ---\n",
    "    df['period'] = df['variable'].str.extract(r'_t(\\d+)$')[0]\n",
    "    df['period'] = pd.to_numeric(df['period'], errors='coerce')  # NaN if no match\n",
    "\n",
    "    # --- Determine action ---\n",
    "    def determine_action(var):\n",
    "        if var.startswith('C'):\n",
    "            return 'construct'\n",
    "        elif var.startswith('M'):\n",
    "            return 'maintain'\n",
    "        elif var.startswith('U'):\n",
    "            return 'upgrade'\n",
    "        elif var.startswith('flow'):\n",
    "            return 'flow'\n",
    "        return 'Unknown'\n",
    "    df['action'] = df['variable'].apply(determine_action)\n",
    "\n",
    "    # --- Extract road type (timber or wide) ---\n",
    "    df['type'] = df['variable'].str.extract(r'_(timber|wide)_')[0]\n",
    "\n",
    "    # --- Extract edge (like node8node14) ---\n",
    "    df['edge'] = df['variable'].str.extract(r'_(node\\d+node\\d+)')[0]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_solution_to_coords(solution_df, node_ID_mapping):\n",
    "    \"\"\"\n",
    "    Remaps edges in the solution DataFrame to node coordinates.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    solution_df : pd.DataFrame\n",
    "        DataFrame containing at least the 'edge' column.\n",
    "    node_ID_mapping : dict\n",
    "        Maps node IDs (e.g., 'node8') to coordinates (tuple or list, e.g., (lat, lon)).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Updated DataFrame with coordinate columns:\n",
    "        node1, node2, node1_coord, node2_coord, node1_lat, node1_lon, node2_lat, node2_lon\n",
    "    \"\"\"\n",
    "    # Ensure we work on a copy to avoid SettingWithCopyWarning\n",
    "    df = solution_df.copy()\n",
    "\n",
    "    # Split edge into nodes\n",
    "    df[['node1', 'node2']] = df['edge'].str.extract(r'(node\\d+)(node\\d+)')\n",
    "\n",
    "    # Map full node IDs to coordinates\n",
    "    df['node1_coord'] = df['node1'].map(node_ID_mapping)\n",
    "    df['node2_coord'] = df['node2'].map(node_ID_mapping)\n",
    "\n",
    "    # Split coordinates into lat/lon\n",
    "    df[['node1_lat','node1_lon']] = pd.DataFrame(df['node1_coord'].tolist(), index=df.index)\n",
    "    df[['node2_lat','node2_lon']] = pd.DataFrame(df['node2_coord'].tolist(), index=df.index)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All-in-1 verification workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def prepare_verify_df(solution_df, edge_attr_df):\n",
    "    \"\"\"\n",
    "    Merge solution with edge attributes and compute cost for each row.\n",
    "    \"\"\"\n",
    "    verify_df = solution_df.merge(edge_attr_df, left_on=\"edge\", right_on=\"EdgeID\", how='inner')\n",
    "    \n",
    "    # Define conditions for cost assignment\n",
    "    conditions = [\n",
    "        (verify_df[\"action\"] == \"construct\") & (verify_df[\"type\"] == \"timber\"),\n",
    "        (verify_df[\"action\"] == \"construct\") & (verify_df[\"type\"] == \"wide\"),\n",
    "        (verify_df[\"action\"] == \"maintain\") & (verify_df[\"type\"] == \"timber\"),\n",
    "        (verify_df[\"action\"] == \"maintain\") & (verify_df[\"type\"] == \"wide\"),\n",
    "        (verify_df[\"action\"] == \"upgrade\"),\n",
    "    ]\n",
    "    \n",
    "    choices = [\n",
    "        verify_df[\"Build5m\"],\n",
    "        verify_df[\"Build10m\"],\n",
    "        verify_df[\"Maintain5m\"],\n",
    "        verify_df[\"Maintain10m\"],\n",
    "        verify_df[\"Upgrade\"],\n",
    "    ]\n",
    "    \n",
    "    verify_df[\"cost\"] = np.select(conditions, choices, default=0)\n",
    "    verify_df.drop(columns=[\"Build5m\", \"Build10m\", \"Maintain5m\", \"Maintain10m\", \"Upgrade\"], inplace=True)\n",
    "    \n",
    "    return verify_df\n",
    "\n",
    "def check_solution_value(verify_df, solution):\n",
    "    \"\"\"\n",
    "    Verify that the calculated cost matches the solver objective.\n",
    "    \"\"\"\n",
    "    calc_cost = verify_df.loc[verify_df.value != 0, \"cost\"].sum()\n",
    "    sol_cost = solution.get_objective_value()\n",
    "    \n",
    "    print(\"üîé Consistency Check\")\n",
    "    print(\"-------------------\")\n",
    "    print(f\"Calculated cost (from verify_df): {calc_cost}\")\n",
    "    print(f\"Solver-reported objective value : {sol_cost}\")\n",
    "    \n",
    "    if abs(calc_cost - sol_cost) < 1e-6:\n",
    "        print(\"‚úÖ Consistent: values match within tolerance.\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Inconsistency detected:\")\n",
    "        print(f\"Difference: {calc_cost - sol_cost}\")\n",
    "\n",
    "def check_initialization(verify_df):\n",
    "    \"\"\"\n",
    "    Verify no edges are active at period 0.\n",
    "    \"\"\"\n",
    "    init_edges = verify_df[(verify_df[\"value\"] != 0) & (verify_df[\"period\"] == 0)]\n",
    "    print(\"----------------------------------------\")\n",
    "    print(\"üîé Initialization Check (period 0)\")\n",
    "    if init_edges.empty:\n",
    "        print(\"‚úÖ No edges active at period 0 (clean initialization).\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Some edges are already active at initialization:\")\n",
    "        print(init_edges[[\"node_min\", \"node_max\", \"value\", \"cost\"]])\n",
    "\n",
    "def check_maintenance_rules(verify_df, road_type, allowed_actions):\n",
    "    \"\"\"\n",
    "    Verify that maintenance/upgrades are only applied after valid previous actions.\n",
    "    \"\"\"\n",
    "    df = verify_df[verify_df[\"type\"] == road_type].copy()\n",
    "    check_df = df[\n",
    "        (df[\"action\"].isin([\"maintain\", \"upgrade\"])) &\n",
    "        (df[\"value\"] == 1) &\n",
    "        (df[\"period\"] >= 1)\n",
    "    ].copy()\n",
    "    \n",
    "    reference_df = df[\n",
    "        (df[\"action\"].isin(allowed_actions)) &\n",
    "        (df[\"value\"] == 1)\n",
    "    ][[\"edge\", \"period\"]]\n",
    "    \n",
    "    check_df[\"check_period\"] = check_df[\"period\"] - 1\n",
    "    validated_df = check_df.merge(\n",
    "        reference_df,\n",
    "        left_on=[\"edge\", \"check_period\"],\n",
    "        right_on=[\"edge\", \"period\"],\n",
    "        how=\"left\",\n",
    "        indicator=True\n",
    "    )\n",
    "    \n",
    "    violations = validated_df[validated_df[\"_merge\"] == \"left_only\"]\n",
    "    print(\"----------------------------------\")\n",
    "    print(f\"üîé {road_type.capitalize()} Road Maintenance/Upgrade Check\")\n",
    "    if violations.empty:\n",
    "        print(f\"‚úÖ All good ‚Äî every {road_type} road maintain/upgrade has valid prior action.\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è {len(violations)} violation(s) found.\")\n",
    "        print(violations[[\"edge\", \"period_x\", \"action\"]])\n",
    "\n",
    "def check_flow_support(verify_df, swap_direction):\n",
    "    \"\"\"\n",
    "    Verify that flow only occurs on edges with a supporting construction/maintenance/upgrade action.\n",
    "    \n",
    "    Timber flows can use timber or wide support.\n",
    "    Wide flows must use wide support.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    verify_df : pd.DataFrame\n",
    "        Must contain columns: ['action','edge','period','type','value']\n",
    "    swap_direction : function\n",
    "        Function to reverse the edge string (for checking reverse flows)\n",
    "    \"\"\"\n",
    "    # Step 1: Get all Flow actions with non-zero values\n",
    "    flow_df = verify_df[\n",
    "        (verify_df[\"action\"] == \"flow\") & (verify_df[\"value\"] != 0)\n",
    "    ][[\"edge\", \"period\", \"type\"]].drop_duplicates()\n",
    "    \n",
    "    # Step 2: Get all supporting actions (construct/maintain)\n",
    "    support_df = verify_df[\n",
    "        (verify_df[\"action\"].isin([\"construct\", \"maintain\"])) & (verify_df[\"value\"] == 1)\n",
    "    ][[\"edge\", \"period\", \"type\"]].drop_duplicates()\n",
    "    \n",
    "    # Step 3: Get upgrade actions (expand to both types)\n",
    "    upgrade_df = verify_df[\n",
    "        (verify_df[\"action\"] == \"upgrade\") & (verify_df[\"value\"] == 1)\n",
    "    ][[\"edge\",\"period\"]].drop_duplicates()\n",
    "    \n",
    "    # Expand upgrades to both types for timber flows\n",
    "    upgrade_expanded = upgrade_df.assign(key=1).merge(\n",
    "        pd.DataFrame({\"type\": [\"timber\",\"wide\"], \"key\":1}),\n",
    "        on=\"key\"\n",
    "    ).drop(\"key\", axis=1)\n",
    "    \n",
    "    # Combine support and upgrades\n",
    "    combined_support_df = pd.concat([support_df, upgrade_expanded], ignore_index=True)\n",
    "    \n",
    "    # Step 4: Validate flows\n",
    "    def is_supported(row):\n",
    "        if row[\"type\"] == \"timber\":\n",
    "            # Timber flow can use timber or wide support\n",
    "            return ((combined_support_df.edge == row.edge) &\n",
    "                    (combined_support_df.period == row.period) &\n",
    "                    (combined_support_df.type.isin([\"timber\",\"wide\"]))).any()\n",
    "        else:\n",
    "            # Wide flow must use wide support\n",
    "            return ((combined_support_df.edge == row.edge) &\n",
    "                    (combined_support_df.period == row.period) &\n",
    "                    (combined_support_df.type == \"wide\")).any()\n",
    "    \n",
    "    flow_df[\"supported\"] = flow_df.apply(is_supported, axis=1)\n",
    "    \n",
    "    # Step 5: Check reversed direction for unsupported flows\n",
    "    reverse_flow_df = flow_df[~flow_df[\"supported\"]].copy()\n",
    "    reverse_flow_df[\"edge\"] = reverse_flow_df[\"edge\"].apply(swap_direction)\n",
    "    reverse_flow_df[\"supported\"] = reverse_flow_df.apply(is_supported, axis=1)\n",
    "    \n",
    "    missing_flows = reverse_flow_df[~reverse_flow_df[\"supported\"]]\n",
    "    \n",
    "    # Report\n",
    "    print(\"----------------------------------------\")\n",
    "    print(\"üîé Flow Support Check\")\n",
    "    if missing_flows.empty:\n",
    "        print(\"‚úÖ All flows have valid support according to asymmetric rules.\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è {len(missing_flows)} flow(s) are missing valid support even after checking reversed direction:\")\n",
    "        print(missing_flows[[\"edge\",\"period\",\"type\"]])\n",
    "    \n",
    "    return missing_flows\n",
    "\n",
    "def check_flow_balance(verify_df, V_source, V_exit):\n",
    "    \"\"\"\n",
    "    Check flow conservation for all nodes except sources and exits.\n",
    "    \"\"\"\n",
    "    source_nodes = set(V_source.values()) if isinstance(V_source, dict) else set(V_source)\n",
    "    exit_nodes = set(V_exit.values()) if isinstance(V_exit, dict) else set(V_exit)\n",
    "    flow_df = verify_df[(verify_df[\"action\"] == \"flow\") & (verify_df[\"value\"] != 0)]\n",
    "    total_violations = 0\n",
    "\n",
    "    for road_type, type_group in flow_df.groupby(\"type\"):\n",
    "        for period, df_group in type_group.groupby(\"period\"):\n",
    "            outgoing = df_group.groupby(\"node1_ID\")[\"value\"].sum().rename(\"outgoing\")\n",
    "            incoming = df_group.groupby(\"node2_ID\")[\"value\"].sum().rename(\"incoming\")\n",
    "            flow_balance = pd.concat([outgoing, incoming], axis=1).fillna(0)\n",
    "            flow_balance[\"diff\"] = flow_balance[\"incoming\"] - flow_balance[\"outgoing\"]\n",
    "            \n",
    "            unbalanced = flow_balance[\n",
    "                (flow_balance[\"diff\"] != 0) &\n",
    "                (~flow_balance.index.isin(source_nodes)) &\n",
    "                (~flow_balance.index.isin(exit_nodes))\n",
    "            ]\n",
    "            if not unbalanced.empty:\n",
    "                print(f\"‚ö†Ô∏è Found {len(unbalanced)} unbalanced node(s):\")\n",
    "                total_violations += len(unbalanced)\n",
    "                for node, row in unbalanced.iterrows():\n",
    "                    print(f\"  Node {node}: in={row['incoming']}, out={row['outgoing']}, diff={row['diff']}\")\n",
    "    print(\"----------------------------------------\")\n",
    "    print(\" üîé Flow Balance Report ===\")\n",
    "    if total_violations == 0:\n",
    "        print(\"‚úÖ All nodes satisfy flow conservation (except sources/exits).\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Total {total_violations} unbalanced node-period(s) detected.\")\n",
    "\n",
    "def check_source_outflow(verify_df, needroad_w_s_t, V_source_dict):\n",
    "    \"\"\"\n",
    "    Check that outflow from source nodes matches expected.\n",
    "    \"\"\"\n",
    "    node_to_s = {v: k for k, v in V_source_dict.items()}\n",
    "    flow_out_df = verify_df[\n",
    "        (verify_df[\"action\"] == \"flow\") &\n",
    "        (verify_df[\"node1\"].isin(node_to_s.keys()))\n",
    "    ].copy()\n",
    "    flow_out_df[\"s\"] = flow_out_df[\"node1\"].map(node_to_s)\n",
    "\n",
    "    actual_outflow = (\n",
    "        flow_out_df.groupby([\"type\", \"s\", \"period\"])[\"value\"]\n",
    "        .sum()\n",
    "        .rename(\"actual\")\n",
    "        .reset_index()\n",
    "    )\n",
    "    actual_outflow[\"expected\"] = actual_outflow.apply(\n",
    "        lambda row: needroad_w_s_t.get((row[\"type\"], row[\"s\"], row[\"period\"]), 0),\n",
    "        axis=1\n",
    "    )\n",
    "    actual_outflow[\"diff\"] = actual_outflow[\"actual\"] - actual_outflow[\"expected\"]\n",
    "\n",
    "    mismatches = actual_outflow[actual_outflow[\"diff\"] != 0]\n",
    "    print(\"----------------------------------------\")\n",
    "    print(\"=== Source Node Outflow Check ===\")\n",
    "    if mismatches.empty:\n",
    "        print(\"‚úÖ All sources have correct outflow as expected.\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Found {len(mismatches)} mismatch(es) in source outflow:\")\n",
    "        print(mismatches[[\"type\",\"s\",\"period\",\"actual\",\"expected\",\"diff\"]])\n",
    "\n",
    "def check_double_construction(verify_df):\n",
    "    \"\"\"\n",
    "    Check for edges that are constructed as both wide and timber in the same period.\n",
    "    \"\"\"\n",
    "    nonimaginary_edges_df = verify_df[\n",
    "        (verify_df[\"value\"] ==1) &\n",
    "        (verify_df.action.isin(['construct', 'maintain','upgrade'])) &\n",
    "        (~verify_df.has_source)\n",
    "    ].copy()\n",
    "    \n",
    "    nonimaginary_edges_df[\"node_min\"] = nonimaginary_edges_df[[\"node1\", \"node2\"]].min(axis=1)\n",
    "    nonimaginary_edges_df[\"node_max\"] = nonimaginary_edges_df[[\"node1\", \"node2\"]].max(axis=1)\n",
    "    \n",
    "    grouped = nonimaginary_edges_df.groupby([\"node_min\", \"node_max\", \"period\"])[\"type\"].apply(set).reset_index()\n",
    "    double_construction = grouped[grouped[\"type\"].apply(lambda x: {\"wide\", \"timber\"}.issubset(x))]\n",
    "    print(\"----------------------------------------\")  \n",
    "    print(\"=== Double Construction Check ===\")\n",
    "    if double_construction.empty:\n",
    "        print(\"‚úÖ No edges are constructed as both 'wide' and 'timber' in the same period.\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Found {len(double_construction)} edge(s) with double construction:\")\n",
    "        print(double_construction)\n",
    "\n",
    "# -----------------------\n",
    "# Full Workflow Function\n",
    "# -----------------------\n",
    "\n",
    "def verify_solution_full(solution_df, edge_attr_df, solution, V_source_dict, V_exit, needroad_w_s_t, swap_direction):\n",
    "    \"\"\"\n",
    "    Run all verification checks on the solution.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Preparing Verification DataFrame ===\")\n",
    "    verify_df = prepare_verify_df(solution_df, edge_attr_df)\n",
    "\n",
    "    check_solution_value(verify_df, solution)\n",
    "    check_initialization(verify_df)\n",
    "    check_maintenance_rules(verify_df, \"timber\", [\"construct\", \"maintain\"])\n",
    "    check_maintenance_rules(verify_df, \"wide\", [\"construct\", \"maintain\", \"upgrade\"])\n",
    "    check_flow_support(verify_df, swap_direction)\n",
    "    check_flow_balance(verify_df, V_source_dict, V_exit_nIDs)\n",
    "    check_source_outflow(verify_df, needroad_w_s_t, V_source_dict)\n",
    "    check_double_construction(verify_df)\n",
    "    \n",
    "    print(\"Verification workflow completed.\")\n",
    "    return verify_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"2_Model\", exist_ok=True)\n",
    "model_dir=\"2_Model_Solution\"\n",
    "\n",
    "harv_sched_file_paths = {\n",
    "    \"mres\": r'1_Preprocessed_Data\\2_Stands_Access_Requirements\\mres_stands_access_needs.csv',\n",
    "    \"mwood\": r'1_Preprocessed_Data\\2_Stands_Access_Requirements\\mwood_stands_access_needs.csv',\n",
    "    \"stake\": r'1_Preprocessed_Data\\2_Stands_Access_Requirements\\stake_stands_access_needs.csv'\n",
    "}\n",
    "# basedir to get the components\n",
    "base_dir = r\"1_Preprocessed_Data\\4_Road_Network_Graphs\"\n",
    "\n",
    "# define fixed sets\n",
    "T, W = define_fixed_sets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Harvesting schedule: mres ---\n",
      "\n",
      "=== Processing Component: comp_1 ===\n",
      "Total nodes: 43\n",
      "Transit nodes: 13\n",
      "Source nodes: 7\n",
      "Exit nodes: 23\n",
      "Total arcs: 196, Forward arcs: 98, Backward arcs: 98\n",
      "‚úÖ Forward arcs are the reverse of backward arcs.\n",
      "55 ingoing to source nodes in total\n",
      "55 outgoing from source nodes in total\n",
      "Decision variables for C, M, U created.\n",
      "Decision variables for C, M, U added to model.\n",
      "2940 action variables\n",
      "5*len(E)*(len(T)+1) = 2940\n",
      "2940 objective coefficients\n",
      "‚úÖ Verification passed: variable count match expected\n",
      "‚úÖ Verification passed: coefficient count match expected\n",
      "Linear objective function assigned and set to minimize.\n",
      "1960 flow variables added to the model.\n",
      "4900 total variables\n",
      "1960 flow variables\n",
      "Expected flow variables (len(A)*len(T)*len(W)) = 1960\n",
      "‚úÖ Flow variable count matches expected\n",
      "\n",
      "=== Transit Node Arc Verification ===\n",
      "Missing arcs in ingoing per transit node: 0\n",
      "Missing arcs in outgoing per transit node: 0\n",
      "‚úÖ All transit node arcs are properly represented in the flow variables.\n",
      "Binary variable info saved to 2_Model_Solution\\mres\\comp_1\\binary_decision_variables.txt\n",
      "Flow variable info saved to 2_Model_Solution\\mres\\comp_1/integer_flow_variables.txt\n",
      "Done.\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default objective names obj1, obj2 ... being created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done for 'timber'.\n",
      "Done for wide.\n",
      "\n",
      "=== Constraint Verification: Constraint_flow_enforcing_road ===\n",
      "Total constraints in model: 2195\n",
      "Constraints added in this group: 490\n",
      "Expected number of constraints for this group: 490\n",
      "‚úÖ Check passed: 490 constraints added as expected.\n",
      "Constraints written to: 2_Model_Solution\\mres\\comp_1/Constraints_wideflow_enforce_wideroad.txt\n",
      "\n",
      "=== Constraint Verification: Constraint_timberflow_enforcing_road ===\n",
      "Total constraints in model: 2195\n",
      "Constraints added in this group: 490\n",
      "Expected number of constraints for this group: 490\n",
      "‚úÖ Check passed: 490 constraints added as expected.\n",
      "Constraints written to: 2_Model_Solution\\mres\\comp_1/Constraints_timberflow_enforce_road.txt\n",
      "\n",
      "=== Constraint Verification: Constraint_flow_conservation ===\n",
      "Total constraints in model: 2195\n",
      "Constraints added in this group: 130\n",
      "Expected number of constraints for this group: 130\n",
      "‚úÖ Check passed: 130 constraints added as expected.\n",
      "Constraints written to: 2_Model_Solution\\mres\\comp_1/Constraints_flow_conservation.txt\n",
      "\n",
      "=== Constraint Verification: Constraint_outflow_iff_needroad ===\n",
      "Total constraints in model: 2195\n",
      "Constraints added in this group: 70\n",
      "Expected number of constraints for this group: 70\n",
      "‚úÖ Check passed: 70 constraints added as expected.\n",
      "Constraints written to: 2_Model_Solution\\mres\\comp_1/Constraints_outflow_iff_needroad.txt\n",
      "\n",
      "=== Constraint Verification: Constraint_no_inflow_source ===\n",
      "Total constraints in model: 2195\n",
      "Constraints added in this group: 35\n",
      "Expected number of constraints for this group: 35\n",
      "‚úÖ Check passed: 35 constraints added as expected.\n",
      "Constraints written to: 2_Model_Solution\\mres\\comp_1/Constraints_no_inflow_to_source.txt\n",
      "\n",
      "=== Constraint Verification: Constraint_maintain_upgrade ===\n",
      "Total constraints in model: 2195\n",
      "Constraints added in this group: 490\n",
      "Expected number of constraints for this group: 490\n",
      "‚úÖ Check passed: 490 constraints added as expected.\n",
      "Constraints written to: 2_Model_Solution\\mres\\comp_1/Constraints_maintain_upgrade_timber.txt\n",
      "\n",
      "=== Constraint Verification: Constraint_maintain_upgrade_wide ===\n",
      "Total constraints in model: 2195\n",
      "Constraints added in this group: 490\n",
      "Expected number of constraints for this group: 490\n",
      "‚úÖ Check passed: 490 constraints added as expected.\n",
      "Constraints written to: 2_Model_Solution\\mres\\comp_1/Constraints_maintain_upgrade_wide.txt\n",
      "Version identifier: 22.1.1.0 | 2022-11-27 | 9160aff4d\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "Tried aggregator 2 times.\n",
      "MIP Presolve eliminated 1692 rows and 3836 columns.\n",
      "Aggregator did 24 substitutions.\n",
      "Reduced MIP has 479 rows, 1040 columns, and 2380 nonzeros.\n",
      "Reduced MIP has 730 binaries, 310 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.05 sec. (4.71 ticks)\n",
      "Found incumbent of value 541203.000000 after 0.05 sec. (5.56 ticks)\n",
      "Probing time = 0.00 sec. (0.16 ticks)\n",
      "Tried aggregator 1 time.\n",
      "MIP Presolve eliminated 197 rows and 428 columns.\n",
      "Reduced MIP has 282 rows, 612 columns, and 1416 nonzeros.\n",
      "Reduced MIP has 432 binaries, 180 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.03 sec. (0.93 ticks)\n",
      "Probing time = 0.00 sec. (0.10 ticks)\n",
      "Tried aggregator 1 time.\n",
      "Detecting symmetries...\n",
      "Reduced MIP has 282 rows, 612 columns, and 1416 nonzeros.\n",
      "Reduced MIP has 432 binaries, 180 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.11 sec. (0.96 ticks)\n",
      "Probing time = 0.00 sec. (0.10 ticks)\n",
      "Clique table members: 44.\n",
      "MIP emphasis: balance optimality and feasibility.\n",
      "MIP search method: dynamic search.\n",
      "Parallel mode: deterministic, using up to 4 threads.\n",
      "Root relaxation solution time = 0.00 sec. (0.55 ticks)\n",
      "\n",
      "        Nodes                                         Cuts/\n",
      "   Node  Left     Objective  IInf  Best Integer    Best Bound    ItCnt     Gap\n",
      "\n",
      "*     0+    0                       180410.0000        0.0000           100.00%\n",
      "      0     0      250.6364     5   180410.0000      250.6364       35   99.86%\n",
      "*     0+    0                         2757.0000      250.6364            90.91%\n",
      "      0     0     1995.1818     2     2757.0000       Cuts: 8       40   27.63%\n",
      "      0     0     2016.3636     8     2757.0000       Cuts: 6       44   26.86%\n",
      "      0     0        cutoff           2757.0000     2757.0000       44    0.00%\n",
      "Elapsed time = 0.66 sec. (26.49 ticks, tree = 0.01 MB, solutions = 5)\n",
      "\n",
      "Cover cuts applied:  2\n",
      "Mixed integer rounding cuts applied:  2\n",
      "Zero-half cuts applied:  2\n",
      "Gomory fractional cuts applied:  3\n",
      "\n",
      "Root node processing (before b&c):\n",
      "  Real time             =    0.67 sec. (26.77 ticks)\n",
      "Parallel b&c, 4 threads:\n",
      "  Real time             =    0.00 sec. (0.00 ticks)\n",
      "  Sync time (average)   =    0.00 sec.\n",
      "  Wait time (average)   =    0.00 sec.\n",
      "                          ------------\n",
      "Total (root+branch&cut) =    0.67 sec. (26.77 ticks)\n",
      "‚úÖ Objective value: 2757.0\n",
      "\n",
      "Optimal values: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Total variables: 4900\n",
      "Non-zero variables: 625\n",
      "\n",
      "Top 5 largest non-zero variables:\n",
      "                variable  value\n",
      " C_timber_node1node37_t1    1.0\n",
      "  C_wide_node24node38_t5    1.0\n",
      "C_timber_node24node38_t3    1.0\n",
      "C_timber_node24node38_t4    1.0\n",
      "C_timber_node24node38_t5    1.0\n",
      "\n",
      "=== Processing Component: comp_10 ===\n",
      "Total nodes: 114\n",
      "Transit nodes: 43\n",
      "Source nodes: 25\n",
      "Exit nodes: 46\n",
      "Total arcs: 574, Forward arcs: 287, Backward arcs: 287\n",
      "‚úÖ Forward arcs are the reverse of backward arcs.\n",
      "172 ingoing to source nodes in total\n",
      "172 outgoing from source nodes in total\n",
      "Decision variables for C, M, U created.\n",
      "Decision variables for C, M, U added to model.\n",
      "8610 action variables\n",
      "5*len(E)*(len(T)+1) = 8610\n",
      "8610 objective coefficients\n",
      "‚úÖ Verification passed: variable count match expected\n",
      "‚úÖ Verification passed: coefficient count match expected\n",
      "Linear objective function assigned and set to minimize.\n",
      "5740 flow variables added to the model.\n",
      "14350 total variables\n",
      "5740 flow variables\n",
      "Expected flow variables (len(A)*len(T)*len(W)) = 5740\n",
      "‚úÖ Flow variable count matches expected\n",
      "\n",
      "=== Transit Node Arc Verification ===\n",
      "Missing arcs in ingoing per transit node: 0\n",
      "Missing arcs in outgoing per transit node: 0\n",
      "‚úÖ All transit node arcs are properly represented in the flow variables.\n",
      "Binary variable info saved to 2_Model_Solution\\mres\\comp_10\\binary_decision_variables.txt\n",
      "Flow variable info saved to 2_Model_Solution\\mres\\comp_10/integer_flow_variables.txt\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done for 'timber'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default objective names obj1, obj2 ... being created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for wide.\n",
      "\n",
      "=== Constraint Verification: Constraint_flow_enforcing_road ===\n",
      "Total constraints in model: 6545\n",
      "Constraints added in this group: 1435\n",
      "Expected number of constraints for this group: 1435\n",
      "‚úÖ Check passed: 1435 constraints added as expected.\n",
      "Constraints written to: 2_Model_Solution\\mres\\comp_10/Constraints_wideflow_enforce_wideroad.txt\n",
      "\n",
      "=== Constraint Verification: Constraint_timberflow_enforcing_road ===\n",
      "Total constraints in model: 6545\n",
      "Constraints added in this group: 1435\n",
      "Expected number of constraints for this group: 1435\n",
      "‚úÖ Check passed: 1435 constraints added as expected.\n",
      "Constraints written to: 2_Model_Solution\\mres\\comp_10/Constraints_timberflow_enforce_road.txt\n",
      "\n",
      "=== Constraint Verification: Constraint_flow_conservation ===\n",
      "Total constraints in model: 6545\n",
      "Constraints added in this group: 430\n",
      "Expected number of constraints for this group: 430\n",
      "‚úÖ Check passed: 430 constraints added as expected.\n",
      "Constraints written to: 2_Model_Solution\\mres\\comp_10/Constraints_flow_conservation.txt\n",
      "\n",
      "=== Constraint Verification: Constraint_outflow_iff_needroad ===\n",
      "Total constraints in model: 6545\n",
      "Constraints added in this group: 250\n",
      "Expected number of constraints for this group: 250\n",
      "‚úÖ Check passed: 250 constraints added as expected.\n",
      "Constraints written to: 2_Model_Solution\\mres\\comp_10/Constraints_outflow_iff_needroad.txt\n",
      "\n",
      "=== Constraint Verification: Constraint_no_inflow_source ===\n",
      "Total constraints in model: 6545\n",
      "Constraints added in this group: 125\n",
      "Expected number of constraints for this group: 125\n",
      "‚úÖ Check passed: 125 constraints added as expected.\n",
      "Constraints written to: 2_Model_Solution\\mres\\comp_10/Constraints_no_inflow_to_source.txt\n",
      "\n",
      "=== Constraint Verification: Constraint_maintain_upgrade ===\n",
      "Total constraints in model: 6545\n",
      "Constraints added in this group: 1435\n",
      "Expected number of constraints for this group: 1435\n",
      "‚úÖ Check passed: 1435 constraints added as expected.\n",
      "Constraints written to: 2_Model_Solution\\mres\\comp_10/Constraints_maintain_upgrade_timber.txt\n",
      "\n",
      "=== Constraint Verification: Constraint_maintain_upgrade_wide ===\n",
      "Total constraints in model: 6545\n",
      "Constraints added in this group: 1435\n",
      "Expected number of constraints for this group: 1435\n",
      "‚úÖ Check passed: 1435 constraints added as expected.\n",
      "Constraints written to: 2_Model_Solution\\mres\\comp_10/Constraints_maintain_upgrade_wide.txt\n",
      "Version identifier: 22.1.1.0 | 2022-11-27 | 9160aff4d\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "Tried aggregator 2 times.\n",
      "MIP Presolve eliminated 4541 rows and 10691 columns.\n",
      "MIP Presolve modified 1968 coefficients.\n",
      "Aggregator did 66 substitutions.\n",
      "Reduced MIP has 1938 rows, 3593 columns, and 9826 nonzeros.\n",
      "Reduced MIP has 1953 binaries, 1640 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.03 sec. (15.24 ticks)\n",
      "Found incumbent of value 2420561.000000 after 0.06 sec. (25.25 ticks)\n",
      "Probing time = 0.02 sec. (0.77 ticks)\n",
      "Tried aggregator 1 time.\n",
      "Detecting symmetries...\n",
      "MIP Presolve eliminated 128 rows and 252 columns.\n",
      "Reduced MIP has 1810 rows, 3341 columns, and 9202 nonzeros.\n",
      "Reduced MIP has 1821 binaries, 1520 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.02 sec. (6.03 ticks)\n",
      "Probing time = 0.00 sec. (0.72 ticks)\n",
      "Clique table members: 184.\n",
      "MIP emphasis: balance optimality and feasibility.\n",
      "MIP search method: dynamic search.\n",
      "Parallel mode: deterministic, using up to 4 threads.\n",
      "Root relaxation solution time = 0.05 sec. (18.50 ticks)\n",
      "\n",
      "        Nodes                                         Cuts/\n",
      "   Node  Left     Objective  IInf  Best Integer    Best Bound    ItCnt     Gap\n",
      "\n",
      "*     0+    0                       391180.0000        0.0000           100.00%\n",
      "      0     0     6332.2778    82   391180.0000     6332.2778      942   98.38%\n",
      "*     0+    0                       375255.0000     6332.2778            98.31%\n",
      "      0     0    11490.1063   202   375255.0000     Cuts: 145     1351   96.94%\n",
      "      0     0    14072.2814   356   375255.0000     Cuts: 126     1908   96.25%\n",
      "*     0+    0                        42673.0000    14072.2814            67.02%\n",
      "      0     0    14797.3078   308    42673.0000      Cuts: 87     2218   65.32%\n",
      "      0     0    14970.1815   359    42673.0000      Cuts: 57     2416   64.92%\n",
      "      0     0    15091.0241   405    42673.0000      Cuts: 50     2549   64.64%\n",
      "*     0+    0                        38661.0000    15091.0241            60.97%\n",
      "*     0+    0                        37652.0000    15091.0241            59.92%\n",
      "      0     0  -1.00000e+75     0    37652.0000    15091.0241     2549   59.92%\n",
      "Detecting symmetries...\n",
      "*     0+    0                        36026.0000    15091.0241            58.11%\n",
      "      0     0    15227.1067   419    36026.0000      Cuts: 43     2718   57.73%\n",
      "      0     0    15283.7238   466    36026.0000      Cuts: 34     2846   57.58%\n",
      "      0     0    15308.0100   509    36026.0000      Cuts: 35     2956   57.51%\n",
      "      0     0    15315.3286   513    36026.0000       Cuts: 6     2990   57.49%\n",
      "      0     0    15430.8881   451    36026.0000      Cuts: 18     3125   57.17%\n",
      "*     0+    0                        34608.0000    15430.8881            55.41%\n",
      "      0     0    15446.6544   522    34608.0000      Cuts: 32     3264   55.37%\n",
      "      0     0    15455.3702   519    34608.0000      Cuts: 10     3348   55.34%\n",
      "      0     0    15474.4368   463    34608.0000      Cuts: 19     3435   55.29%\n",
      "      0     0    15488.2215   531    34608.0000      Cuts: 27     3528   55.25%\n",
      "*     0+    0                        32471.0000    15488.2215            52.30%\n",
      "      0     0    15505.3129   517    32471.0000      Cuts: 13     3608   52.25%\n",
      "      0     0    15724.7364   607    32471.0000      Cuts: 42     3902   51.57%\n",
      "      0     0    15856.0526   545    32471.0000      Cuts: 57     4133   51.17%\n",
      "      0     0    15949.6988   602    32471.0000      Cuts: 44     4319   50.88%\n",
      "      0     0    15982.2543   567    32471.0000      Cuts: 32     4456   50.78%\n",
      "      0     0    16184.6637   658    32471.0000      Cuts: 32     4683   50.16%\n",
      "      0     0    16360.5315   554    32471.0000      Cuts: 36     4970   49.61%\n",
      "      0     0    16422.6187   554    32471.0000      Cuts: 34     5102   49.42%\n",
      "      0     0    16502.7081   604    32471.0000      Cuts: 27     5258   49.18%\n",
      "      0     0    16577.3145   645    32471.0000      Cuts: 17     5428   48.95%\n",
      "      0     0    16606.9624   619    32471.0000      Cuts: 22     5535   48.86%\n",
      "      0     0    16629.2205   621    32471.0000      Cuts: 28     5700   48.79%\n",
      "      0     0    16635.9619   625    32471.0000      Cuts: 23     5786   48.77%\n",
      "      0     0    16635.9619   634    32471.0000      Cuts: 18     5808   48.77%\n",
      "      0     0    16635.9619   629    32471.0000       Cuts: 8     5821   48.77%\n",
      "Detecting symmetries...\n",
      "      0     2    16635.9619   625    32471.0000    16635.9619     5821   48.77%\n",
      "Elapsed time = 7.08 sec. (2455.86 ticks, tree = 0.02 MB, solutions = 10)\n",
      "     12    12    22437.9167   414    32471.0000    16637.0565     9741   48.76%\n",
      "     28    29    22389.0698   295    32471.0000    16725.0956    15939   48.49%\n",
      "     77    61    21575.7303   283    32471.0000    16725.0956    22525   48.49%\n",
      "    122    94    25697.0420   311    32471.0000    16725.0956    29060   48.49%\n",
      "    187   156    26320.2664   250    32471.0000    16725.0956    36864   48.49%\n",
      "    257   220    19768.7505   240    32471.0000    16725.0956    44215   48.49%\n",
      "    363   286    20650.5394   299    32471.0000    16817.7305    49788   48.21%\n",
      "    469   347    19799.8276   310    32471.0000    16817.7305    54766   48.21%\n",
      "    569   476    24195.7698   329    32471.0000    16817.7305    63589   48.21%\n",
      "   1018   857    22291.9336   451    32471.0000    16993.9322    92882   47.66%\n",
      "Elapsed time = 14.22 sec. (5600.08 ticks, tree = 10.27 MB, solutions = 10)\n",
      "\n",
      "Performing restart 1\n",
      "\n",
      "Repeating presolve.\n",
      "Tried aggregator 1 time.\n",
      "Reduced MIP has 1810 rows, 3341 columns, and 9202 nonzeros.\n",
      "Reduced MIP has 1821 binaries, 1520 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.03 sec. (4.51 ticks)\n",
      "Tried aggregator 1 time.\n",
      "Reduced MIP has 1810 rows, 3341 columns, and 9202 nonzeros.\n",
      "Reduced MIP has 1821 binaries, 1520 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.02 sec. (6.04 ticks)\n",
      "Represolve time = 0.11 sec. (28.81 ticks)\n",
      "   1256     0    17334.8623   609    32471.0000     Cuts: 552   118885   46.61%\n",
      "   1256     0    18254.4820   643    32471.0000     Cuts: 552   119839   43.78%\n",
      "   1256     0    19064.7410   651    32471.0000     Cuts: 552   120684   41.29%\n",
      "   1256     0    19466.7826   657    32471.0000     Cuts: 552   121285   40.05%\n",
      "   1256     0    19841.8755   674    32471.0000     Cuts: 552   121986   38.89%\n",
      "   1256     0    20113.9570   690    32471.0000     Cuts: 552   122582   38.06%\n",
      "   1256     0    20465.1250   661    32471.0000     Cuts: 479   123329   36.97%\n",
      "   1256     0    20737.2022   631    32471.0000     Cuts: 505   123897   36.14%\n",
      "   1256     0    20926.9826   639    32471.0000     Cuts: 552   124413   35.55%\n",
      "   1256     0    21145.4671   603    32471.0000     Cuts: 447   124914   34.88%\n",
      "   1256     0    21344.3369   655    32471.0000     Cuts: 460   125561   34.27%\n",
      "   1256     0    21565.0324   644    32471.0000     Cuts: 511   126045   33.59%\n",
      "   1256     0    21732.5490   648    32471.0000     Cuts: 546   126479   33.07%\n",
      "   1256     0    21939.0102   718    32471.0000     Cuts: 459   127010   32.44%\n",
      "   1256     0    22043.5570   598    32471.0000     Cuts: 453   127434   32.11%\n",
      "   1256     0    22073.6504   664    32471.0000     Cuts: 411   127723   32.02%\n",
      "   1256     0    22104.3168   635    32471.0000     Cuts: 381   128006   31.93%\n",
      "   1256     0    22131.4500   669    32471.0000     Cuts: 410   128280   31.84%\n",
      "   1256     0    22163.7445   636    32471.0000     Cuts: 392   128692   31.74%\n",
      "   1256     0    22279.4642   626    32471.0000     Cuts: 425   129190   31.39%\n",
      "   1256     0    22320.8391   689    32471.0000     Cuts: 502   129552   31.26%\n",
      "   1256     0    22342.8164   708    32471.0000     Cuts: 482   129876   31.19%\n",
      "   1256     0    22368.0820   659    32471.0000     Cuts: 364   130183   31.11%\n",
      "   1256     0    22425.0772   681    32471.0000     Cuts: 380   130488   30.94%\n",
      "   1256     0    22613.8104   674    32471.0000     Cuts: 505   131169   30.36%\n",
      "   1256     0    22669.1778   700    32471.0000     Cuts: 552   131520   30.19%\n",
      "   1256     0    22762.4769   700    32471.0000     Cuts: 552   132155   29.90%\n",
      "   1256     0    22790.2341   721    32471.0000     Cuts: 552   132475   29.81%\n",
      "   1256     0    22833.6059   647    32471.0000     Cuts: 526   132845   29.68%\n",
      "   1256     0    22881.4163   666    32471.0000     Cuts: 462   133236   29.53%\n",
      "   1256     0    22975.0261   671    32471.0000     Cuts: 552   133640   29.24%\n",
      "   1256     0    23046.1780   622    32471.0000     Cuts: 552   134042   29.03%\n",
      "   1256     0    23089.6024   702    32471.0000     Cuts: 552   134385   28.89%\n",
      "   1256     0    23161.5570   681    32471.0000     Cuts: 552   134802   28.67%\n",
      "   1256     0    23193.2269   701    32471.0000     Cuts: 552   135165   28.57%\n",
      "   1256     0    23218.6698   704    32471.0000     Cuts: 465   135416   28.49%\n",
      "   1256     0    23265.2021   698    32471.0000     Cuts: 515   135762   28.35%\n",
      "   1256     0    23344.6178   708    32471.0000     Cuts: 445   136233   28.11%\n",
      "   1256     0    23366.7871   697    32471.0000     Cuts: 552   136522   28.04%\n",
      "   1256     0    23427.0271   641    32471.0000     Cuts: 552   137034   27.85%\n",
      "   1256     0    23455.8607   717    32471.0000     Cuts: 552   137390   27.76%\n",
      "   1256     0    23499.6844   711    32471.0000     Cuts: 500   137724   27.63%\n",
      "   1256     0    23530.6911   668    32471.0000     Cuts: 430   137972   27.53%\n",
      "   1256     0    23547.4939   721    32471.0000     Cuts: 395   138214   27.48%\n",
      "   1256     0    23557.6164   689    32471.0000     Cuts: 407   138438   27.45%\n",
      "   1256     0    23562.7574   702    32471.0000     Cuts: 354   138606   27.43%\n",
      "   1256     0    23564.0526   656    32471.0000     Cuts: 241   138797   27.43%\n",
      "   1256     0    23564.2212   695    32471.0000     Cuts: 552   139030   27.43%\n",
      "   1256     0    23598.3436   675    32471.0000     Cuts: 321   139511   27.32%\n",
      "   1256     0    23605.6201   688    32471.0000     Cuts: 552   139789   27.30%\n",
      "   1256     2    23605.6201   636    32471.0000    23605.6201   139789   27.30%\n",
      "   1258     4    23649.6617   471    32471.0000    23651.0961   140381   27.16%\n",
      "   1265     9    25571.5056   595    32471.0000    23689.3618   143846   27.04%\n",
      "   1272    13    25068.1287   427    32471.0000    23689.3618   147878   27.04%\n",
      "   1281    22    24925.2513   492    32471.0000    23689.3618   155553   27.04%\n",
      "   1298    35    27447.3824   372    32471.0000    23689.3618   165714   27.04%\n",
      "   1320    50    26998.8787   494    32471.0000    23689.3618   173093   27.04%\n",
      "   1339    67    31810.2139   400    32471.0000    23689.3618   181552   27.04%\n",
      "   1373    92    30658.6489   314    32471.0000    23689.3618   185192   27.04%\n",
      "   1474   148    25426.1242   466    32471.0000    23689.3618   198339   27.04%\n",
      "Elapsed time = 74.75 sec. (26014.64 ticks, tree = 1.46 MB, solutions = 10)\n",
      "   1555   206        cutoff          32471.0000    23689.3618   210134   27.04%\n",
      "   1714   294    26043.6737   514    32471.0000    24300.7419   223192   25.16%\n",
      "   1854   320    26817.3594   388    32471.0000    24996.9949   225008   23.02%\n",
      "   1941   494    28618.1618   471    32471.0000    25007.1975   245886   22.99%\n",
      "   2105   542    28227.8968   512    32471.0000    25007.1975   251142   22.99%\n",
      "   2304   770    26879.2672   507    32471.0000    25010.0774   272408   22.98%\n",
      "   2552  1028    30175.5392   437    32471.0000    25077.4092   297161   22.77%\n",
      "   2720  1225    27367.5362   362    32471.0000    25147.4187   317904   22.55%\n",
      "   2908  1348    29683.1375   359    32471.0000    25223.9907   333678   22.32%\n",
      "   3155  1518    32028.8711   427    32471.0000    25248.1311   357215   22.24%\n",
      "Elapsed time = 101.75 sec. (35590.62 ticks, tree = 16.30 MB, solutions = 10)\n",
      "   3431  1622    27138.6647   391    32471.0000    25334.4282   370843   21.98%\n",
      "   3807  2044    30133.5058   370    32471.0000    25345.8712   402279   21.94%\n",
      "   4175  2449    28636.7378   429    32471.0000    25376.7380   429451   21.85%\n",
      "   4469  2690    28170.4287   494    32471.0000    25433.6851   448523   21.67%\n",
      "   4750  2921    30080.4433   437    32471.0000    25438.5323   473501   21.66%\n",
      "*  4958+ 3221                        30625.0000    25442.9101            16.92%\n",
      "   5041  3144    31608.3816   434    30625.0000    25450.4384   496574   16.90%\n",
      "   5274  2632    26164.1055   492    30625.0000    25490.9198   528864   16.76%\n",
      "   5535  2732    28024.9924   565    30625.0000    25666.9858   544657   16.19%\n",
      "   5823  3073    30132.2480   469    30625.0000    25666.9858   577961   16.19%\n",
      "   6108  3331    29616.6141   429    30625.0000    25807.0392   607930   15.73%\n",
      "Elapsed time = 124.94 sec. (45183.66 ticks, tree = 47.65 MB, solutions = 11)\n",
      "   6405  3543    29516.3258   457    30625.0000    25863.4867   633216   15.55%\n",
      "   6701  3890    28483.6825   509    30625.0000    25931.6703   667001   15.33%\n",
      "   6869  3959    27483.8644   474    30625.0000    25984.8821   679174   15.15%\n",
      "   7105  4202    29782.6728   527    30625.0000    26002.8901   709574   15.09%\n",
      "   7283  4381    28134.9370   571    30625.0000    26022.2985   739470   15.03%\n",
      "   7488  4495    30304.7271   503    30625.0000    26057.0286   758626   14.92%\n",
      "   7714  4732    29524.0517   470    30625.0000    26081.4251   797861   14.84%\n",
      "   7898  4842    28679.7000   449    30625.0000    26107.3224   818884   14.75%\n",
      "   8136  5061    29176.2722   513    30625.0000    26121.1318   850822   14.71%\n",
      "   8388  5241    27498.4384   583    30625.0000    26129.8380   871056   14.68%\n",
      "Elapsed time = 152.92 sec. (54763.20 ticks, tree = 78.71 MB, solutions = 11)\n",
      "   8632  5347    30218.7159   467    30625.0000    26152.3167   882708   14.60%\n",
      "   8849  5636    28443.9723   418    30625.0000    26167.0040   926561   14.56%\n",
      "   9155  5836    29378.5652   435    30625.0000    26173.0703   951175   14.54%\n",
      "   9452  6128    27830.5921   573    30625.0000    26192.4042   981326   14.47%\n",
      "   9643  6231    30587.2297   494    30625.0000    26214.4509   997370   14.40%\n",
      "   9911  6515    27930.4348   513    30625.0000    26220.2250  1028708   14.38%\n",
      "  10149  6596    29893.4087   530    30625.0000    26229.7080  1046727   14.35%\n",
      "  10418  6958        cutoff          30625.0000    26238.8132  1089912   14.32%\n",
      "  10703  7060    29261.8266   416    30625.0000    26256.3053  1102806   14.27%\n",
      "  10962  7333    30461.7710   422    30625.0000    26272.6860  1142092   14.21%\n",
      "Elapsed time = 184.00 sec. (64338.56 ticks, tree = 114.49 MB, solutions = 11)\n",
      "  11142  7602    28157.0372   481    30625.0000    26303.2525  1175404   14.11%\n",
      "  11375  7677    28627.6816   431    30625.0000    26309.8904  1190164   14.09%\n",
      "  11717  7967    30534.1653   419    30625.0000    26310.9333  1229042   14.09%\n",
      "  11964  8254    30101.9879   387    30625.0000    26327.6148  1256649   14.03%\n",
      "  12240  8423    29698.7704   538    30625.0000    26349.9751  1283631   13.96%\n",
      "  12493  8535    27607.9438   428    30625.0000    26366.9909  1299819   13.90%\n",
      "  12811  8862    29432.1177   472    30625.0000    26383.3403  1335637   13.85%\n",
      "  13087  9189    30486.6916   200    30625.0000    26391.9585  1370162   13.82%\n",
      "  13350  9375    28192.1221   568    30625.0000    26405.5093  1396138   13.78%\n",
      "  13603  9549    28136.1401   571    30625.0000    26406.4311  1411954   13.77%\n",
      "Elapsed time = 213.73 sec. (73905.36 ticks, tree = 149.46 MB, solutions = 11)\n",
      "  13850  9714    28264.1675   598    30625.0000    26412.7949  1438226   13.75%\n",
      "  14144 10034    29533.2888   428    30625.0000    26425.5943  1475983   13.71%\n",
      "  14484 10332    29572.5561   511    30625.0000    26428.7006  1504809   13.70%\n",
      "  14772 10405    30185.1758   359    30625.0000    26431.7495  1511944   13.69%\n",
      "  15061 10728    30544.0528   317    30625.0000    26451.9795  1549573   13.63%\n",
      "  15316 11024    29427.0642   667    30625.0000    26459.1906  1580652   13.60%\n",
      "  15592 11319    29738.1360   485    30625.0000    26461.0449  1612572   13.60%\n",
      "  15837 11539    30116.6179   507    30625.0000    26468.3697  1639963   13.57%\n",
      "  16081 11515    29449.3761   591    30625.0000    26469.8607  1639700   13.57%\n",
      "  16348 11826    29897.2957   483    30625.0000    26491.2703  1677785   13.50%\n",
      "Elapsed time = 243.31 sec. (83475.91 ticks, tree = 187.24 MB, solutions = 11)\n",
      "  16610 11986    29250.7805   505    30625.0000    26496.9143  1693463   13.48%\n",
      "  16763 12247    29189.3926   538    30625.0000    26507.8412  1731335   13.44%\n",
      "  16952 12488    29370.2872   501    30625.0000    26508.3493  1761581   13.44%\n",
      "  17225 12680    29990.9752   448    30625.0000    26549.0760  1784665   13.31%\n",
      "  17452 12647    29379.7264   561    30625.0000    26557.5080  1782008   13.28%\n",
      "  17748 12938    29472.7754   257    30625.0000    26583.5574  1821440   13.20%\n",
      "* 17768+13103                        29190.0000    26583.5574             8.93%\n",
      "  18039  7025    28351.0298   384    29190.0000    26605.5033  1846468    8.85%\n",
      "  18302  7185    27624.1883   457    29190.0000    26607.4637  1883877    8.85%\n",
      "  18540  7265    28421.2819   459    29190.0000    26628.5329  1897276    8.78%\n",
      "  18757  7582    27754.2120   601    29190.0000    26638.6971  1940925    8.74%\n",
      "Elapsed time = 274.77 sec. (93058.44 ticks, tree = 123.58 MB, solutions = 12)\n",
      "  19027  7715    29090.0351   537    29190.0000    26656.3666  1959153    8.68%\n",
      "  19235  7997    28755.7914   507    29190.0000    26672.8461  2003349    8.62%\n",
      "  19500  8141    28295.4712   552    29190.0000    26696.2561  2017438    8.54%\n",
      "  19736  8309    27712.7354   507    29190.0000    26711.2707  2039435    8.49%\n",
      "  19923  8381    27805.4816   479    29190.0000    26734.7522  2055420    8.41%\n",
      "  20149  8517    27952.8957   538    29190.0000    26740.7449  2083335    8.39%\n",
      "  20318  8662    28438.8853   528    29190.0000    26759.7558  2104846    8.33%\n",
      "  20486  8807    29177.8373   451    29190.0000    26790.6218  2131985    8.22%\n",
      "  20705  8869    28054.4606   524    29190.0000    26793.4571  2144445    8.21%\n",
      "  21500  9498    28255.8280   494    29190.0000    26869.6555  2267659    7.95%\n",
      "Elapsed time = 319.59 sec. (105508.79 ticks, tree = 155.76 MB, solutions = 12)\n",
      "  22227  9920        cutoff          29190.0000    26947.4756  2346162    7.68%\n",
      "  22971 10385    27341.0079   595    29190.0000    27021.1950  2444142    7.43%\n",
      "  23724 10931    28116.2437   416    29190.0000    27070.5754  2536059    7.26%\n",
      "  24409 11324        cutoff          29190.0000    27139.8302  2641102    7.02%\n",
      "\n",
      "Performing restart 2\n",
      "\n",
      "Repeating presolve.\n",
      "Tried aggregator 1 time.\n",
      "MIP Presolve eliminated 294 rows and 551 columns.\n",
      "Reduced MIP has 1516 rows, 2790 columns, and 7737 nonzeros.\n",
      "Reduced MIP has 1530 binaries, 1260 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.01 sec. (4.15 ticks)\n",
      "Tried aggregator 1 time.\n",
      "Reduced MIP has 1516 rows, 2790 columns, and 7737 nonzeros.\n",
      "Reduced MIP has 1530 binaries, 1260 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.02 sec. (5.07 ticks)\n",
      "Represolve time = 0.76 sec. (125.50 ticks)\n",
      "  24846     0    24485.3701   638    29190.0000     Cuts: 311  2753895    6.89%\n",
      "  24846     0    24548.2021   707    29190.0000     Cuts: 141  2754287    6.89%\n",
      "  24846     0    24582.6941   538    29190.0000     Cuts: 479  2754624    6.89%\n",
      "  24846     0    24588.1274   579    29190.0000     Cuts: 479  2754816    6.89%\n",
      "  24846     0    24593.6840   565    29190.0000     Cuts: 479  2755062    6.89%\n",
      "  24846     0    24598.5913   568    29190.0000     Cuts: 479  2755400    6.89%\n",
      "  24846     0    24617.9393   602    29190.0000     Cuts: 479  2755710    6.89%\n",
      "  24846     0    24626.0008   550    29190.0000     Cuts: 479  2756022    6.89%\n",
      "  24846     0    24635.2371   587    29190.0000     Cuts: 479  2756251    6.89%\n",
      "  24846     0    24654.8978   573    29190.0000     Cuts: 479  2756614    6.89%\n",
      "  24846     0    24655.0857   652    29190.0000     Cuts: 479  2756830    6.89%\n",
      "  24846     2    24655.0857   597    29190.0000    27178.2393  2756830    6.89%\n",
      "  24953    37        cutoff          29190.0000    27178.2393  2777128    6.89%\n",
      "  25468   331    28108.4365   451    29190.0000    27178.2393  2823498    6.89%\n",
      "  26477  1111    27600.7462   433    29190.0000    27178.2393  2931630    6.89%\n",
      "  27648  2086    28011.4484   489    29190.0000    27178.2393  3032685    6.89%\n",
      "  28675  2966    28992.0305   465    29190.0000    27178.2393  3145590    6.89%\n",
      "Elapsed time = 479.86 sec. (148255.48 ticks, tree = 32.23 MB, solutions = 14)\n",
      "  29382  3371    27415.4527   570    29190.0000    27178.2393  3247356    6.89%\n",
      "  30180  3912    28781.2208   485    29190.0000    27178.2393  3347985    6.89%\n",
      "  31024  4557    29171.3591   478    29190.0000    27178.2393  3473551    6.89%\n",
      "  31789  5040        cutoff          29190.0000    27178.2393  3568127    6.89%\n",
      "  32604  5508        cutoff          29190.0000    27178.2393  3684042    6.89%\n",
      "  33393  6129        cutoff          29190.0000    27178.2393  3796121    6.89%\n",
      "  34159  6580    28233.4106   585    29190.0000    27186.0564  3889835    6.87%\n",
      "  34866  7041    28964.9113   621    29190.0000    27250.2739  3996232    6.65%\n",
      "  35540  7328        cutoff          29190.0000    27298.5578  4077897    6.48%\n",
      "  36187  7767    28947.9357   570    29190.0000    27366.9251  4180509    6.25%\n",
      "Elapsed time = 599.80 sec. (186480.61 ticks, tree = 95.35 MB, solutions = 14)\n",
      "  36955  8160    28464.7202   504    29190.0000    27432.4580  4292509    6.02%\n",
      "  37531  8552    28492.0950   417    29190.0000    27516.1653  4396945    5.73%\n",
      "  38156  8760    28507.7205   472    29190.0000    27575.3149  4472195    5.53%\n",
      "  38730  9080    28702.3423   397    29190.0000    27621.8358  4583643    5.37%\n",
      "  39246  9272    28482.3988   471    29190.0000    27694.1348  4682923    5.12%\n",
      "  39819  9382        cutoff          29190.0000    27743.5352  4757876    4.96%\n",
      "  40354  9467    28872.2636   596    29190.0000    27795.8473  4844400    4.78%\n",
      "  40866  9630    28722.9679   493    29190.0000    27833.7719  4933308    4.65%\n",
      "  41442  9860        cutoff          29190.0000    27881.0370  5046486    4.48%\n",
      "  41995  9932    28793.9775   582    29190.0000    27906.8795  5128874    4.40%\n",
      "Elapsed time = 746.30 sec. (224764.71 ticks, tree = 129.50 MB, solutions = 14)\n",
      "  42539 10041        cutoff          29190.0000    27957.9938  5223594    4.22%\n",
      "  43130 10178    29144.3441   669    29190.0000    27994.3737  5321164    4.10%\n",
      "  43721 10316    28910.4847   391    29190.0000    28031.5168  5405138    3.97%\n",
      "  44213 10422        cutoff          29190.0000    28063.8609  5484813    3.86%\n",
      "  44809 10514        cutoff          29190.0000    28112.8971  5586656    3.69%\n",
      "  45338 10529        cutoff          29190.0000    28138.3111  5628961    3.60%\n",
      "  45885 10612    29168.8014   539    29190.0000    28177.7479  5757093    3.47%\n",
      "  46425 10530        cutoff          29190.0000    28203.1775  5801316    3.38%\n",
      "  46928 10372        cutoff          29190.0000    28250.6125  5906580    3.22%\n",
      "  47474 10314    28693.6866   620    29190.0000    28281.7168  5955252    3.11%\n",
      "Elapsed time = 860.11 sec. (262995.02 ticks, tree = 140.57 MB, solutions = 14)\n",
      "  47932 10067        cutoff          29190.0000    28323.3722  6070834    2.97%\n",
      "  48475  9981    29065.1227   508    29190.0000    28363.3140  6139166    2.83%\n",
      "  49020  9801        cutoff          29190.0000    28399.6991  6208725    2.71%\n",
      "  49596  9599        cutoff          29190.0000    28438.2060  6290673    2.58%\n",
      "  50106  9324        cutoff          29190.0000    28479.1796  6361658    2.44%\n",
      "  50659  9055        cutoff          29190.0000    28521.7480  6433378    2.29%\n",
      "  51257  8675        cutoff          29190.0000    28562.3888  6497436    2.15%\n",
      "  51879  8355        cutoff          29190.0000    28600.5795  6563227    2.02%\n",
      "  52516  7825        cutoff          29190.0000    28653.6510  6641106    1.84%\n",
      "  53191  7272        cutoff          29190.0000    28692.3404  6717662    1.70%\n",
      "Elapsed time = 989.73 sec. (301213.49 ticks, tree = 100.26 MB, solutions = 14)\n",
      "  53909  6676        cutoff          29190.0000    28746.8690  6792350    1.52%\n",
      "  54644  6107        cutoff          29190.0000    28789.8244  6849452    1.37%\n",
      "  55459  5390        cutoff          29190.0000    28845.8079  6916180    1.18%\n",
      "  56491  4459        cutoff          29190.0000    28909.0402  6994500    0.96%\n",
      "  57735  3263        cutoff          29190.0000    28982.1714  7063962    0.71%\n",
      "  59387  1719        cutoff          29190.0000    29079.1763  7123127    0.38%\n",
      "\n",
      "GUB cover cuts applied:  26\n",
      "Cover cuts applied:  21\n",
      "Flow cuts applied:  87\n",
      "Mixed integer rounding cuts applied:  1247\n",
      "Zero-half cuts applied:  84\n",
      "Lift and project cuts applied:  69\n",
      "Gomory fractional cuts applied:  1\n",
      "\n",
      "Root node processing (before b&c):\n",
      "  Real time             =    7.06 sec. (2455.16 ticks)\n",
      "Parallel b&c, 4 threads:\n",
      "  Real time             = 1080.72 sec. (324136.64 ticks)\n",
      "  Sync time (average)   =   31.61 sec.\n",
      "  Wait time (average)   =    0.12 sec.\n",
      "                          ------------\n",
      "Total (root+branch&cut) = 1087.78 sec. (326591.80 ticks)\n",
      "‚úÖ Objective value: 29190.0\n",
      "\n",
      "Optimal values: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 4.0, 5.0, 4.0, 5.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 4.0, 4.0, 5.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 5.0, 4.0, 6.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 4.0, 3.0, 4.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 5.0, 4.0, 6.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 6.0, 5.0, 7.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 6.0, 5.0, 7.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Total variables: 14350\n",
      "Non-zero variables: 2736\n",
      "\n",
      "Top 5 largest non-zero variables:\n",
      "                   variable  value\n",
      "flow_timber_node21node80_t4    7.0\n",
      "flow_timber_node21node80_t1    7.0\n",
      "flow_timber_node37node21_t4    7.0\n",
      "flow_timber_node37node21_t1    7.0\n",
      "flow_timber_node18node32_t4    6.0\n",
      "\n",
      "=== Processing Component: comp_14_15_48_merged ===\n",
      "Total nodes: 376\n",
      "Transit nodes: 176\n",
      "Source nodes: 89\n",
      "Exit nodes: 111\n",
      "Total arcs: 2038, Forward arcs: 1019, Backward arcs: 1019\n",
      "‚úÖ Forward arcs are the reverse of backward arcs.\n",
      "637 ingoing to source nodes in total\n",
      "637 outgoing from source nodes in total\n",
      "Decision variables for C, M, U created.\n",
      "Decision variables for C, M, U added to model.\n",
      "30570 action variables\n",
      "5*len(E)*(len(T)+1) = 30570\n",
      "30570 objective coefficients\n",
      "‚úÖ Verification passed: variable count match expected\n",
      "‚úÖ Verification passed: coefficient count match expected\n",
      "Linear objective function assigned and set to minimize.\n",
      "20380 flow variables added to the model.\n",
      "50950 total variables\n",
      "20380 flow variables\n",
      "Expected flow variables (len(A)*len(T)*len(W)) = 20380\n",
      "‚úÖ Flow variable count matches expected\n",
      "\n",
      "=== Transit Node Arc Verification ===\n",
      "Missing arcs in ingoing per transit node: 0\n",
      "Missing arcs in outgoing per transit node: 0\n",
      "‚úÖ All transit node arcs are properly represented in the flow variables.\n",
      "Binary variable info saved to 2_Model_Solution\\mres\\comp_14_15_48_merged\\binary_decision_variables.txt\n",
      "Flow variable info saved to 2_Model_Solution\\mres\\comp_14_15_48_merged/integer_flow_variables.txt\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done for 'timber'.\n",
      "Done for wide.\n",
      "\n",
      "=== Constraint Verification: Constraint_flow_enforcing_road ===\n",
      "Total constraints in model: 23475\n",
      "Constraints added in this group: 5095\n",
      "Expected number of constraints for this group: 5095\n",
      "‚úÖ Check passed: 5095 constraints added as expected.\n",
      "Constraints written to: 2_Model_Solution\\mres\\comp_14_15_48_merged/Constraints_wideflow_enforce_wideroad.txt\n",
      "\n",
      "=== Constraint Verification: Constraint_timberflow_enforcing_road ===\n",
      "Total constraints in model: 23475\n",
      "Constraints added in this group: 5095\n",
      "Expected number of constraints for this group: 5095\n",
      "‚úÖ Check passed: 5095 constraints added as expected.\n",
      "Constraints written to: 2_Model_Solution\\mres\\comp_14_15_48_merged/Constraints_timberflow_enforce_road.txt\n",
      "\n",
      "=== Constraint Verification: Constraint_flow_conservation ===\n",
      "Total constraints in model: 23475\n",
      "Constraints added in this group: 1760\n",
      "Expected number of constraints for this group: 1760\n",
      "‚úÖ Check passed: 1760 constraints added as expected.\n",
      "Constraints written to: 2_Model_Solution\\mres\\comp_14_15_48_merged/Constraints_flow_conservation.txt\n",
      "\n",
      "=== Constraint Verification: Constraint_outflow_iff_needroad ===\n",
      "Total constraints in model: 23475\n",
      "Constraints added in this group: 890\n",
      "Expected number of constraints for this group: 890\n",
      "‚úÖ Check passed: 890 constraints added as expected.\n",
      "Constraints written to: 2_Model_Solution\\mres\\comp_14_15_48_merged/Constraints_outflow_iff_needroad.txt\n",
      "\n",
      "=== Constraint Verification: Constraint_no_inflow_source ===\n",
      "Total constraints in model: 23475\n",
      "Constraints added in this group: 445\n",
      "Expected number of constraints for this group: 445\n",
      "‚úÖ Check passed: 445 constraints added as expected.\n",
      "Constraints written to: 2_Model_Solution\\mres\\comp_14_15_48_merged/Constraints_no_inflow_to_source.txt\n",
      "\n",
      "=== Constraint Verification: Constraint_maintain_upgrade ===\n",
      "Total constraints in model: 23475\n",
      "Constraints added in this group: 5095\n",
      "Expected number of constraints for this group: 5095\n",
      "‚úÖ Check passed: 5095 constraints added as expected.\n",
      "Constraints written to: 2_Model_Solution\\mres\\comp_14_15_48_merged/Constraints_maintain_upgrade_timber.txt\n",
      "\n",
      "=== Constraint Verification: Constraint_maintain_upgrade_wide ===\n",
      "Total constraints in model: 23475\n",
      "Constraints added in this group: 5095\n",
      "Expected number of constraints for this group: 5095\n",
      "‚úÖ Check passed: 5095 constraints added as expected.\n",
      "Constraints written to: 2_Model_Solution\\mres\\comp_14_15_48_merged/Constraints_maintain_upgrade_wide.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default objective names obj1, obj2 ... being created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version identifier: 22.1.1.0 | 2022-11-27 | 9160aff4d\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "Tried aggregator 2 times.\n",
      "MIP Presolve eliminated 15861 rows and 36226 columns.\n",
      "MIP Presolve added 658 rows and 0 columns.\n",
      "MIP Presolve modified 7896 coefficients.\n",
      "Aggregator did 106 substitutions.\n",
      "Reduced MIP has 8166 rows, 14618 columns, and 40152 nonzeros.\n",
      "Reduced MIP has 8038 binaries, 6580 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.16 sec. (56.83 ticks)\n",
      "Found incumbent of value 7740845.000000 after 0.28 sec. (116.00 ticks)\n",
      "Probing time = 0.02 sec. (1.25 ticks)\n",
      "Tried aggregator 1 time.\n",
      "MIP Presolve eliminated 1681 rows and 3033 columns.\n",
      "Reduced MIP has 6485 rows, 11585 columns, and 32174 nonzeros.\n",
      "Reduced MIP has 6445 binaries, 5140 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.05 sec. (16.14 ticks)\n",
      "Probing time = 0.01 sec. (1.01 ticks)\n",
      "Tried aggregator 1 time.\n",
      "Detecting symmetries...\n",
      "Reduced MIP has 6485 rows, 11585 columns, and 32174 nonzeros.\n",
      "Reduced MIP has 6445 binaries, 5140 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.12 sec. (20.00 ticks)\n",
      "Probing time = 0.05 sec. (1.01 ticks)\n",
      "Clique table members: 666.\n",
      "MIP emphasis: balance optimality and feasibility.\n",
      "MIP search method: dynamic search.\n",
      "Parallel mode: deterministic, using up to 4 threads.\n",
      "Root relaxation solution time = 0.28 sec. (74.82 ticks)\n",
      "\n",
      "        Nodes                                         Cuts/\n",
      "   Node  Left     Objective  IInf  Best Integer    Best Bound    ItCnt     Gap\n",
      "\n",
      "*     0+    0                      1532616.0000      836.0000            99.95%\n",
      "      0     0    10311.3333   213  1532616.0000    10311.3333     3756   99.33%\n",
      "*     0+    0                      1481810.0000    10311.3333            99.30%\n",
      "      0     0    35270.8454   681  1481810.0000     Cuts: 480     6358   97.62%\n",
      "      0     0    42783.1183   998  1481810.0000     Cuts: 424     7970   97.11%\n",
      "      0     0    45814.8681  1157  1481810.0000     Cuts: 356     9272   96.91%\n",
      "*     0+    0                      1453701.0000    45814.8681            96.85%\n",
      "      0     0  -1.00000e+75     0  1453701.0000    45814.8681     9272   96.85%\n",
      "      0     0    47642.6067  1448  1453701.0000     Cuts: 330    10432   96.72%\n",
      "      0     0    48870.4773  1627  1453701.0000     Cuts: 213    11420   96.64%\n",
      "Detecting symmetries...\n",
      "*     0+    0                       154307.0000    48870.4773            68.33%\n",
      "      0     0    49749.5612  1759   154307.0000     Cuts: 220    12217   67.76%\n",
      "*     0+    0                       137468.0000    49749.5612            63.81%\n",
      "      0     0    50475.3368  1602   137468.0000     Cuts: 211    12951   63.28%\n",
      "      0     0    50847.1849  1818   137468.0000     Cuts: 140    13495   63.01%\n",
      "      0     0    51436.0179  1870   137468.0000     Cuts: 129    14158   62.58%\n",
      "      0     0    51683.9496  1829   137468.0000     Cuts: 161    14698   62.40%\n",
      "      0     0    51894.8417  1868   137468.0000     Cuts: 141    15219   62.25%\n",
      "      0     0    51977.8800  1875   137468.0000      Cuts: 88    15597   62.19%\n",
      "      0     0    52218.6834  1910   137468.0000      Cuts: 72    16064   62.01%\n",
      "      0     0    52400.0083  1900   137468.0000      Cuts: 84    16430   61.88%\n",
      "      0     0    52501.6240  1887   137468.0000      Cuts: 94    16696   61.81%\n",
      "      0     0    52798.9066  1810   137468.0000      Cuts: 54    17239   61.59%\n",
      "      0     0    52978.4769  1907   137468.0000      Cuts: 83    17635   61.46%\n",
      "      0     0    53034.0042  1884   137468.0000      Cuts: 70    17921   61.42%\n",
      "      0     0    53168.4926  1947   137468.0000      Cuts: 67    18272   61.32%\n",
      "      0     0    53338.0457  1974   137468.0000      Cuts: 85    18717   61.20%\n",
      "      0     0    53423.0199  2059   137468.0000      Cuts: 91    19072   61.14%\n",
      "      0     0    53535.5858  2010   137468.0000      Cuts: 90    19375   61.06%\n",
      "      0     0    53644.5958  2055   137468.0000      Cuts: 56    19671   60.98%\n",
      "      0     0    53779.1410  2030   137468.0000      Cuts: 47    19928   60.88%\n",
      "      0     0    53828.4533  2053   137468.0000      Cuts: 59    20179   60.84%\n",
      "      0     0    53990.7840  2050   137468.0000      Cuts: 77    20599   60.72%\n",
      "      0     0    54151.5775  2075   137468.0000      Cuts: 85    20916   60.61%\n",
      "      0     0    54229.3842  2071   137468.0000      Cuts: 76    21227   60.55%\n",
      "      0     0    54266.3436  2089   137468.0000      Cuts: 78    21484   60.52%\n",
      "      0     0    54316.8062  2031   137468.0000      Cuts: 69    21802   60.49%\n",
      "      0     0    54345.7597  2082   137468.0000      Cuts: 66    22049   60.47%\n",
      "      0     0    54399.8473  2127   137468.0000      Cuts: 71    22286   60.43%\n",
      "      0     0    54423.7510  2139   137468.0000      Cuts: 45    22470   60.41%\n",
      "*     0+    0                       118659.0000    54423.7510            54.13%\n",
      "      0     0    54637.3887  2184   118659.0000      Cuts: 67    22929   53.95%\n",
      "      0     0    54987.8689  2105   118659.0000     Cuts: 103    23321   53.66%\n",
      "*     0+    0                       106355.0000    54987.8689            48.30%\n",
      "      0     0    55052.2457  2116   106355.0000      Cuts: 79    23608   48.24%\n",
      "      0     0    55066.1880  2185   106355.0000      Cuts: 72    23769   48.22%\n",
      "      0     0    55086.4316  2151   106355.0000      Cuts: 46    23995   48.21%\n",
      "Detecting symmetries...\n",
      "      0     2    55086.4316  2143   106355.0000    55086.4316    23995   48.21%\n",
      "Elapsed time = 41.31 sec. (9802.00 ticks, tree = 0.02 MB, solutions = 10)\n",
      "      4     6    63497.5292  1817   106355.0000    55086.4493    24999   48.21%\n",
      "     10    12    63666.5737  1774   106355.0000    55086.4493    25706   48.21%\n",
      "     16    15    70379.0397  1702   106355.0000    55086.4493    28712   48.21%\n",
      "     24    20    66665.0325  1683   106355.0000    55086.4493    30567   48.21%\n",
      "     29    25    71598.8068  1757   106355.0000    55089.0921    34023   48.20%\n",
      "     33    33    64996.4977  1812   106355.0000    55098.8537    39426   48.19%\n",
      "     43    41    65399.2196  1772   106355.0000    55098.8537    45904   48.19%\n",
      "     63    43    56335.0693  1943   106355.0000    55910.5783    48003   47.43%\n",
      "     74    61    66879.5001  1603   106355.0000    55910.5783    53107   47.43%\n",
      "    128    97    68170.7976  1578   106355.0000    55910.5783    64123   47.43%\n",
      "Elapsed time = 62.25 sec. (14142.48 ticks, tree = 2.14 MB, solutions = 10)\n",
      "    169   160    93440.5649  1362   106355.0000    55910.5783    82643   47.43%\n",
      "    248   209    71519.5777  1517   106355.0000    55910.5783    95978   47.43%\n",
      "*   347+  257                       105846.0000    55910.5783            47.18%\n",
      "    354   314    56135.5582  1908   105846.0000    55910.5783   117216   47.18%\n",
      "    393   365    95351.4147  1111   105846.0000    55910.5783   131327   47.18%\n",
      "    447   403   101401.4666   920   105846.0000    55910.5783   136530   47.18%\n",
      "    503   436    85407.6220  1326   105846.0000    55910.5783   145585   47.18%\n",
      "    545   510    85100.3135  1405   105846.0000    55910.5783   168043   47.18%\n",
      "    582   532    92281.0229  1197   105846.0000    55910.5783   171217   47.18%\n",
      "    644   572    84208.7874  1305   105846.0000    55910.5783   184193   47.18%\n",
      "    700   649    95208.2099  1080   105846.0000    55910.5783   198620   47.18%\n",
      "Elapsed time = 108.86 sec. (23803.92 ticks, tree = 18.96 MB, solutions = 11)\n",
      "    789   681    73060.6285  1733   105846.0000    55910.5783   210946   47.18%\n",
      "    843   768    64937.0355  2029   105846.0000    56109.8569   227195   46.99%\n",
      "    888   783    59087.0467  1845   105846.0000    56109.8569   232696   46.99%\n",
      "    933   857    77766.7739  1504   105846.0000    56109.8569   248494   46.99%\n",
      "    999   880    59926.7416  1732   105846.0000    56109.8569   259324   46.99%\n",
      "   1046   956    85664.9660  1396   105846.0000    56109.8569   273333   46.99%\n",
      "   1192  1100    87117.1104  1321   105846.0000    56109.8569   287422   46.99%\n",
      "   1366  1181   105733.5980   875   105846.0000    56109.8569   291339   46.99%\n",
      "\n",
      "Performing restart 1\n",
      "\n",
      "Repeating presolve.\n",
      "Tried aggregator 1 time.\n",
      "Reduced MIP has 6485 rows, 11585 columns, and 32174 nonzeros.\n",
      "Reduced MIP has 6445 binaries, 5140 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.03 sec. (15.09 ticks)\n",
      "Tried aggregator 1 time.\n",
      "Reduced MIP has 6485 rows, 11585 columns, and 32174 nonzeros.\n",
      "Reduced MIP has 6445 binaries, 5140 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.05 sec. (20.59 ticks)\n",
      "Represolve time = 0.25 sec. (101.23 ticks)\n",
      "   1374     0    63230.7002  1832   105846.0000    Cuts: 1721   318115   40.26%\n",
      "   1374     0    68476.0861  1917   105846.0000    Cuts: 1721   320507   35.31%\n",
      "   1374     0    72644.8100  1991   105846.0000    Cuts: 1721   323082   31.37%\n",
      "   1374     0    74469.4510  1805   105846.0000    Cuts: 1721   325520   29.64%\n",
      "   1374     0    76822.5112  1889   105846.0000    Cuts: 1721   328011   27.42%\n",
      "   1374     0    78085.3845  1755   105846.0000    Cuts: 1721   330147   26.23%\n",
      "   1374     0    79013.0836  1861   105846.0000    Cuts: 1704   331810   25.35%\n",
      "   1374     0    79538.4140  1990   105846.0000    Cuts: 1550   333477   24.85%\n",
      "   1374     0    80290.9403  1746   105846.0000    Cuts: 1524   335178   24.14%\n",
      "   1374     0    80805.9938  1602   105846.0000    Cuts: 1721   336666   23.66%\n",
      "   1374     0    81565.8195  1741   105846.0000    Cuts: 1402   338097   22.94%\n",
      "   1374     0    82298.0170  1892   105846.0000    Cuts: 1576   340062   22.25%\n",
      "   1374     0    82930.0501  1838   105846.0000    Cuts: 1721   342209   21.65%\n",
      "   1374     0    83354.2863  1997   105846.0000    Cuts: 1398   343505   21.25%\n",
      "   1374     0    83705.7287  1875   105846.0000    Cuts: 1316   345231   20.92%\n",
      "   1374     0    83865.7528  1820   105846.0000    Cuts: 1252   346615   20.77%\n",
      "   1374     0    83954.1005  1791   105846.0000    Cuts: 1277   347747   20.68%\n",
      "   1374     0    84042.2445  1809   105846.0000    Cuts: 1148   348758   20.60%\n",
      "   1374     0    84161.3639  1897   105846.0000    Cuts: 1117   350023   20.49%\n",
      "   1374     0    85101.7606  1807   105846.0000    Cuts: 1438   352870   19.60%\n",
      "   1374     0    85641.4477  1766   105846.0000    Cuts: 1530   354718   19.09%\n",
      "   1374     0    85891.2270  1867   105846.0000    Cuts: 1416   356666   18.85%\n",
      "   1374     0    85989.4642  1655   105846.0000     Cuts: 989   357915   18.76%\n",
      "   1374     0    86164.9844  1863   105846.0000     Cuts: 731   359166   18.59%\n",
      "   1374     0    86243.5051  1029   105846.0000     Cuts: 933   359937   18.52%\n",
      "   1374     0    86319.6170  1962   105846.0000     Cuts: 626   360928   18.45%\n",
      "   1374     0    86351.0505  1872   105846.0000    Cuts: 1022   361894   18.42%\n",
      "   1374     0    86384.9049  1892   105846.0000     Cuts: 686   362671   18.39%\n",
      "   1374     0    86419.0832  1869   105846.0000     Cuts: 701   363475   18.35%\n",
      "   1374     0    86431.4893  1847   105846.0000     Cuts: 702   364029   18.34%\n",
      "   1374     0    86446.0746  1757   105846.0000     Cuts: 526   365064   18.33%\n",
      "   1374     0    86462.0525  1809   105846.0000    Cuts: 1357   366072   18.31%\n",
      "   1374     0    86485.2744  1811   105846.0000     Cuts: 534   366756   18.29%\n",
      "   1374     0    86494.5234  1872   105846.0000    Cuts: 1200   367577   18.28%\n",
      "   1374     0    86531.3798  1767   105846.0000     Cuts: 627   368636   18.25%\n",
      "   1374     0    86539.8889  1705   105846.0000     Cuts: 966   369387   18.24%\n",
      "   1374     0    86545.0543  1739   105846.0000     Cuts: 671   369951   18.23%\n",
      "   1374     2    86545.0543  1630   105846.0000    86545.0543   369951   18.23%\n",
      "   1384    11    93511.2359  1431   105846.0000    86554.6738   373633   18.23%\n",
      "Elapsed time = 357.09 sec. (80387.99 ticks, tree = 0.03 MB, solutions = 11)\n",
      "   1399    27    90724.9045  1521   105846.0000    86554.6738   386854   18.23%\n",
      "   1426    49    86665.7553  1165   105846.0000    86554.6738   394998   18.23%\n",
      "   1478    99    95753.1588  1315   105846.0000    86554.6738   401295   18.23%\n",
      "   1492   115    88950.9508  1662   105846.0000    86554.6738   413052   18.23%\n",
      "   1513   127    89183.9412  1647   105846.0000    86554.6738   425788   18.23%\n",
      "   1545   151    98456.9346  1605   105846.0000    86554.6738   445290   18.23%\n",
      "   1612   206    89633.7986  1426   105846.0000    86554.6738   460865   18.23%\n",
      "   1651   258    89959.8805  1135   105846.0000    86554.6738   472802   18.23%\n",
      "   1694   277    92516.3034  1530   105846.0000    86554.6738   478437   18.23%\n",
      "   1728   302    90303.0030  1107   105846.0000    86554.6738   486266   18.23%\n",
      "Elapsed time = 403.38 sec. (90085.60 ticks, tree = 11.38 MB, solutions = 11)\n",
      "   1765   368   104014.6921  1422   105846.0000    86554.6738   496912   18.23%\n",
      "   1831   406   104158.5430  1455   105846.0000    86554.6738   504274   18.23%\n",
      "   1883   468    90866.7920   801   105846.0000    86554.6738   518806   18.23%\n",
      "   1917   517    91054.3882  1104   105846.0000    86554.6738   529535   18.23%\n",
      "   1991   528    93593.0560  1052   105846.0000    86554.6738   535626   18.23%\n",
      "   2035   563    93828.3053  1176   105846.0000    86554.6738   543735   18.23%\n",
      "   2071   659    95478.9996  1365   105846.0000    86554.6738   559820   18.23%\n",
      "   2123   710   103190.5824  1375   105846.0000    86554.6738   571821   18.23%\n",
      "   2198   719    92295.6001  1008   105846.0000    86554.6738   575766   18.23%\n",
      "   2239   746    92472.2689   770   105846.0000    86554.6738   578930   18.23%\n",
      "Elapsed time = 450.72 sec. (99791.86 ticks, tree = 39.54 MB, solutions = 11)\n",
      "   2264   824    90049.2357  1313   105846.0000    86554.6738   602927   18.23%\n",
      "   2286   838    90483.5617  1274   105846.0000    86554.6738   616321   18.23%\n",
      "   2318   869    92832.0463   784   105846.0000    86554.6738   624732   18.23%\n",
      "   2363   868    90880.7312  1312   105846.0000    86554.6738   628792   18.23%\n",
      "   2427   950    91193.7961   922   105846.0000    86554.6738   654237   18.23%\n",
      "   2483  1025    91452.8229   836   105846.0000    86554.6738   669416   18.23%\n",
      "   2559  1061    93572.8926   829   105846.0000    86554.6738   676017   18.23%\n",
      "   2634  1149    91603.1297  1315   105846.0000    86554.6738   689397   18.23%\n",
      "   2701  1179   100538.6063  1405   105846.0000    86554.6738   696191   18.23%\n",
      "   2776  1227    93941.8407  1185   105846.0000    86554.6738   702854   18.23%\n",
      "Elapsed time = 498.09 sec. (109440.30 ticks, tree = 69.63 MB, solutions = 11)\n",
      "   2864  1300   102386.6944  1036   105846.0000    86554.6738   713121   18.23%\n",
      "   2929  1410   105166.2578  1171   105846.0000    86554.6738   724670   18.23%\n",
      "   2967  1440   102393.2232  1399   105846.0000    86554.6738   732218   18.23%\n",
      "   3017  1542    98446.6437   691   105846.0000    86554.6738   751299   18.23%\n",
      "   3082  1564    95624.3799   894   105846.0000    86554.6738   756671   18.23%\n",
      "   3158  1614    96733.6476  1324   105846.0000    86554.6738   768084   18.23%\n",
      "   3180  1713   104607.0807   633   105846.0000    86554.6738   788642   18.23%\n",
      "   3217  1731    98000.5883  1031   105846.0000    86554.6738   791918   18.23%\n",
      "   3279  1798    97413.3913   962   105846.0000    86554.6738   808883   18.23%\n",
      "   3358  1814    90458.3058  1514   105846.0000    86554.6738   820583   18.23%\n",
      "Elapsed time = 547.36 sec. (119189.85 ticks, tree = 97.26 MB, solutions = 11)\n",
      "   3442  1903    89255.0123  1168   105846.0000    86554.6738   833888   18.23%\n",
      "   3575  1934    90298.9545   981   105846.0000    86554.6738   837476   18.23%\n",
      "   3663  2103    91899.3270  1356   105846.0000    86618.9843   857404   18.17%\n",
      "   3730  2140    93579.4269  1180   105846.0000    86618.9843   860818   18.17%\n",
      "   3797  2168    90273.8116  1185   105846.0000    86618.9843   873529   18.17%\n",
      "   3842  2258    91076.0312   823   105846.0000    86618.9843   884475   18.17%\n",
      "   3867  2361    91116.7494  1274   105846.0000    86666.3810   903831   18.12%\n",
      "   3887  2369    92243.8407   950   105846.0000    86666.3810   908200   18.12%\n",
      "   3931  2391    91993.6142  1393   105846.0000    86666.3810   911090   18.12%\n",
      "   3995  2452    90347.6335  1181   105846.0000    86666.3810   934367   18.12%\n",
      "Elapsed time = 596.81 sec. (129103.92 ticks, tree = 135.29 MB, solutions = 11)\n",
      "   4084  2511    93039.3703  1386   105846.0000    86666.3810   941564   18.12%\n",
      "   4173  2571    97038.4919  1241   105846.0000    86666.3810   953184   18.12%\n",
      "   4315  2602    94928.8997  1358   105846.0000    86666.3810   956363   18.12%\n",
      "   4403  2778   102528.0572  1234   105846.0000    86678.4266   976926   18.11%\n",
      "   4491  2801    87321.8151  1266   105846.0000    86678.4266   982317   18.11%\n",
      "   4511  2804    90690.3054  1107   105846.0000    86678.4266   985539   18.11%\n",
      "   4530  3001    87950.6180  1474   105846.0000    86760.5492  1005101   18.03%\n",
      "   4548  3008    89290.0536  1649   105846.0000    86819.7009  1012712   17.98%\n",
      "   4565  3023    95886.8863  1355   105846.0000    86819.7009  1025891   17.98%\n",
      "   4596  3074    90298.9875  1132   105846.0000    86819.7009  1039444   17.98%\n",
      "Elapsed time = 644.91 sec. (138845.92 ticks, tree = 155.27 MB, solutions = 11)\n",
      "   4623  3060    91193.2178  1180   105846.0000    86819.7009  1048456   17.98%\n",
      "   4645  3065    95602.7987   954   105846.0000    86819.7009  1055647   17.98%\n",
      "   4669  3123    88300.1450  1344   105846.0000    86819.7009  1072332   17.98%\n",
      "   4696  3161    88693.9871  1709   105846.0000    86819.7009  1095223   17.98%\n",
      "   4715  3140    92445.1054  1105   105846.0000    86819.7009  1080192   17.98%\n",
      "   4753  3187    91585.1635  1325   105846.0000    86819.7009  1104654   17.98%\n",
      "   4790  3228    94319.4468  1075   105846.0000    86819.7009  1124296   17.98%\n",
      "   4834  3263    91603.5517  1013   105846.0000    86819.7009  1134852   17.98%\n",
      "   4874  3313    93013.0455   910   105846.0000    86819.7009  1153867   17.98%\n",
      "   5032  3470   104867.8888   919   105846.0000    86819.7009  1194680   17.98%\n",
      "Elapsed time = 707.72 sec. (151552.54 ticks, tree = 180.22 MB, solutions = 11)\n",
      "   5225  3617    97226.0727   793   105846.0000    86997.3484  1238543   17.81%\n",
      "   5398  3752    91248.8134  1162   105846.0000    86997.3484  1267946   17.81%\n",
      "   5661  3881    88188.1097  1459   105846.0000    87102.2459  1293778   17.71%\n",
      "   5977  4291    93310.3487   815   105846.0000    87102.2459  1339677   17.71%\n",
      "   6398  4630    92601.2745   790   105846.0000    87102.2459  1383331   17.71%\n",
      "   6583  4885    90318.9834  1579   105846.0000    87143.3218  1419789   17.67%\n",
      "   6925  5193    92257.4013  1531   105846.0000    87154.8487  1467589   17.66%\n",
      "   7239  5530    95987.8563  1623   105846.0000    87200.1944  1517962   17.62%\n",
      "   7617  5769   100032.8936   907   105846.0000    87248.9696  1549330   17.57%\n",
      "   7894  6210    97259.7517  1424   105846.0000    87249.1072  1605530   17.57%\n",
      "Elapsed time = 887.36 sec. (189896.34 ticks, tree = 317.59 MB, solutions = 11)\n",
      "   8064  6366    97628.6714  1702   105846.0000    87249.8149  1653498   17.57%\n",
      "   8287  6585    96728.7425   824   105846.0000    87249.8149  1707383   17.57%\n",
      "   8478  6712    97018.0658   830   105846.0000    87267.1524  1738136   17.55%\n",
      "   8728  6938    95710.3898  1723   105846.0000    87273.4827  1781532   17.55%\n",
      "   9029  7179   103084.7381  1719   105846.0000    87310.7210  1828037   17.51%\n",
      "   9223  7479   103425.6854   741   105846.0000    87319.1382  1877963   17.50%\n",
      "   9530  7731    96924.2606  1549   105846.0000    87321.8744  1933335   17.50%\n",
      "   9839  7979   103197.1085  1067   105846.0000    87339.9330  1966844   17.48%\n",
      "  10058  8251    91011.7068  1923   105846.0000    87361.6732  2018844   17.46%\n",
      "  10317  8561    88341.8099  1205   105846.0000    87372.8731  2073413   17.45%\n",
      "Elapsed time = 1076.14 sec. (228210.55 ticks, tree = 432.86 MB, solutions = 11)\n",
      "  10602  8770   103444.6362  1097   105846.0000    87372.8731  2107779   17.45%\n",
      "  10809  8982    93389.5292  1406   105846.0000    87389.1163  2154897   17.44%\n",
      "  10983  9166    96331.6901  1145   105846.0000    87389.1163  2205282   17.44%\n",
      "  11266  9290    94734.1035  1526   105846.0000    87397.6792  2238121   17.43%\n",
      "  11508  9645    91082.5748  1661   105846.0000    87397.6792  2316279   17.43%\n",
      "  11672  9860    92792.3757  1523   105846.0000    87424.8164  2366054   17.40%\n",
      "  11922 10120    94312.4837  1367   105846.0000    87424.8164  2416803   17.40%\n",
      "  12098 10235    97375.0599  1244   105846.0000    87424.8164  2438430   17.40%\n",
      "  12383 10419    93045.3031  1782   105846.0000    87424.8164  2487101   17.40%\n",
      "  12701 10619    88312.8342  1261   105846.0000    87445.9213  2525226   17.38%\n",
      "Elapsed time = 1265.33 sec. (266493.30 ticks, tree = 542.97 MB, solutions = 11)\n",
      "  12813 10845    90811.9084  1235   105846.0000    87453.9257  2567054   17.38%\n",
      "  12990 11089   102109.1530  1321   105846.0000    87496.2153  2644598   17.34%\n",
      "  13239 11209    95409.8726  1282   105846.0000    87496.6231  2664027   17.34%\n",
      "  13577 11367    91509.6202  1905   105846.0000    87500.6551  2710547   17.33%\n",
      "* 13669+11567                       105700.0000    87500.6551            17.22%\n",
      "* 13669+11567                       105370.0000    87500.6551            16.96%\n",
      "* 13676+11567                       104739.0000    87500.6551            16.46%\n",
      "  13746 11785    93444.1611  1705   104739.0000    87519.7504  2765341   16.44%\n",
      "  13943 11536   100474.6897  1607   104739.0000    87519.7504  2813860   16.44%\n",
      "  14140 11723   101143.9352  1428   104739.0000    87572.6266  2862157   16.39%\n",
      "  14268 11794    93253.9249  1830   104739.0000    87587.8773  2883937   16.38%\n",
      "  14428 11992    95469.6552  1130   104739.0000    87587.8773  2943390   16.38%\n",
      "  14585 12192   102036.4795  1672   104739.0000    87587.8773  3013003   16.38%\n",
      "Elapsed time = 1461.09 sec. (304880.68 ticks, tree = 635.78 MB, solutions = 14)\n",
      "  14804 12349    94816.8464   817   104739.0000    87610.6128  3061573   16.35%\n",
      "  15070 12390    89263.0531  1422   104739.0000    87624.2085  3080096   16.34%\n",
      "  15257 12767   104727.6540   841   104739.0000    87631.3909  3158356   16.33%\n",
      "  15401 12809    99391.2081  1608   104739.0000    87631.3909  3154224   16.33%\n",
      "  15547 13091    90610.7951  1596   104739.0000    87631.3909  3232129   16.33%\n",
      "  15716 13131    97469.6345  1137   104739.0000    87631.3909  3257105   16.33%\n",
      "  15913 13360   102885.4909   989   104739.0000    87631.3909  3332273   16.33%\n",
      "  16127 13607    88530.6954  1768   104739.0000    87637.7301  3383602   16.33%\n",
      "  16339 13828   101675.1545  1507   104739.0000    87681.6172  3434717   16.29%\n",
      "  16598 13961    91543.6642  1011   104739.0000    87699.9958  3466763   16.27%\n",
      "Elapsed time = 1640.97 sec. (343256.49 ticks, tree = 760.54 MB, solutions = 14)\n",
      "  16769 14026    97169.6888   927   104739.0000    87733.5380  3479280   16.24%\n",
      "  17157 14377    88713.0634  1200   104739.0000    87733.6314  3538861   16.24%\n",
      "  17338 14496    99984.9022  1008   104739.0000    87758.9866  3567226   16.21%\n",
      "  17650 14658    94127.3776  1454   104739.0000    87770.2580  3598209   16.20%\n",
      "  17822 15297    92567.2553  1653   104739.0000    87811.0094  3694326   16.16%\n",
      "  17915 15236    94124.2032  1651   104739.0000    87811.0094  3689635   16.16%\n",
      "  18073 15537   101707.2048  1623   104739.0000    87829.7023  3759582   16.14%\n",
      "  18191 15520    96112.2685  1379   104739.0000    87839.3443  3776861   16.14%\n",
      "  18317 15749    98337.4945  1560   104739.0000    87866.7822  3846347   16.11%\n",
      "  18532 15800   102188.9702   840   104739.0000    87866.7822  3864621   16.11%\n",
      "Elapsed time = 1817.77 sec. (381578.95 ticks, tree = 893.74 MB, solutions = 14)\n",
      "  18743 16084   102092.5703   959   104739.0000    87866.7822  3938452   16.11%\n",
      "  18882 16202    98848.6262  1903   104739.0000    87875.8613  3970804   16.10%\n",
      "  19045 16281    97640.9640  1753   104739.0000    87907.9546  4002041   16.07%\n",
      "  19203 16460    94015.8572  1285   104739.0000    87922.5835  4055528   16.06%\n",
      "  19340 16617    96665.8912  1936   104739.0000    87922.5835  4108792   16.06%\n",
      "  19529 16758   104125.7471  1108   104739.0000    87947.8712  4140904   16.03%\n",
      "  19735 16951   102394.5039  1486   104739.0000    87947.8712  4191439   16.03%\n",
      "  19964 17001    91003.2599  1284   104739.0000    87964.8133  4202752   16.02%\n",
      "  20172 17389    99248.5643   913   104739.0000    87988.0256  4298333   15.99%\n",
      "  20425 17584    96860.6669   984   104739.0000    87988.0256  4331160   15.99%\n",
      "Elapsed time = 1997.33 sec. (419987.72 ticks, tree = 929.74 MB, solutions = 14)\n",
      "  20685 17862    90786.8098  1742   104739.0000    87989.3700  4408183   15.99%\n",
      "  20818 17754   101026.0161  1249   104739.0000    88006.4333  4399725   15.98%\n",
      "  21041 18336    98163.6942  1277   104739.0000    88034.3070  4496953   15.95%\n",
      "  21235 18381   103726.1012   891   104739.0000    88034.3070  4531202   15.95%\n",
      "  21378 18470    99345.4844  1165   104739.0000    88072.9715  4548025   15.91%\n",
      "  21525 18719    98544.8728  1408   104739.0000    88072.9715  4618845   15.91%\n",
      "  21674 18808    93788.9843  1762   104739.0000    88080.0885  4643790   15.91%\n",
      "  21799 18972    91159.3015  1990   104739.0000    88080.0885  4686266   15.91%\n",
      "  21977 19105   102068.9481  1148   104739.0000    88084.4479  4725345   15.90%\n",
      "  22155 19232   100105.9981  1102   104739.0000    88084.4479  4776288   15.90%\n",
      "Elapsed time = 2176.80 sec. (458368.09 ticks, tree = 999.61 MB, solutions = 14)\n",
      "  22321 19459    94222.5619  1429   104739.0000    88084.5252  4835382   15.90%\n",
      "  22442 19485    96566.7938  1583   104739.0000    88090.1673  4847479   15.90%\n",
      "  22638 19531    99042.2025  1092   104739.0000    88090.1673  4858386   15.90%\n",
      "  22809 19787    97321.2622  1437   104739.0000    88096.4501  4916938   15.89%\n",
      "  23030 19880    93205.0379  1084   104739.0000    88096.4501  4947706   15.89%\n",
      "  23224 20232    96257.9437  1513   104739.0000    88144.1796  5055485   15.84%\n",
      "  23440 20153   104389.8671  1330   104739.0000    88144.1796  5022112   15.84%\n",
      "  23647 20513    96469.2910  1041   104739.0000    88144.7700  5110013   15.84%\n",
      "  23828 20569   104535.9285   658   104739.0000    88144.7700  5122729   15.84%\n",
      "* 23876+20922                       104614.0000    88178.2510            15.71%\n",
      "* 23878+20922                       104370.0000    88178.2510            15.51%\n",
      "  23982 20779   102455.4863   373   104370.0000    88188.5146  5255351   15.50%\n",
      "Elapsed time = 2361.03 sec. (496689.77 ticks, tree = 1119.32 MB, solutions = 16)\n",
      "* 24128+20649                       104262.0000    88188.5146            15.42%\n",
      "  24137 20767    92928.8385  1104   104262.0000    88188.5146  5293110   15.42%\n",
      "  24304 20827   101433.3514   848   104262.0000    88188.5146  5304350   15.42%\n",
      "  24458 20837    95730.5017  1317   104262.0000    88188.5146  5327944   15.42%\n",
      "  24610 21000    90227.0044  1309   104262.0000    88194.4213  5386822   15.41%\n",
      "  24679 21287    92640.2574  1502   104262.0000    88213.0076  5466721   15.39%\n",
      "* 24811+21199                       103051.0000    88214.9470            14.40%\n",
      "* 24812+21199                       102943.0000    88214.9470            14.31%\n",
      "  24821 21396   102236.8899   861   102943.0000    88214.9470  5478323   14.31%\n",
      "  24877 21386    91451.3863  1961   102943.0000    88214.9470  5501304   14.31%\n",
      "  24918 19717    91836.2635  1464   102943.0000    88214.9470  5506966   14.31%\n",
      "\n",
      "Performing restart 2\n",
      "\n",
      "Repeating presolve.\n",
      "Tried aggregator 1 time.\n",
      "MIP Presolve eliminated 1389 rows and 2455 columns.\n",
      "Reduced MIP has 5096 rows, 9130 columns, and 25387 nonzeros.\n",
      "Reduced MIP has 5110 binaries, 4020 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.20 sec. (13.50 ticks)\n",
      "Tried aggregator 1 time.\n",
      "Reduced MIP has 5096 rows, 9130 columns, and 25387 nonzeros.\n",
      "Reduced MIP has 5110 binaries, 4020 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.03 sec. (16.24 ticks)\n",
      "Represolve time = 6.27 sec. (314.74 ticks)\n",
      "  24920     0    86903.7647  1627   102943.0000     Cuts: 295  5572690   14.30%\n",
      "  24920     0    86943.0344  1649   102943.0000     Cuts: 176  5573770   14.30%\n",
      "  24920     0    86990.9417  1673   102943.0000    Cuts: 1318  5575130   14.30%\n",
      "  24920     0    87095.5018  1802   102943.0000    Cuts: 1030  5576624   14.30%\n",
      "  24920     0    87123.3332  1846   102943.0000     Cuts: 849  5577661   14.30%\n",
      "  24920     0    87146.8748  1825   102943.0000     Cuts: 886  5578730   14.30%\n",
      "  24920     0    87180.7792  1846   102943.0000    Cuts: 1287  5580202   14.30%\n",
      "  24920     2    87180.7792  1777   102943.0000    88221.5848  5580202   14.30%\n",
      "  24983    60    96626.4811  1056   102943.0000    88221.5848  5610770   14.30%\n",
      "Elapsed time = 27202.75 sec. (550628.95 ticks, tree = 1.00 MB, solutions = 20)\n",
      "  25116   142    90904.0912   946   102943.0000    88221.5848  5653210   14.30%\n",
      "  25273   277    99594.7535  1624   102943.0000    88221.5848  5696814   14.30%\n",
      "  25457   489    90659.2963  1837   102943.0000    88221.5848  5756138   14.30%\n",
      "  25611   601   102832.1024  1490   102943.0000    88221.5848  5792027   14.30%\n",
      "  25767   749    97981.4648  1446   102943.0000    88221.5848  5848536   14.30%\n",
      "  26040  1018    96353.9103  1547   102943.0000    88221.5848  5907566   14.30%\n",
      "  26434  1362    95884.3331  1303   102943.0000    88221.5848  5956024   14.30%\n",
      "  26768  1655    91090.4610  1059   102943.0000    88221.5848  5997920   14.30%\n",
      "  26962  1871    90478.0203   985   102943.0000    88221.5848  6047726   14.30%\n",
      "  27324  2131    91262.8442  1178   102943.0000    88221.5848  6095169   14.30%\n",
      "Elapsed time = 27351.66 sec. (588985.42 ticks, tree = 92.73 MB, solutions = 20)\n",
      "  27500  2414    92620.2073  1274   102943.0000    88221.5848  6143249   14.30%\n",
      "  27904  2631   100582.3536  1200   102943.0000    88221.5848  6181480   14.30%\n",
      "  28075  2968   100207.3782  1346   102943.0000    88221.5848  6249888   14.30%\n",
      "  28268  3117    93358.5089  1330   102943.0000    88221.5848  6297282   14.30%\n",
      "  28446  3286    94354.9117  1966   102943.0000    88221.5848  6339906   14.30%\n",
      "  28668  3428    93363.2369  1277   102943.0000    88221.5848  6385338   14.30%\n",
      "  28914  3750    93980.5825  1708   102943.0000    88221.5848  6444883   14.30%\n",
      "  29145  3879    91183.2285  1173   102943.0000    88221.5848  6473796   14.30%\n",
      "  29315  4123    92122.5528  1442   102943.0000    88237.3902  6523123   14.29%\n",
      "  29592  4291   100469.7143  1772   102943.0000    88258.3695  6561655   14.26%\n",
      "Elapsed time = 27505.64 sec. (627291.22 ticks, tree = 208.84 MB, solutions = 20)\n",
      "  29883  4567   100864.4493  1150   102943.0000    88267.5338  6602679   14.26%\n",
      "  30315  4936    90347.2847  1142   102943.0000    88365.6585  6659106   14.16%\n",
      "  30554  5219    94418.9684  1092   102943.0000    88423.7185  6697569   14.10%\n",
      "  31036  5560    95903.6099  1325   102943.0000    88430.8937  6759705   14.10%\n",
      "  31333  5960    97108.9660  1703   102943.0000    88535.4372  6804053   14.00%\n",
      "  31766  6324    98647.8487  1198   102943.0000    88538.9631  6865849   13.99%\n",
      "  31951  6638    96981.4030  1500   102943.0000    88612.8823  6899105   13.92%\n",
      "  32151  6871   102387.4003   799   102943.0000    88654.2894  6959438   13.88%\n",
      "  32305  6974    92511.5966  1412   102943.0000    88673.4656  6999358   13.86%\n",
      "  32515  7241    98975.3045  1327   102943.0000    88674.7729  7058402   13.86%\n",
      "Elapsed time = 27664.20 sec. (665584.87 ticks, tree = 371.35 MB, solutions = 20)\n",
      "  32750  7394    99307.8552  1071   102943.0000    88674.7729  7093133   13.86%\n",
      "  32999  7529    97547.5183  1695   102943.0000    88674.7729  7136812   13.86%\n",
      "  33151  7760    92185.1807  1465   102943.0000    88697.9185  7188525   13.84%\n",
      "  33503  7965    98139.1170   911   102943.0000    88710.8707  7217724   13.83%\n",
      "  33790  8256    96492.9730  1661   102943.0000    88725.5340  7284764   13.81%\n",
      "  33948  8602    99402.3906  1853   102943.0000    88827.0000  7358473   13.71%\n",
      "  34208  8709   101730.4955  1319   102943.0000    88827.0000  7387759   13.71%\n",
      "  34459  8905    95885.0290  1318   102943.0000    88881.9034  7432080   13.66%\n",
      "  34765  9276   101098.1853  1390   102943.0000    88883.4527  7508275   13.66%\n",
      "  35012  9467    93543.5893  1172   102943.0000    88968.9537  7546798   13.57%\n",
      "Elapsed time = 27826.81 sec. (703882.80 ticks, tree = 497.53 MB, solutions = 20)\n",
      "  35340  9778   101788.2560   866   102943.0000    88992.9238  7609944   13.55%\n",
      "  35496  9943   101209.6325  1083   102943.0000    88992.9238  7641128   13.55%\n",
      "  35725 10101    95829.8374  1287   102943.0000    89123.7799  7681121   13.42%\n",
      "  35923 10331    96824.3593  1029   102943.0000    89149.1715  7754246   13.40%\n",
      "  36287 10576    99620.1262   593   102943.0000    89149.1715  7807100   13.40%\n",
      "  36477 10814    98074.2427  1526   102943.0000    89149.1715  7852129   13.40%\n",
      "  36600 10976    98063.5346  1418   102943.0000    89268.9499  7884933   13.28%\n",
      "  36748 11053    97217.3168  1382   102943.0000    89268.9499  7926838   13.28%\n",
      "  37030 11224    99787.0287  1414   102943.0000    89316.3092  7982871   13.24%\n",
      "* 37228+11235                       101898.0000    89316.3092            12.35%\n",
      "  37318 11527    91462.1801  1888   101898.0000    89316.3092  8038738   12.35%\n",
      "Elapsed time = 27996.91 sec. (742343.04 ticks, tree = 578.32 MB, solutions = 21)\n",
      "  37585 11083   100667.7262  1365   101898.0000    89316.3092  8071603   12.35%\n",
      "  37741 11470   101533.6002   955   101898.0000    89352.4839  8151840   12.31%\n",
      "  37935 11677    94645.6364  1275   101898.0000    89386.6230  8212993   12.28%\n",
      "  38086 11777    97688.0185  1318   101898.0000    89390.7965  8236881   12.27%\n",
      "  38337 11816    95044.4920  1240   101898.0000    89390.7965  8268880   12.27%\n",
      "  38542 12120    97881.5519  1226   101898.0000    89398.0583  8342654   12.27%\n",
      "  38701 12251    98286.2782  1245   101898.0000    89402.4376  8367330   12.26%\n",
      "  38875 12373    99786.1227  1788   101898.0000    89402.9572  8399994   12.26%\n",
      "  38967 12580    98359.9404  1833   101898.0000    89413.9856  8478379   12.25%\n",
      "  39103 12672    94988.0805  1602   101898.0000    89420.4431  8515544   12.25%\n",
      "Elapsed time = 28161.22 sec. (780556.90 ticks, tree = 636.27 MB, solutions = 21)\n",
      "  39226 12786    93250.3926  1503   101898.0000    89431.7315  8564529   12.23%\n",
      "  39382 12930    95986.2583  1394   101898.0000    89433.6429  8620444   12.23%\n",
      "  39556 13095    95989.3510  1336   101898.0000    89440.0116  8672340   12.23%\n",
      "  39738 13348   100632.6578  1163   101898.0000    89450.9382  8734057   12.22%\n",
      "  39925 13412    96565.7060  1365   101898.0000    89465.3815  8755788   12.20%\n",
      "  40057 13587    98000.8701  1783   101898.0000    89485.1116  8804469   12.18%\n",
      "  40234 13766    97625.3443  1403   101898.0000    89488.2388  8856051   12.18%\n",
      "  40416 13900    97722.2889  1058   101898.0000    89499.2254  8893864   12.17%\n",
      "  40577 13934        cutoff         101898.0000    89503.3233  8920167   12.16%\n",
      "  40704 14137    98019.7353  1821   101898.0000    89505.9573  8967005   12.16%\n",
      "Elapsed time = 28325.55 sec. (818883.82 ticks, tree = 726.64 MB, solutions = 21)\n",
      "  40831 14330    98140.0048   858   101898.0000    89519.7343  9025603   12.15%\n",
      "  41053 14503   100467.2793   777   101898.0000    89519.7343  9088369   12.15%\n",
      "  41144 14505    93228.1685  1366   101898.0000    89526.4439  9108401   12.14%\n",
      "  41280 14757    97091.9352  1261   101898.0000    89610.4511  9175628   12.06%\n",
      "  41489 14822    99097.3912   965   101898.0000    89610.4511  9196390   12.06%\n",
      "  41599 14967    92673.5483  1402   101898.0000    89621.9672  9242510   12.05%\n",
      "  41691 15118    95302.4343  1402   101898.0000    89624.4648  9298191   12.04%\n",
      "  41832 15229    99220.1367  1164   101898.0000    89624.4648  9328127   12.04%\n",
      "  41951 15354    92583.2678  1870   101898.0000    89635.9591  9400435   12.03%\n",
      "  42071 15358   101324.8937  1648   101898.0000    89640.3606  9395794   12.03%\n",
      "Elapsed time = 28488.94 sec. (857171.98 ticks, tree = 793.30 MB, solutions = 21)\n",
      "  42140 15608   100587.3971  1302   101898.0000    89641.4171  9508823   12.03%\n",
      "  42213 15547   100742.9229  1375   101898.0000    89641.4171  9481721   12.03%\n",
      "  42331 15692   101259.8406  1581   101898.0000    89641.4171  9575272   12.03%\n",
      "  42431 15758    94449.7107  1439   101898.0000    89650.0049  9607506   12.02%\n",
      "  42582 15821    99759.6392   948   101898.0000    89679.6959  9627366   11.99%\n",
      "  42779 15918   101550.5113   846   101898.0000    89679.6959  9674492   11.99%\n",
      "  42864 16029    98953.5895  1663   101898.0000    89679.7414  9724477   11.99%\n",
      "  43032 16234    96578.4403  1760   101898.0000    89682.9820  9778064   11.99%\n",
      "  43139 16378    97842.9688  1959   101898.0000    89682.9972  9828732   11.99%\n",
      "  43273 16441    94907.6608  1233   101898.0000    89682.9972  9859623   11.99%\n",
      "Elapsed time = 28655.66 sec. (895626.95 ticks, tree = 847.34 MB, solutions = 21)\n",
      "  43464 16710    98786.2870  1007   101898.0000    89722.9454  9940807   11.95%\n",
      "  43703 16751    99524.4827  1646   101898.0000    89742.0693  9965268   11.93%\n",
      "  43857 17104    94387.7625  1066   101898.0000    89745.2140 10030384   11.93%\n",
      "  43917 17147    96322.5334  1868   101898.0000    89745.2140 10054357   11.93%\n",
      "  44002 17291    99666.3306   785   101898.0000    89757.6851 10122383   11.91%\n",
      "  44140 17273    95826.5447  1277   101898.0000    89757.6851 10111938   11.91%\n",
      "  44254 17414    99403.2145  1211   101898.0000    89759.6087 10193856   11.91%\n",
      "  44563 17473   101751.5169  1870   101898.0000    89767.8570 10226776   11.90%\n",
      "  44658 17818    97128.8736   949   101898.0000    89780.6384 10306709   11.89%\n",
      "  44829 17673   100756.1164  1765   101898.0000    89787.1348 10273751   11.89%\n",
      "Elapsed time = 28825.84 sec. (934063.12 ticks, tree = 918.73 MB, solutions = 21)\n",
      "  44894 18042    97910.9917  1406   101898.0000    89790.9573 10382717   11.88%\n",
      "  44989 18104    99308.9024  1816   101898.0000    89795.8145 10417750   11.88%\n",
      "  45057 18159    90693.7422  1454   101898.0000    89797.6325 10440554   11.87%\n",
      "  45135 18175    98780.2804  1591   101898.0000    89797.6325 10452185   11.87%\n",
      "  45256 18311   101226.1282  1184   101898.0000    89821.1614 10504930   11.85%\n",
      "  45329 18301    97987.3585  1279   101898.0000    89826.2996 10555906   11.85%\n",
      "  45387 18480   101008.4505  1632   101898.0000    89826.2996 10627933   11.85%\n",
      "  45478 18553    97961.5433  1053   101898.0000    89850.4045 10669739   11.82%\n",
      "  45610 18595    98046.7022  1458   101898.0000    89850.4045 10723307   11.82%\n",
      "  45763 18662    98270.4633  1131   101898.0000    89850.4045 10752526   11.82%\n",
      "Elapsed time = 38240.55 sec. (972941.39 ticks, tree = 947.55 MB, solutions = 21)\n",
      "  45916 18751   100044.5663  1305   101898.0000    89865.7853 10775477   11.81%\n",
      "  46004 18798    99646.9386  1809   101898.0000    89865.8019 10809098   11.81%\n",
      "  46096 19126    92787.0544  1443   101898.0000    89875.6059 10921263   11.80%\n",
      "  46174 19112    98007.0882  1576   101898.0000    89875.6059 10909850   11.80%\n",
      "  46300 19152    95972.0212  1255   101898.0000    89887.1018 10942598   11.79%\n",
      "  46354 19324    98817.8552  1401   101898.0000    89887.1018 11030574   11.79%\n",
      "  46477 19423   100021.2653  2018   101898.0000    89887.1018 11057086   11.79%\n",
      "  46629 19564        cutoff         101898.0000    89887.1018 11129934   11.79%\n",
      "  46724 19495    96553.1846  1178   101898.0000    89906.8888 11114294   11.77%\n",
      "  46806 19704    99453.6040  1278   101898.0000    89920.1105 11208461   11.75%\n",
      "Elapsed time = 38451.19 sec. (1011380.86 ticks, tree = 1012.11 MB, solutions = 21)\n",
      "  46898 19798   101842.3452  1714   101898.0000    89920.1105 11241263   11.75%\n",
      "  46961 19727    94991.7843  1783   101898.0000    89951.0265 11229849   11.72%\n",
      "  47049 19946   101071.7595  1561   101898.0000    89951.0265 11338728   11.72%\n",
      "  47128 19886    90515.3084  2033   101898.0000    89968.9727 11324566   11.71%\n",
      "  47277 20082    96147.9904  1420   101898.0000    89985.8448 11439639   11.69%\n",
      "  47355 20118    98804.8285  1496   101898.0000    89991.5116 11451005   11.68%\n",
      "  47469 20217    96961.5889  1468   101898.0000    90004.3991 11476323   11.67%\n",
      "  47569 20291    99908.9157  1649   101898.0000    90015.8341 11527528   11.66%\n",
      "  47660 20404   100256.3641  1303   101898.0000    90015.9968 11567956   11.66%\n",
      "  47753 20475   100768.0147  1343   101898.0000    90015.9968 11595415   11.66%\n",
      "Elapsed time = 38659.95 sec. (1049986.03 ticks, tree = 1032.64 MB, solutions = 21)\n",
      "  47818 20505   100926.9666  1485   101898.0000    90015.9968 11629659   11.66%\n",
      "  47910 20620    98664.1066  1320   101898.0000    90047.3446 11690285   11.63%\n",
      "  47993 20674    96289.7609  1183   101898.0000    90048.3460 11717957   11.63%\n",
      "  48122 20806    94204.7409  1772   101898.0000    90056.8359 11773669   11.62%\n",
      "  48267 20853        cutoff         101898.0000    90056.8359 11830726   11.62%\n",
      "  48384 20993    99040.1132  1561   101898.0000    90056.8359 11881085   11.62%\n",
      "  48538 21117   101096.0805   746   101898.0000    90062.8357 11942505   11.61%\n",
      "  48614 21166        cutoff         101898.0000    90072.8826 11970652   11.60%\n",
      "  48662 21166    91605.2333  2035   101898.0000    90086.9330 11978268   11.59%\n",
      "  48709 21308    97136.3078  1190   101898.0000    90086.9330 12013136   11.59%\n",
      "Elapsed time = 38891.27 sec. (1088686.70 ticks, tree = 1078.10 MB, solutions = 21)\n",
      "  48786 21365    99318.2730  1337   101898.0000    90092.2827 12048256   11.59%\n"
     ]
    }
   ],
   "source": [
    "# Loop over harvesting schedules ---\n",
    "for hsched_name, path in harv_sched_file_paths.items():\n",
    "    print(f\"\\n--- Harvesting schedule: {hsched_name} ---\")\n",
    "    # Loop over components and run workflow ---\n",
    "    for folder_name in os.listdir(base_dir):\n",
    "        in_component_dir = os.path.join(base_dir, folder_name)\n",
    "        if not os.path.isdir(in_component_dir):\n",
    "            continue  # Skip non-directories\n",
    "\n",
    "        out_dir = os.path.join(model_dir, hsched_name, folder_name)\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "        print(f\"\\n=== Processing Component: {folder_name} ===\")\n",
    "\n",
    "        # --- Load nodes ---\n",
    "        V_source, V_exit, V, nodes_df = load_nodes(in_component_dir)\n",
    "\n",
    "        # --- Map node IDs ---\n",
    "        node_ID_mapping, reversed_node_ID_mapping, V_nodeIDs, V_source_nIDs, V_exit_nIDs = build_node_mappings(V, V_source, V_exit)\n",
    "\n",
    "        # --- Transit nodes ---\n",
    "        V_transit = get_transit_nodes(V_nodeIDs, V_source_nIDs, V_exit_nIDs)\n",
    "\n",
    "        # --- Load arcs & attributes ---\n",
    "        A, arcs_fw, arcs_bw, edge_attr_df = load_and_verify_arcs(in_component_dir)\n",
    "\n",
    "        # --- Map arcs to node IDs ---\n",
    "        A, A_fw, A_bw = replace_coord_with_IDs(A, arcs_fw, arcs_bw)\n",
    "        \n",
    "        # --- Process edges into tuples/strings ---\n",
    "        A, A_fw, A_bw, E = process_edge_pairs(A, A_fw, A_bw)\n",
    "\n",
    "        # create fw bw mappings\n",
    "        fw_to_bw_map, bw_to_fw_map= create_forward_backward_mapping(A_fw, A_bw, swap_direction)\n",
    "        \n",
    "        # --- Build source dictionary ---\n",
    "        V_source_dict, S = build_source_dict(V_source, reversed_node_ID_mapping)\n",
    "\n",
    "        # --- Build arcs ---\n",
    "        source_arcs_ingoing, source_arcs_outgoing = get_source_arcs(A, V_source_dict)\n",
    "        exit_arcs_ingoing, totalin, exit_arcs_outgoing, totalout = build_exit_arcs(V_exit_nIDs, A)\n",
    "        ingoing_per_transitnode, outgoing_per_transitnode, total_in, total_out = build_transitnode_arcs(V_transit, A)\n",
    "\n",
    "        # --- Load parameters & costs & accessneeds---\n",
    "        reverse_mapping = {f'({x[0]}, {x[1]})': short_name for short_name, x in node_ID_mapping.items()}\n",
    "        edge_attr_df = load_and_process_edge_attributes(f'{in_component_dir}/arcs_with_attributes.csv', reverse_mapping)\n",
    "        CostC, CostM, CostU = build_cost_dicts(E, W, edge_attr_df)\n",
    "        accessneeds_df, wide_accessneeds_df = load_access_needs(path, filter_stands=S)\n",
    "        accessneeds_df_dict = {'timber': accessneeds_df, 'wide': wide_accessneeds_df}\n",
    "\n",
    "        # --- Needroad and maxflow ---\n",
    "        needroad_w_s_t = set_needroad_parameters(S, T, accessneeds_df_dict)\n",
    "        maxflow_results = set_maxflow_params(S, T, needroad_w_s_t, ['timber', 'wide'])\n",
    "        maxflow_w_t = {**maxflow_results['timber'], **maxflow_results['wide']}\n",
    "\n",
    "        # --- Decision variables ---\n",
    "        C, M, U = create_binary_decision_variables(E, W, T)\n",
    "        flow = create_integer_flow_variables(A, W, T)\n",
    "\n",
    "        # --- Build CPLEX model ---\n",
    "        model = Cplex()\n",
    "        model.set_problem_type(Cplex.problem_type.LP)\n",
    "        model.variables.delete()\n",
    "        model.linear_constraints.delete()\n",
    "\n",
    "        # --- Add variables and objective ---\n",
    "        objective_terms, objective_coeffs = add_binary_variables_to_model(model, C, M, U, CostC, CostM, CostU)\n",
    "        n_action_variables = verify_binary_variables(model, E, T, objective_coeffs, 5)\n",
    "        set_objective(model, objective_terms, objective_coeffs)\n",
    "        add_flow_variables(model, flow, lb=0, ub=9)\n",
    "        n_flow_variables = verify_flow_variables(model, n_action_variables, A, W, T)\n",
    "        arc_check_results = verify_transitnode_arcs(flow, ingoing_per_transitnode, outgoing_per_transitnode)\n",
    "\n",
    "        # --- save Variables\n",
    "        save_binary_variables_info(model, CostC, CostM, CostU, f'{out_dir}')\n",
    "        save_flow_variables_info(model, n_flow_variables, f'{out_dir}')\n",
    "\n",
    "        # --- Add constraints ---\n",
    "        # 1. Wide road flow enforcing road existence\n",
    "        verification_wide = add_wide_flow_constraints(model, flow, C, M, U, maxflow_w_t, fw_to_bw_map, T, A_fw)\n",
    "        expected_constraints_group1 = 5 * len(E)\n",
    "\n",
    "        # 2. Timber road flow enforcing road existence\n",
    "        verification_timber = add_timber_flow_constraints(model, flow, C, M, U, maxflow_w_t, fw_to_bw_map, T, E)\n",
    "        expected_constraints_group2 = 5 * len(E)  # adjust if multiplicity of T is relevant\n",
    "\n",
    "        # 3. Flow conservation at transit nodes (all road types)\n",
    "        verification_flow_conservation = add_flow_conservation_constraints(model, flow, ingoing_per_transitnode, outgoing_per_transitnode, W, T)\n",
    "        expected_constraints_group3 = 2 * len(V_transit) * len(T)\n",
    "\n",
    "        # 4. Outflow only if stand needs road (all road types)\n",
    "        verification_outflow = add_outflow_needroad_constraints(model, flow, needroad_w_s_t, source_arcs_outgoing, W, T)\n",
    "        expected_constraints_group4 = len(V_source_dict) * len(T) * 2  # adjust if number of periods differs\n",
    "\n",
    "        # 5. No inflow to source nodes\n",
    "        verification_no_inflow = add_no_inflow_source_constraints(model, flow, source_arcs_ingoing, T)\n",
    "        expected_constraints_group5 = len(V_source_dict) * len(T)  # adjust if number of periods differs\n",
    "\n",
    "        # 6. Maintenance/Upgrade timber roads\n",
    "        verification_maintain_timber = add_maintain_upgrade_constraints(model, C, M, U, E, T, road_type='timber')\n",
    "        expected_constraints_group6 = len(T) * len(E)  # adjust if number of periods differs\n",
    "\n",
    "        # 7. Maintenance/Upgrade wide roads\n",
    "        verification_maintain_wide = add_maintain_upgrade_wide_constraints(model, C, M, U, E, T, road_type='wide')\n",
    "        expected_constraints_group7 = len(T) * len(E)  # adjust if number of periods differs\n",
    "\n",
    "        # --- Verify and store constraints ---\n",
    "        verify_and_store_constraints(model, verification_wide, \"Constraint_flow_enforcing_road\", 5*len(E), f\"{out_dir}/Constraints_wideflow_enforce_wideroad.txt\")\n",
    "        verify_and_store_constraints(model, verification_timber, \"Constraint_timberflow_enforcing_road\", 5*len(E), f\"{out_dir}/Constraints_timberflow_enforce_road.txt\")\n",
    "        verify_and_store_constraints(model, verification_flow_conservation, \"Constraint_flow_conservation\", 2*len(V_transit)*len(T), f\"{out_dir}/Constraints_flow_conservation.txt\")\n",
    "        verify_and_store_constraints(model, verification_outflow, \"Constraint_outflow_iff_needroad\", len(V_source_dict)*len(T)*2, f\"{out_dir}/Constraints_outflow_iff_needroad.txt\")\n",
    "        verify_and_store_constraints(model, verification_no_inflow, \"Constraint_no_inflow_source\", len(V_source_dict)*len(T), f\"{out_dir}/Constraints_no_inflow_to_source.txt\")\n",
    "        verify_and_store_constraints(model, verification_maintain_timber, \"Constraint_maintain_upgrade\", len(T)*len(E), f\"{out_dir}/Constraints_maintain_upgrade_timber.txt\")\n",
    "        verify_and_store_constraints(model, verification_maintain_wide, \"Constraint_maintain_upgrade_wide\", len(T)*len(E), f\"{out_dir}/Constraints_maintain_upgrade_wide.txt\")\n",
    "\n",
    "        # --- Save model files ---\n",
    "        model.write(os.path.join(out_dir, \"model.lp\"))\n",
    "        model.write(os.path.join(out_dir, \"model.sav\"))\n",
    "        model.write(os.path.join(out_dir, \"model.mps\"))\n",
    "\n",
    "        # --- Solve model ---\n",
    "        model.solve()\n",
    "\n",
    "        # --- Save solution ---\n",
    "        df_sol, solution = print_solution_summary(model, top_n=5)\n",
    "        df_sol.to_csv(os.path.join(out_dir, \"solution_full.csv\"), index=False)\n",
    "        df_sol[df_sol['value'] != 0].to_csv(os.path.join(out_dir, \"solution_nonzero.csv\"), index=False)\n",
    "        with open(os.path.join(out_dir, \"solution_summary.txt\"), \"w\") as f:\n",
    "            f.write(f\"Objective value: {model.solution.get_objective_value()}\\n\")\n",
    "            f.write(f\"Total variables: {len(model.variables.get_names())}\\n\")\n",
    "            f.write(f\"Non-zero variables: {len(df_sol[df_sol['value'] != 0])}\\n\")\n",
    "\n",
    "        # --- Post Processing ---\n",
    "        full_solution_df = extract_solution_df(model)\n",
    "        solution_df = full_solution_df[full_solution_df.value!=0]\n",
    "        solution_df = remap_solution_to_coords(solution_df, node_ID_mapping)\n",
    "        full_solution_df = remap_solution_to_coords(full_solution_df, node_ID_mapping)\n",
    "\n",
    "        #--- Verification Workflow ---\n",
    "\n",
    "        # --- store component solution for postprocessing to merge and visualize and use it\n",
    "\n",
    "        print(f\"=== Finished Component: {folder_name} ===\")\n",
    "    # --- merge the component solutions into one big solution\n",
    "\n",
    "    # --- visualize  \n",
    "    # f  \n",
    "    print(f'--- FINISHED {hsched_name} ---') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üëÅ Visualize the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prep: load shapefile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot shapefile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot the real edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot the solution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
