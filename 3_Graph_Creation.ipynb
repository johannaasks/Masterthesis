{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a graph for the possible future road network\n",
    "For each component of stands that is not connected to any roads (respective: big roads), we wanna create a network of possible future road segments which strictly follow the boundaries of the forest stands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import math\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# Import third-party libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import missingno as msno\n",
    "\n",
    "# Import geometrical and spatial libraries\n",
    "from shapely.geometry import MultiPolygon, Polygon, Point, LineString\n",
    "from shapely import wkt\n",
    "\n",
    "# Import plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input and output paths\n",
    "inpath = r\"1_Preprocessed_Data\\2_Stand_Components\\unconnected_to_roads\\2_nonsingle_inaccessible_components_with_ring_of_accessible_neighbors\"\n",
    "out_directory = r\"1_Preprocessed_Data\\3_Road_Network_Graphs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component 'component_10' loaded with 9 stands.\n",
      "Component 'component_11' loaded with 3 stands.\n",
      "Component 'component_12' loaded with 6 stands.\n",
      "Component 'component_13' loaded with 7 stands.\n",
      "Component 'component_14' loaded with 14 stands.\n",
      "Component 'component_15' loaded with 5 stands.\n",
      "Component 'component_16' loaded with 4 stands.\n",
      "Component 'component_17' loaded with 6 stands.\n",
      "Component 'component_18' loaded with 17 stands.\n",
      "Component 'component_19' loaded with 4 stands.\n",
      "Component 'component_1' loaded with 6 stands.\n",
      "Component 'component_20' loaded with 5 stands.\n",
      "Component 'component_21' loaded with 30 stands.\n",
      "Component 'component_22' loaded with 10 stands.\n",
      "Component 'component_23' loaded with 4 stands.\n",
      "Component 'component_24' loaded with 12 stands.\n",
      "Component 'component_25' loaded with 5 stands.\n",
      "Component 'component_26' loaded with 10 stands.\n",
      "Component 'component_2' loaded with 4 stands.\n",
      "Component 'component_3' loaded with 91 stands.\n",
      "Component 'component_4' loaded with 9 stands.\n",
      "Component 'component_5' loaded with 4 stands.\n",
      "Component 'component_6' loaded with 18 stands.\n",
      "Component 'component_7' loaded with 22 stands.\n",
      "Component 'component_8' loaded with 48 stands.\n",
      "Component 'component_9' loaded with 4 stands.\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary\n",
    "components = {}\n",
    "\n",
    "# List all shapefiles in the directory\n",
    "shapefiles = [f.path for f in os.scandir(inpath) if f.is_file() and f.name.endswith('.shp')]\n",
    "\n",
    "for shapefile_path in shapefiles:\n",
    "    # Extract the filename without extension\n",
    "    filename = os.path.splitext(os.path.basename(shapefile_path))[0]\n",
    "    \n",
    "    # Extract the part after \"combi_\"\n",
    "    key = filename.split('_stands')[0] if '_stands' in filename else filename\n",
    "    \n",
    "    # Load the shapefile into a GeoDataFrame\n",
    "    components[key] = gpd.read_file(shapefile_path)\n",
    "    \n",
    "    print(f\"Component '{key}' loaded with {len(components[key])} stands.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load road data\n",
    "roads = gpd.read_file(r'1_Preprocessed_Data\\1_Roads_clean\\roads_clean.shp')\n",
    "roads = roads.to_crs(components['component_1'].crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extract vertices and edges with attributes (slope, edge length) and exit points from boundaries [helper functions]\n",
    "From the boundaries of the stands, we extract all points with coordianates and additionally save the edges (lines) connecting them. \n",
    "\n",
    "Note: We only want need exterior boundaries, and NO roads along interior boundaries of a forest stand (because such interior roads would not help with connecting the stands to the existing road network).\n",
    "\n",
    "There will be helper functions for step I consider important enough to mention them seperately, even if the function might be a single line of code, it helps to beter understand the structure and what happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Snap coordinates to grid [helper function] \n",
    "Before comparing edges, snap all coordinates to a common grid (round coordinates to a fixed number of decimal places). This helps ensure that neighboring stands with slightly different coordinate representations share identical coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snap_to_grid(coord, precision):\n",
    "    \"\"\"\n",
    "    Snaps the given coordinates to the specified precision.\n",
    "\n",
    "    Parameters:\n",
    "        coord (tuple or list): A tuple or list containing the x, y (and optionally z) coordinates to be snapped.\n",
    "        precision (int): The number of decimal places to round the coordinates.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple of coordinates rounded to the specified precision.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the input is not a tuple or list, or if any coordinate is NaN or infinite.\n",
    "    \"\"\"\n",
    "    # Check if input is a tuple or list\n",
    "    if not isinstance(coord, (tuple, list)):\n",
    "        raise ValueError(\"Input must be a tuple or list of coordinates\")\n",
    "\n",
    "    # Check for NaN or infinity values\n",
    "    if any(map(lambda c: isinstance(c, (float, int)) and (math.isnan(c) or math.isinf(c)), coord)):\n",
    "        raise ValueError(\"Coordinate contains NaN or infinite values\")\n",
    "    \n",
    "    # Round coordinates to the specified precision\n",
    "    return tuple(round(c, precision) for c in coord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Calculate attributes [helper function]\n",
    "To calculate the costs, we need to know for each edge its edge length and its approximative slope.\n",
    "- *edgelength*: The length of an edge (u,v) is calculated using the Euclidean distance formula, to compute the distance between the coordinates of points u and v.\n",
    "- *slope (approx.)*: The slope of an edge is approximated by the slope (\"Declive\") of the polygon the edge belongs to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shapefile contains 2D geometries (no altitude per coordinate).\n",
      "The shapefile has an 'Altitude' column (single altitude per polygon).\n"
     ]
    }
   ],
   "source": [
    "# Check geometry dimension for the one example component\n",
    "component = next(iter(components.values()))  # Get the first component\n",
    "geometry = component.geometry.iloc[0]\n",
    "\n",
    "if geometry.has_z:\n",
    "    print(\"The shapefile contains 3D geometries with Z-values (altitudes per coordinate).\")\n",
    "else:\n",
    "    print(\"The shapefile contains 2D geometries (no altitude per coordinate).\")\n",
    "    \n",
    "    # Check for altitude attribute\n",
    "    if 'Altitude' in component.columns:\n",
    "        print(\"The shapefile has an 'Altitude' column (single altitude per polygon).\")\n",
    "    else: \n",
    "        print(\"No 'Altitude' column found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If we knew the altitude per coordinate, the slope could be approximated via the ratio of the altitude difference to the edgelength; but the edges all belong to the same polygon so we only have one single altitude per polygon (which would lead to a slope of 0). Therefore, we just take the slope (\"Declive\") of the polygon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_edge_length(u, v):\n",
    "    \"\"\"\n",
    "    Calculate the length of the edge defined by two vertices (u, v).\n",
    "\n",
    "    Parameters:\n",
    "        u (tuple): A tuple representing the coordinates (x, y) of the first vertex.\n",
    "        v (tuple): A tuple representing the coordinates (x, y) of the second vertex.\n",
    "\n",
    "    Returns:\n",
    "        float: The length of the edge between vertices u and v.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the input coordinates are not tuples or lists of length 2.\n",
    "    \"\"\"\n",
    "    # Ensure the input coordinates are valid (tuples of length 2)\n",
    "    if not (isinstance(u, (tuple, list)) and len(u) == 2) or not (isinstance(v, (tuple, list)) and len(v) == 2):\n",
    "        raise ValueError(\"Both u and v must be tuples or lists of length 2 representing coordinates.\")\n",
    "\n",
    "    # Create a LineString object to calculate the edge length\n",
    "    line = LineString([u, v])\n",
    "\n",
    "    # Return the length of the line\n",
    "    return line.length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Extract nodes, edges, attributes [helper function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_boundaries_with_attributes(stands, precision=5):\n",
    "    \"\"\"\n",
    "    Extracts the vertices, edges, edge attributes (such as edge length and slope),\n",
    "    and exit points (intersections with roads) from polygon geometries in the input \n",
    "    stands dataset. Coordinates and intersections are snapped to a grid for precision.\n",
    "\n",
    "    Parameters:\n",
    "        stands (GeoDataFrame): A GeoDataFrame containing the stand boundaries and \n",
    "                                associated data. Each feature must have a polygon geometry.\n",
    "        precision (int, optional, default=4): The precision to which the coordinates \n",
    "                                              will be snapped when extracted (controls decimal places).\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing four elements:\n",
    "            - vertices (list of tuples): A list of unique vertices (coordinates of stand boundary points)\n",
    "            - edges (list of tuples): A list of edges (pairs of vertices)\n",
    "            - edge_attributes (list of dicts): A list of dictionaries containing edge attributes (edge length, slope)\n",
    "            - exit_points (list of tuples): A list of exit points (coordinates where stand boundaries intersect roads)\n",
    "    \"\"\"\n",
    "    vertices = set()  # Using set to avoid duplicate vertices\n",
    "    edges = []\n",
    "    edge_attributes = []\n",
    "    exit_points = []\n",
    "\n",
    "    for _, feature in stands.iterrows():\n",
    "        geometry = feature.geometry\n",
    "        slope = feature['Declive']\n",
    "\n",
    "        # Process only polygons\n",
    "        if geometry.geom_type == 'Polygon':\n",
    "            # Snap coordinates for the exterior\n",
    "            exterior_coords = [snap_to_grid(coord, precision) for coord in geometry.exterior.coords]\n",
    "            vertices.update(exterior_coords)  # Use set to avoid duplicates\n",
    "\n",
    "            # Creating edges\n",
    "            for i in range(len(exterior_coords) - 1):\n",
    "                u, v = exterior_coords[i], exterior_coords[i + 1]\n",
    "                edges.append((u, v))\n",
    "\n",
    "                # Edge length and slope\n",
    "                edge_length = calculate_edge_length(u, v)\n",
    "                edge_attributes.append({'edgelength': edge_length, 'slope': slope, 'has_exit': False})\n",
    "\n",
    "            # Find intersections with roads (exit points)\n",
    "            stand_boundary = geometry.exterior  # Stand polygon boundary\n",
    "            for road in roads.geometry:\n",
    "                if stand_boundary.intersects(road):  # Only proceed if there is an intersection\n",
    "                    intersection = stand_boundary.intersection(road)\n",
    "                    \n",
    "                    # Process intersections\n",
    "                    if intersection.geom_type == 'Point':\n",
    "                        exit_points.append(snap_to_grid((intersection.x, intersection.y), precision))\n",
    "                    elif intersection.geom_type == 'MultiPoint':\n",
    "                        exit_points.extend([snap_to_grid((point.x, point.y), precision) for point in intersection.geoms])\n",
    "\n",
    "    return list(vertices), edges, edge_attributes, exit_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create the Graph\n",
    "Next, we'll use these vertices and edges to build a graph. This graph will represent the potential road network, where the roads are constrained to follow the boundaries of the forest stands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing graph data [helper function] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_data_for_graph(out_path, vertices, edges, attributes, name):\n",
    "    \"\"\"\n",
    "    Saves the data for the graph (vertices, edges, and attributes) into CSV files within a specified folder.\n",
    "\n",
    "    Parameters:\n",
    "        out_path (str): The directory where the CSV files will be saved.\n",
    "        vertices (list): A list of vertex coordinates (x, y) to be saved.\n",
    "        edges (list): A list of edges, each represented by a tuple of vertices.\n",
    "        attributes (list): A list of dictionaries containing edge attributes (e.g., 'edgelength', 'slope').\n",
    "        name (str): The name of the component, used in the file naming.\n",
    "        G (networkx.Graph): The graph containing node attributes, including `is_exit`.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the folder exists\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "    # File paths\n",
    "    vertices_file = os.path.join(out_path, f'nodes_{name}.csv')\n",
    "    edges_file = os.path.join(out_path, f'edges_{name}.csv')\n",
    "    attributes_file = os.path.join(out_path, f'attributes_{name}.csv')\n",
    "    edges_with_attributes_file = os.path.join(out_path, f'edges_with_attributes_{name}.csv')\n",
    "\n",
    "    # Save vertices to CSV with the 'is_exit' column\n",
    "    vertices_data = [{'x': x, 'y': y, } for x, y in vertices]\n",
    "    pd.DataFrame(vertices_data).to_csv(vertices_file, index=False)\n",
    "\n",
    "    # Save edges to CSV\n",
    "    edges_data = [(f\"({u[0]}, {u[1]})\", f\"({v[0]}, {v[1]})\") for u, v in edges]\n",
    "    pd.DataFrame(edges_data, columns=['Node1(x,y)', 'Node2(x,y)']).to_csv(edges_file, index=False)\n",
    "\n",
    "    # Save attributes to CSV\n",
    "    pd.DataFrame(attributes).to_csv(attributes_file, index=False)\n",
    "\n",
    "    # Save edges with attributes to CSV\n",
    "    edges_attributes_data = [\n",
    "        {\n",
    "            'Node1(x,y)': f\"({u[0]}, {u[1]})\",\n",
    "            'Node2(x,y)': f\"({v[0]}, {v[1]})\",\n",
    "            'edgelength': attributes['edgelength'],\n",
    "            'slope': attributes['slope'],\n",
    "            'has_exit': attributes['has_exit']\n",
    "        }\n",
    "        for (u, v), attributes in zip(edges, attributes)\n",
    "    ]\n",
    "    pd.DataFrame(edges_attributes_data).to_csv(edges_with_attributes_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create graph from vertices, edges, attributes [helper function] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(vertices, edges, attributes):\n",
    "    \"\"\"\n",
    "    Create an undirected graph using NetworkX based on the provided vertices, edges, and edge attributes.\n",
    "\n",
    "    Parameters:\n",
    "        vertices (list): A list of vertices (nodes) to be added to the graph.\n",
    "        edges (list): A list of edges represented as tuples (u, v), where u and v are vertices.\n",
    "        attributes (list): A list of dictionaries, where each dictionary contains edge attributes \n",
    "                           (such as 'weight', 'length', 'has_exit', etc.) corresponding to each edge.\n",
    "\n",
    "    Returns:\n",
    "        nx.Graph: A NetworkX Graph object containing the nodes, edges, and associated attributes.\n",
    "    \n",
    "    Example:\n",
    "        vertices = [(x1, y1), (x2, y2), (x3, y3)]\n",
    "        edges = [((x1, y1), (x2, y2)),\n",
    "                 ((x2, y2), (x3, y3))]\n",
    "        attributes = [\n",
    "            {'edgelength': 74.92801170857655, 'slope': 18.0777, 'has_exit': False},\n",
    "            {'edgelength': 61.5825216583405, 'slope': 18.0777, 'has_exit': False}\n",
    "        ]\n",
    "    \"\"\"\n",
    "\n",
    "    if len(edges) != len(attributes):\n",
    "        raise ValueError(\"The number of edges and attributes must match.\")\n",
    "\n",
    "    G = nx.Graph()\n",
    "    for vertex in vertices:\n",
    "        G.add_node(vertex, is_exit=False)  # Default: not an exit\n",
    "\n",
    "    for edge, attr in zip(edges, attributes):\n",
    "        u, v = edge\n",
    "        # Add the edge with the attributes\n",
    "        G.add_edge(u, v, **attr)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot graph and store image [helper function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save(outpath, G, name, prefix):\n",
    "    \"\"\"Plots the graph 'G' along with associated geographical components and saves the plot to a file.\n",
    "\n",
    "    Parameters:\n",
    "        G (nx.Graph): The NetworkX graph object to be plotted.\n",
    "        name (str): The name of the component, used in the plot title and file naming.\n",
    "        filename (str): The path and filename where the plot will be saved.\n",
    "\n",
    "    Saves:\n",
    "        A PNG image containing:\n",
    "            - The geographical component from the 'components' GeoDataFrame.\n",
    "            - The graph 'G' overlaid with nodes and edges.\n",
    "            - A summary of node degrees, total edge length, and number of exit nodes as an annotation.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    filename=os.path.join(outpath,f'{prefix}_{name}.png')\n",
    "\n",
    "    components[name].plot(ax=plt.gca(), color='lightgray', alpha=0.5)  # Add GeoDataFrame\n",
    "    components[name].apply(lambda row: plt.annotate(text=row['ID_UG'], \n",
    "                                                xy=(row.geometry.centroid.x, row.geometry.centroid.y), \n",
    "                                                xytext=(3, 3), textcoords=\"offset points\", \n",
    "                                                fontsize=8, color='black'), axis=1)\n",
    "\n",
    "    \n",
    "    nodecolor = [\"blue\" if G.nodes[node].get('is_exit', False) else \"red\" for node in G.nodes()]\n",
    "\n",
    "    nx.draw(G, pos={node: node for node in G.nodes()}, node_size=50, \n",
    "            node_color=nodecolor, edge_color=\"blue\", with_labels=False)\n",
    "    \n",
    "    # Get degree of each node\n",
    "    degree_counts = Counter(dict(G.degree()).values())\n",
    "\n",
    "    # Calculate total edge length\n",
    "    total_edge_length = sum(G[u][v].get('edgelength', 0) for u, v in G.edges())\n",
    "\n",
    "    # Calculate total costs across multiple attributes\n",
    "    # List of required attributes\n",
    "    cost_attributeskeys = ['Build5m', 'Maintain5m', 'Build10m', 'Maintain10m', 'Upgrade']\n",
    "\n",
    "    # Check if all required attributes exist in any edge\n",
    "    costattributes_exist = all(any(attr in G[u][v] for u, v in G.edges()) for attr in cost_attributeskeys)\n",
    "\n",
    "    if costattributes_exist:\n",
    "\n",
    "        # Calculate total costs if the attributes exist\n",
    "        total_costs = sum(\n",
    "            G[u][v].get('Build5', 0) + \n",
    "            G[u][v].get('Maintain5', 0) + \n",
    "            G[u][v].get('Build10', 0) + \n",
    "            G[u][v].get('Maintain10', 0) + \n",
    "            G[u][v].get('Upgrade', 0)\n",
    "            for u, v in G.edges()\n",
    "        )\n",
    "\n",
    "    # Count nodes marked as exit\n",
    "    exit_nodes_count = sum(1 for node in G.nodes if G.nodes[node].get('is_exit'))\n",
    "\n",
    "    # Create the overview text\n",
    "    degree_overview = \"Graph Degree Overview:\\n\"\n",
    "    for degree, count in sorted(degree_counts.items()):\n",
    "        degree_overview += f\"Nodes with degree {degree}: {count}\\n\"\n",
    "\n",
    "    degree_overview += f\"\\nNumber of Exit Nodes: {exit_nodes_count}\\n\"\n",
    "    degree_overview += f\"\\nTotal Edge Length: {total_edge_length:.2f}\\n\"\n",
    "    if costattributes_exist:\n",
    "        degree_overview += f\"Total Costs: {total_costs:.2f}\\n\"\n",
    "\n",
    "    # Add graph details to plot\n",
    "    plt.title(f\"Graph Plot for {name},\\n {len(G.nodes)} nodes\\n {len(G.edges)} edges\")\n",
    "    \n",
    "    # Add the degree overview text to the plot\n",
    "    plt.text(0.5, -0.1, degree_overview, ha='center', va='top', transform=plt.gca().transAxes, fontsize=10)\n",
    "\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')  # Save plot\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Handle exit points [helper functions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find nearest node [helper function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_node(graph, exit_points):\n",
    "    \"\"\"\n",
    "    Find the nearest nodes in the graph for a list of exit points based on Euclidean distance.\n",
    "\n",
    "    Parameters:\n",
    "        graph (nx.Graph): A NetworkX graph object containing nodes and their coordinates.\n",
    "        exit_points (list): A list of exit points, where each exit point is a tuple representing (x, y) coordinates.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with columns ['exit_point', 'nearest_neighbor_node', 'distance'],\n",
    "                      containing the exit points, their corresponding nearest nodes, and the calculated distances.\n",
    "\n",
    "    Example:\n",
    "        graph = nx.Graph()\n",
    "        exit_points = [(x1, y1), (x2, y2)]\n",
    "        result_df = find_nearest_node(graph, exit_points)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for exit_point in exit_points:\n",
    "        # Find the nearest node based on distance\n",
    "        nearest_node = min(graph.nodes, key=lambda node: np.linalg.norm(np.array(exit_point) - np.array(node)))\n",
    "        \n",
    "        # Calculate the distance to the nearest node\n",
    "        distance = np.linalg.norm(np.array(exit_point) - np.array(nearest_node))\n",
    "        \n",
    "        # Append the result\n",
    "        results.append((exit_point, nearest_node, distance))\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(results, columns=['exit_point', 'nearest_neighbor_node', 'distance'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find edges closeby [helper function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_edge(G, exit_x, exit_y):\n",
    "    \"\"\"\n",
    "    Finds the closest edge in the graph to the exit point (exit_x, exit_y).\n",
    "    Returns the edge (u, v) and the intersection point.\n",
    "    \"\"\"\n",
    "    min_dist = float('inf')\n",
    "    closest_edge = None\n",
    "    intersection_point = None\n",
    "\n",
    "    # Iterate through all edges in the graph\n",
    "    for u, v in G.edges():\n",
    "        # Get the coordinates of the nodes (assumed to be stored as node attributes)\n",
    "        ux, uy = u\n",
    "        vx, vy = v\n",
    "        \n",
    "        # Create a LineString for the edge\n",
    "        line = LineString([(ux, uy), (vx, vy)])\n",
    "\n",
    "        # Create a Point for the exit\n",
    "        exit_point = Point(exit_x, exit_y)\n",
    "\n",
    "        # Check if the exit point intersects the edge\n",
    "        if line.distance(exit_point) < min_dist:\n",
    "            min_dist = line.distance(exit_point)\n",
    "            closest_edge = (u, v)\n",
    "            # If the point is on the line, we can get the intersection point\n",
    "            if line.intersects(exit_point):\n",
    "                intersection_point = line.interpolate(line.project(exit_point))  # Exact intersection point\n",
    "\n",
    "    return closest_edge, intersection_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split at exit [helper function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_edge_at_exit(G, exit_node, exit_x, exit_y):\n",
    "    \"\"\"\n",
    "    Splits the edge in the graph that is closest to the exit node based on coordinates.\n",
    "    After splitting, ensures that the new edges have the 'has_exit' attribute if they contain the exit node.\n",
    "    Also adds the 'has_exit' attribute to the edge if the exit node is already part of it.\n",
    "\n",
    "    Parameters:\n",
    "        G (nx.Graph): The NetworkX graph containing the edges to be split.\n",
    "        exit_node (tuple): The coordinates (x, y) of the exit node to be added.\n",
    "        exit_x (float): The x-coordinate of the exit point.\n",
    "        exit_y (float): The y-coordinate of the exit point.\n",
    "\n",
    "    Actions:\n",
    "        - Identifies the closest edge to the exit point.\n",
    "        - Splits the identified edge by adding the exit node and connecting it to both vertices of the edge.\n",
    "        - Removes the original edge and adds two new edges that include the exit node.\n",
    "        - Adds the 'has_exit' attribute to the edges, whether split or not.\n",
    "    \"\"\"\n",
    "    # Find the closest edge and the intersection point\n",
    "    closest_edge, intersection_point = find_closest_edge(G, exit_x, exit_y)\n",
    "\n",
    "    if closest_edge is None:\n",
    "        print(f\"Warning: No edge found for exit point {exit_node}. Skipping split.\")\n",
    "        return\n",
    "\n",
    "    u, v = closest_edge\n",
    "\n",
    "    # If the exit_node is already part of the edge, just mark the edge with 'has_exit'\n",
    "    if exit_node == u or exit_node == v:\n",
    "        print(f\"Exit node {exit_node} is already part of the edge ({u}, {v}). Marking it with 'has_exit'.\")\n",
    "        G[u][v]['has_exit'] = True\n",
    "        return\n",
    "    \n",
    "    # Get attributes from the original edge\n",
    "    original_slope = G[u][v].get('slope', None)\n",
    "\n",
    "    # Remove the original edge\n",
    "    G.remove_edge(u, v)\n",
    "\n",
    "    # Add the exit node and split the edge\n",
    "    G.add_edge(u, exit_node)\n",
    "    G.add_edge(exit_node, v)\n",
    "\n",
    "    # Assign attributes to the new edges\n",
    "    for node1, node2 in [(u, exit_node), (exit_node, v)]:\n",
    "        G[node1][node2]['has_exit'] = True\n",
    "        G[node1][node2]['slope'] = original_slope  # Retain the slope\n",
    "        G[node1][node2]['edgelength'] = calculate_edge_length(node1, node2)  # Recalculate edge length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### handling exit points [helper function] [mini workflow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_exit_points(G, exit_points):\n",
    "    \"\"\"\n",
    "    Processes exit points by adding them as nodes or merging them with existing ones.\n",
    "    Also updates edge attributes to indicate if they contain an exit node.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (count of already contained exit points, count of newly added exit points).\n",
    "    \"\"\"\n",
    "    # Find nearest nodes and determine new exit points\n",
    "    exitdf = find_nearest_node(G, exit_points)\n",
    "    exitdf['newexit'] = np.where(exitdf['distance'] <= 10, exitdf['nearest_neighbor_node'], exitdf['exit_point'])\n",
    "\n",
    "    # Add exit nodes to graph\n",
    "    for node in exitdf['newexit']:\n",
    "        G.add_node(node, is_exit=True)  # Mark node as an exit\n",
    "\n",
    "    # Split edges at new exit points if necessary\n",
    "    for _, row in exitdf[exitdf['distance'] > 10].iterrows():\n",
    "        exit_x, exit_y = row['exit_point']\n",
    "        closest_edge, intersection_point = find_closest_edge(G, exit_x, exit_y)\n",
    "\n",
    "        if closest_edge:\n",
    "            split_edge_at_exit(G, row['newexit'], exit_x, exit_y)\n",
    "\n",
    "    # Mark edges that contain exit nodes\n",
    "    exit_nodes = set(exitdf['newexit'])  # Convert to set for fast lookup\n",
    "    for u, v in G.edges():\n",
    "        G[u][v]['has_exit'] = u in exit_nodes or v in exit_nodes  \n",
    "\n",
    "    # Return counts\n",
    "    return (exitdf['distance'] <= 10).sum(), (exitdf['distance'] > 10).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO: Verify Exit Points (Plot with roads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### store updated graph data [helper function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_updated_graph_data(out_path, G, name, prefix):\n",
    "    \"\"\"\n",
    "    Saves the updated graph data (vertices, edges, and attributes) into CSV files after processing exit points.\n",
    "\n",
    "    Parameters:\n",
    "        out_path (str): The directory where the CSV files will be saved.\n",
    "        name (str): The name of the component, used in the file naming.\n",
    "    \"\"\"\n",
    "    # Ensure the folder exists\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "    # File paths\n",
    "    updated_vertices_file = os.path.join(out_path, f'{prefix}_nodes_{name}.csv')\n",
    "    updated_edges_file = os.path.join(out_path, f'{prefix}_edges_{name}.csv')\n",
    "    updated_attributes_file = os.path.join(out_path, f'{prefix}_attributes_{name}.csv')\n",
    "    updated_edges_with_attributes_file = os.path.join(out_path, f'{prefix}_edges_with_attributes_{name}.csv')\n",
    "\n",
    "    # Extract and save vertices (including 'is_exit' flag if present)\n",
    "    vertices_data = [{'x': node[0], 'y': node[1], 'is_exit': G.nodes[node].get('is_exit')} for node in G.nodes]\n",
    "    pd.DataFrame(vertices_data).to_csv(updated_vertices_file, index=False)\n",
    "\n",
    "    # Extract and save edges\n",
    "    edges_data = [(f\"({u[0]}, {u[1]})\", f\"({v[0]}, {v[1]})\") for u, v in G.edges]\n",
    "    pd.DataFrame(edges_data, columns=['Node1(x,y)', 'Node2(x,y)']).to_csv(updated_edges_file, index=False)\n",
    "\n",
    "    # Extract and save attributes\n",
    "    attributes_data = [{**G[u][v]} for u, v in G.edges]\n",
    "    pd.DataFrame(attributes_data).to_csv(updated_attributes_file, index=False)\n",
    "\n",
    "    # Extract and save edges with attributes dynamically\n",
    "    edges_attributes_data = []\n",
    "    for u, v in G.edges:\n",
    "        edge_data = {'Node1(x,y)': f\"({u[0]}, {u[1]})\", 'Node2(x,y)': f\"({v[0]}, {v[1]})\"}\n",
    "        edge_data.update(G[u][v])  # Dynamically add all attributes\n",
    "        edges_attributes_data.append(edge_data)\n",
    "    pd.DataFrame(edges_attributes_data).to_csv(updated_edges_with_attributes_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate the costs associated with each road segment\n",
    "\n",
    "There are costs associated with the construction, maintenance and upgrade of roads, depending on the slope. They need to be calculated for each road segment according to their length.\n",
    "\n",
    "We name the 3 categories of slope:\n",
    "* flat (slope ≤ 5)\n",
    "* moderate (5 < slope < 25)\n",
    "* steep (slope ≥ 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Build5m  Maintain5m\n",
      "flat       2147.0     1073.50\n",
      "moderate      0.0        0.00\n",
      "steep      7514.5     2683.75\n"
     ]
    }
   ],
   "source": [
    "costs = {\n",
    "    \"flat\": {  \n",
    "        \"Build5m\": 2147,\n",
    "        \"Maintain5m\": 1073.5\n",
    "    },\n",
    "    \"moderate\": {\n",
    "        \"Build5m\": 0,\n",
    "        \"Maintain5m\": 0\n",
    "    },\n",
    "    \"steep\": {\n",
    "        \"Build5m\": 7514.5,\n",
    "        \"Maintain5m\": 2683.75\n",
    "    }\n",
    "}\n",
    "costs_df = pd.DataFrame(costs).T\n",
    "print(costs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### approximation for unknown costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Build5m</th>\n",
       "      <th>Maintain5m</th>\n",
       "      <th>Build10m</th>\n",
       "      <th>Maintain10m</th>\n",
       "      <th>Upgrade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flat</th>\n",
       "      <td>2147.0</td>\n",
       "      <td>1073.50</td>\n",
       "      <td>3220.50</td>\n",
       "      <td>1073.50</td>\n",
       "      <td>1610.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moderate</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>steep</th>\n",
       "      <td>7514.5</td>\n",
       "      <td>2683.75</td>\n",
       "      <td>11271.75</td>\n",
       "      <td>2683.75</td>\n",
       "      <td>5635.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Build5m  Maintain5m  Build10m  Maintain10m   Upgrade\n",
       "flat       2147.0     1073.50   3220.50      1073.50  1610.250\n",
       "moderate      0.0        0.00      0.00         0.00     0.000\n",
       "steep      7514.5     2683.75  11271.75      2683.75  5635.875"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "costs_df['Build10m'] = 1.5 * costs_df.Build5m\n",
    "costs_df['Maintain10m'] = costs_df.Maintain5m\n",
    "costs_df['Upgrade'] = 0.75 * costs_df.Build5m\n",
    "costs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Build5m</th>\n",
       "      <th>Maintain5m</th>\n",
       "      <th>Build10m</th>\n",
       "      <th>Maintain10m</th>\n",
       "      <th>Upgrade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flat</th>\n",
       "      <td>2147.00</td>\n",
       "      <td>1073.500</td>\n",
       "      <td>3220.500</td>\n",
       "      <td>1073.500</td>\n",
       "      <td>1610.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moderate</th>\n",
       "      <td>4830.75</td>\n",
       "      <td>1878.625</td>\n",
       "      <td>7246.125</td>\n",
       "      <td>1878.625</td>\n",
       "      <td>3623.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>steep</th>\n",
       "      <td>7514.50</td>\n",
       "      <td>2683.750</td>\n",
       "      <td>11271.750</td>\n",
       "      <td>2683.750</td>\n",
       "      <td>5635.8750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Build5m  Maintain5m   Build10m  Maintain10m    Upgrade\n",
       "flat      2147.00    1073.500   3220.500     1073.500  1610.2500\n",
       "moderate  4830.75    1878.625   7246.125     1878.625  3623.0625\n",
       "steep     7514.50    2683.750  11271.750     2683.750  5635.8750"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "costs_df.iloc[1] = (costs_df.iloc[0] + costs_df.iloc[2]) / 2\n",
    "costs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### assign the costs [helper function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_all_costs_to_edges(G):\n",
    "    \"\"\"\n",
    "    Assign all cost-related variables (Build5m, Maintain5m, Upgrade, Build10m, Maintain10m) to edges\n",
    "    based on slope, road type, and edge length.\n",
    "    \n",
    "    Parameters:\n",
    "    G (NetworkX graph): The graph representing the road network.\n",
    "    \n",
    "    Returns:\n",
    "    G (NetworkX graph): The graph with updated cost attributes.\n",
    "    \"\"\"\n",
    "\n",
    "    # Iterate over each edge in the graph and set the new attributes\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        if 'edgelength' in data and 'slope' in data:  # Ensure both 'edgelength' and 'slope' exist\n",
    "\n",
    "            # Determine the correct category based on slope\n",
    "            if data['slope'] <= 5:\n",
    "                category = \"flat\"\n",
    "            elif 5 < data['slope'] < 25:\n",
    "                category = \"moderate\"\n",
    "            else:  # data['slope'] >= 25\n",
    "                category = \"steep\"\n",
    "\n",
    "            # Assign costs based on the selected category\n",
    "            for column in costs_df.columns:\n",
    "                data[column] = data['edgelength'] * costs_df.loc[category, column]\n",
    "                \n",
    "    print(f'{name} costs assigned')\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Merge short edges to improve performance of optimisation algorithms\n",
    "\n",
    "Note: It would have been possible to merge earlier, but the cost approximization is better this way, because we have more information on the slope if we don't merge the edges before calculation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge short edges [helper function] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_short_edges(G, length_threshold):\n",
    "    \"\"\"\n",
    "    Merges edges in a graph G that are shorter than a given length_threshold and connect nodes with degree 2.\n",
    "    The function merges two such edges by summing their lengths and other attributes. If at least one of the original \n",
    "    edges has an exit, the merged edge will also have an exit. The function removes nodes involved in the merge if \n",
    "    they are not exit nodes.\n",
    "\n",
    "    Parameters:\n",
    "    G (networkx.Graph): The input graph containing nodes and edges to be merged.\n",
    "    length_threshold (float): The maximum length below which edges will be merged.\n",
    "\n",
    "    Returns:\n",
    "    networkx.Graph: The modified graph with merged edges.\n",
    "    \"\"\"\n",
    "    # While there are edges to merge (based on the length threshold)\n",
    "    while any(\n",
    "        data.get('edgelength', float('inf')) < length_threshold and \n",
    "        G.degree[v] == 2\n",
    "        for u, v, data in G.edges(data=True)\n",
    "    ):\n",
    "        # Track if any merge occurs in this iteration\n",
    "        merged = False\n",
    "\n",
    "        # Iterate over a static list of edges\n",
    "        for u, v, data_uv in list(G.edges(data=True)):\n",
    "            # Skip merging if node v is an exit node or a crossing point\n",
    "            if G.nodes[v].get('is_exit') or G.degree[v] != 2:\n",
    "                continue  # Don't attempt to merge if node v is an exit node or a crossing\n",
    "\n",
    "            if data_uv.get('edgelength', float('inf')) < length_threshold:\n",
    "                neighbors = list(G.neighbors(v))\n",
    "\n",
    "                # Only proceed if the node v has exactly 2 neighbors as it will be the one removed\n",
    "                if G.degree[v] == 2:#true\n",
    "                    # Initialize variables to find the shortest neighbor\n",
    "                    shortest_length = float('inf')\n",
    "                    shortest_neighbor = None\n",
    "\n",
    "                    # Find the shortest neighbor n (of node v) to merge\n",
    "                    for n in neighbors:\n",
    "                        if n != u and G.degree[n] == 2:\n",
    "                            edge_length = G[v][n].get('edgelength', float('inf'))\n",
    "                            if edge_length < shortest_length:\n",
    "                                shortest_length = edge_length\n",
    "                                shortest_neighbor = n\n",
    "\n",
    "                    # If a shortest neighbor is found, perform the merge\n",
    "                    if shortest_neighbor is not None:\n",
    "                        # Edge data for the second edge\n",
    "                        data_vn = G[v][shortest_neighbor]\n",
    "\n",
    "                        # Compute merged length\n",
    "                        new_length = data_uv['edgelength'] + data_vn['edgelength']\n",
    "\n",
    "                        # Check if either edge has an exit\n",
    "                        has_exit = data_uv.get('has_exit') or data_vn.get('has_exit')\n",
    "\n",
    "                        # Create new edge data by merging attributes\n",
    "                        new_data = {\n",
    "                            'edgelength': new_length,\n",
    "                            'has_exit': has_exit,  # Set 'has_exit' based on the original edges\n",
    "                            'Build5m': data_uv.get('Build5m', 0) + data_vn.get('Build5m', 0),\n",
    "                            'Maintain5m': data_uv.get('Maintain5m', 0) + data_vn.get('Maintain5m', 0),\n",
    "                            'Build10m': data_uv.get('Build10m', 0) + data_vn.get('Build10m', 0),\n",
    "                            'Maintain10m': data_uv.get('Maintain10m', 0) + data_vn.get('Maintain10m', 0),\n",
    "                            'Upgrade': data_uv.get('Upgrade', 0) + data_vn.get('Upgrade', 0),\n",
    "                        }\n",
    "\n",
    "                        # Add merged edge\n",
    "                        G.add_edge(u, shortest_neighbor, **new_data)\n",
    "\n",
    "                        # Remove old edges\n",
    "                        if G.has_edge(u, v):\n",
    "                            G.remove_edge(u, v)\n",
    "                        if G.has_edge(v, shortest_neighbor):\n",
    "                            G.remove_edge(v, shortest_neighbor)\n",
    "\n",
    "                        # Remove node v\n",
    "                        if G.has_node(v):\n",
    "                            G.remove_node(v)\n",
    "\n",
    "                        # Mark as merged and break out to restart\n",
    "                        merged = True\n",
    "                        break\n",
    "\n",
    "            if merged:\n",
    "                break\n",
    "\n",
    "        # If no merges were performed, we're done\n",
    "        if not merged:\n",
    "            break\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### verify the result of merging [helper function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_merge(G_before_merge, G_after_merge):\n",
    "    \"\"\"\n",
    "    Verifies the merge by comparing the total sum of `edgelength` and costs \n",
    "    before and after the merge.\n",
    "\n",
    "    Parameters:\n",
    "        G_before_merge: The graph before merging.\n",
    "        G_after_merge: The graph after merging.\n",
    "    \"\"\"\n",
    "    def calculate_totals(G):\n",
    "        return {\n",
    "            'edgelength': sum(data.get('edgelength', 0) for _, _, data in G.edges(data=True)),\n",
    "            'Build5m': sum(data.get('Build5m', 0) for _, _, data in G.edges(data=True)),\n",
    "            'Maintain5m': sum(data.get('Maintain5m', 0) for _, _, data in G.edges(data=True)),\n",
    "            'Build10m': sum(data.get('Build10m', 0) for _, _, data in G.edges(data=True)),\n",
    "            'Maintain10m': sum(data.get('Maintain10m', 0) for _, _, data in G.edges(data=True)),\n",
    "            'Upgrade': sum(data.get('Upgrade', 0) for _, _, data in G.edges(data=True))\n",
    "        }\n",
    "    \n",
    "    totals_before = calculate_totals(G_before_merge)\n",
    "    totals_after = calculate_totals(G_after_merge)\n",
    "    \n",
    "    # Check for differences\n",
    "    differences = {key: round(totals_after[key] - totals_before[key], 2) for key in totals_before}\n",
    "    significant_differences = {k: v for k, v in differences.items() if v != 0}\n",
    "    \n",
    "    if significant_differences:\n",
    "        print(\"Warning: Differences detected in the following totals:\")\n",
    "        for key, value in significant_differences.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "    \n",
    "    return {\n",
    "        'deleted_edges': G_before_merge.number_of_edges() - G_after_merge.number_of_edges()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store debugging infos [helper function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_debug_infos(base_info, folder_path, name):\n",
    "    # Debugging Infos\n",
    "        total_vertices = len(vertices)\n",
    "        total_edges = len(edges)\n",
    "        #unique_road_segments = len(road_segments)\n",
    "        #merged_edges = total_edges - unique_road_segments\n",
    "\n",
    "        # Write info for the component to its individual text file\n",
    "        info_file_path = os.path.join(folder_path, f'info_{name}.txt')\n",
    "        with open(info_file_path, 'w') as info_file:\n",
    "            info_file.write(f\"Component {name} Information\\n\")\n",
    "            info_file.write(f\"----------------------------\\n\")\n",
    "            info_file.write(f\"Number of vertices: {total_vertices}\\n\")\n",
    "            info_file.write(f\"Total original edges: {total_edges}\\n\")\n",
    "            #info_file.write(f\"Unique road segments after removing duplicate (shared) edges: {unique_road_segments}\\n\")\n",
    "            #info_file.write(f\"Number of removed edges: {merged_edges}\\n\")\n",
    "            info_file.write(f\"Number of edge attributes: {len(attributes)}\\n\")\n",
    "            info_file.write(f\"Number of deleted edges due to merging of short ones: {results['deleted_edges']}\\n\")\n",
    "            info_file.write(f\"Totals Before Merge: {results['before']}\\n\")\n",
    "            info_file.write(f\"Totals After Merge: {results['after']}\\n\")\n",
    "            info_file.write(f\"Differences: {results['difference']}\\n\")\n",
    "            info_file.write(f\"Number of nodes per degree: {results['node_degrees']}\\n\")\n",
    "            info_file.write(f\"----------------------------\\n\")\n",
    "\n",
    "        # Write the aggregated summary to the base info file\n",
    "        base_info.write(f\"\\nComponent {name} Information\\n\")\n",
    "        base_info.write(f\"----------------------------\\n\")\n",
    "        base_info.write(f\"Number of vertices: {total_vertices}\\n\")\n",
    "        base_info.write(f\"Total original edges: {total_edges}\\n\")\n",
    "        #base_info.write(f\"Unique road segments after removing duplicate (shared) edges: {unique_road_segments}\\n\")\n",
    "        #base_info.write(f\"Number of removed edges: {merged_edges}\\n\")\n",
    "        base_info.write(f\"Number of edge attributes: {len(attributes)}\\n\")\n",
    "        base_info.write(f\"Number of deleted edges due to merging of short ones: {results['deleted_edges']}\\n\")\n",
    "        base_info.write(f\"Totals Before Merge: {results['before']}\\n\")\n",
    "        base_info.write(f\"Totals After Merge: {results['after']}\\n\")\n",
    "        base_info.write(f\"Differences: {results['difference']}\\n\")\n",
    "        base_info.write(f\"Number of nodes per degree: {results['node_degrees']}\\n\")\n",
    "        base_info.write(f\"----------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Handle source nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create source nodes for each stand [helper function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### assign costs to source nodes [helper function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Step 1-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing component: component_10\n",
      "2 exit points already exist\n",
      "2 exit points added\n",
      "component_10 costs assigned\n",
      "Processing component: component_11\n",
      "1 exit points already exist\n",
      "1 exit points added\n",
      "component_11 costs assigned\n",
      "Processing component: component_12\n",
      "7 exit points already exist\n",
      "8 exit points added\n",
      "component_12 costs assigned\n",
      "Processing component: component_13\n",
      "Exit node (-14725.76646, 148708.12995) is already part of the edge ((-14854.02958, 148755.56971), (-14725.76646, 148708.12995)). Marking it with 'has_exit'.\n",
      "Exit node (-14511.22747, 148637.70934) is already part of the edge ((-14568.27898, 148670.90301), (-14511.22747, 148637.70934)). Marking it with 'has_exit'.\n",
      "Exit node (-14482.92326, 148621.2414) is already part of the edge ((-14451.86208, 148603.16941), (-14482.92326, 148621.2414)). Marking it with 'has_exit'.\n",
      "Exit node (-14433.07574, 148589.79609) is already part of the edge ((-14451.86208, 148603.16941), (-14433.07574, 148589.79609)). Marking it with 'has_exit'.\n",
      "8 exit points already exist\n",
      "13 exit points added\n",
      "component_13 costs assigned\n",
      "Processing component: component_14\n",
      "Exit node (-9984.20277, 146563.07825) is already part of the edge ((-10017.96688, 146572.53221), (-9984.20277, 146563.07825)). Marking it with 'has_exit'.\n",
      "Exit node (-9988.06853, 146375.41721) is already part of the edge ((-10006.06058, 146375.41721), (-9988.06853, 146375.41721)). Marking it with 'has_exit'.\n",
      "Exit node (-9668.512, 145677.10047) is already part of the edge ((-9645.19858, 145672.96421), (-9668.512, 145677.10047)). Marking it with 'has_exit'.\n",
      "Exit node (-10000.51986, 146251.47094) is already part of the edge ((-10171.53348, 146040.09591), (-10000.51986, 146251.47094)). Marking it with 'has_exit'.\n",
      "Exit node (-9913.6735, 145997.5426) is already part of the edge ((-9924.07008, 145978.42631), (-9913.6735, 145997.5426)). Marking it with 'has_exit'.\n",
      "Exit node (-9860.92361, 145931.46244) is already part of the edge ((-9888.35118, 145888.46781), (-9860.92361, 145931.46244)). Marking it with 'has_exit'.\n",
      "5 exit points already exist\n",
      "19 exit points added\n",
      "component_14 costs assigned\n",
      "Processing component: component_15\n",
      "Exit node (-13425.68547, 151948.79471) is already part of the edge ((-13419.44358, 151970.31321), (-13425.68547, 151948.79471)). Marking it with 'has_exit'.\n",
      "3 exit points already exist\n",
      "4 exit points added\n",
      "component_15 costs assigned\n",
      "Processing component: component_16\n",
      "0 exit points already exist\n",
      "1 exit points added\n",
      "component_16 costs assigned\n",
      "Processing component: component_17\n",
      "Exit node (-12265.6432, 151204.889) is already part of the edge ((-12283.13698, 151212.98991), (-12265.6432, 151204.889)). Marking it with 'has_exit'.\n",
      "Exit node (-12373.66408, 151017.43164) is already part of the edge ((-12316.39918, 151023.63861), (-12373.66408, 151017.43164)). Marking it with 'has_exit'.\n",
      "Exit node (-12211.4194, 151445.35873) is already part of the edge ((-12175.53648, 151431.44301), (-12211.4194, 151445.35873)). Marking it with 'has_exit'.\n",
      "1 exit points already exist\n",
      "11 exit points added\n",
      "component_17 costs assigned\n",
      "Processing component: component_18\n",
      "23 exit points already exist\n",
      "23 exit points added\n",
      "component_18 costs assigned\n",
      "Processing component: component_19\n",
      "4 exit points already exist\n",
      "2 exit points added\n",
      "component_19 costs assigned\n",
      "Processing component: component_1\n",
      "Exit node (-20855.40696, 152286.94596) is already part of the edge ((-20894.65738, 152294.33101), (-20855.40696, 152286.94596)). Marking it with 'has_exit'.\n",
      "6 exit points already exist\n",
      "12 exit points added\n",
      "component_1 costs assigned\n",
      "Processing component: component_20\n",
      "Exit node (-10000.61717, 149694.17443) is already part of the edge ((-9976.24618, 149694.22161), (-10000.61717, 149694.17443)). Marking it with 'has_exit'.\n",
      "Exit node (-10269.17415, 149957.4208) is already part of the edge ((-10260.60268, 149968.31281), (-10269.17415, 149957.4208)). Marking it with 'has_exit'.\n",
      "2 exit points already exist\n",
      "7 exit points added\n",
      "component_20 costs assigned\n",
      "Processing component: component_21\n",
      "Exit node (-18503.2236, 149519.86065) is already part of the edge ((-18553.08138, 149562.03561), (-18503.2236, 149519.86065)). Marking it with 'has_exit'.\n",
      "Exit node (-18829.90115, 149411.86516) is already part of the edge ((-18805.75758, 149406.29991), (-18829.90115, 149411.86516)). Marking it with 'has_exit'.\n",
      "Exit node (-19128.69942, 149815.47209) is already part of the edge ((-19103.88308, 149820.98701), (-19128.69942, 149815.47209)). Marking it with 'has_exit'.\n",
      "Exit node (-19666.52518, 149136.00578) is already part of the edge ((-19636.21338, 149142.39861), (-19666.52518, 149136.00578)). Marking it with 'has_exit'.\n",
      "Exit node (-18490.60597, 149526.7322) is already part of the edge ((-18480.18678, 149559.09321), (-18490.60597, 149526.7322)). Marking it with 'has_exit'.\n",
      "Exit node (-19733.36518, 149565.05353) is already part of the edge ((-19753.60688, 149559.02921), (-19733.36518, 149565.05353)). Marking it with 'has_exit'.\n",
      "Exit node (-19913.17696, 149560.30699) is already part of the edge ((-19925.05728, 149556.91261), (-19913.17696, 149560.30699)). Marking it with 'has_exit'.\n",
      "33 exit points already exist\n",
      "40 exit points added\n",
      "component_21 costs assigned\n",
      "Processing component: component_22\n",
      "6 exit points already exist\n",
      "8 exit points added\n",
      "component_22 costs assigned\n",
      "Processing component: component_23\n",
      "1 exit points already exist\n",
      "5 exit points added\n",
      "component_23 costs assigned\n",
      "Processing component: component_24\n",
      "Exit node (-9938.65227, 149154.81321) is already part of the edge ((-9956.90198, 149155.55691), (-9938.65227, 149154.81321)). Marking it with 'has_exit'.\n",
      "Exit node (-9799.49707, 149327.06965) is already part of the edge ((-9752.94028, 149326.58331), (-9799.49707, 149327.06965)). Marking it with 'has_exit'.\n",
      "6 exit points already exist\n",
      "18 exit points added\n",
      "component_24 costs assigned\n",
      "Processing component: component_25\n",
      "Exit node (-11982.65825, 153501.88596) is already part of the edge ((-11964.83178, 153491.57111), (-11982.65825, 153501.88596)). Marking it with 'has_exit'.\n",
      "0 exit points already exist\n",
      "7 exit points added\n",
      "component_25 costs assigned\n",
      "Processing component: component_26\n",
      "Exit node (-8987.80826, 154263.83146) is already part of the edge ((-9015.72998, 154269.88901), (-8987.80826, 154263.83146)). Marking it with 'has_exit'.\n",
      "8 exit points already exist\n",
      "10 exit points added\n",
      "component_26 costs assigned\n",
      "Processing component: component_2\n",
      "Exit node (-17124.67922, 152350.38854) is already part of the edge ((-17075.48728, 152358.91511), (-17124.67922, 152350.38854)). Marking it with 'has_exit'.\n",
      "2 exit points already exist\n",
      "3 exit points added\n",
      "component_2 costs assigned\n",
      "Processing component: component_3\n",
      "Exit node (-11298.81805, 144346.94946) is already part of the edge ((-11320.00928, 144379.32771), (-11298.81805, 144346.94946)). Marking it with 'has_exit'.\n",
      "Exit node (-11345.44256, 144244.06245) is already part of the edge ((-11372.82138, 144227.12571), (-11345.44256, 144244.06245)). Marking it with 'has_exit'.\n",
      "Exit node (-11051.44306, 144481.72032) is already part of the edge ((-11059.54818, 144474.97531), (-11051.44306, 144481.72032)). Marking it with 'has_exit'.\n",
      "Exit node (-13563.25154, 145364.09884) is already part of the edge ((-13616.96968, 145393.15941), (-13563.25154, 145364.09884)). Marking it with 'has_exit'.\n",
      "Exit node (-13759.39692, 145318.22574) is already part of the edge ((-13785.81918, 145315.53891), (-13759.39692, 145318.22574)). Marking it with 'has_exit'.\n",
      "Exit node (-13786.78596, 145304.54738) is already part of the edge ((-13785.81918, 145315.53891), (-13786.78596, 145304.54738)). Marking it with 'has_exit'.\n",
      "Exit node (-14259.51482, 145246.99947) is already part of the edge ((-14261.13518, 145233.19071), (-14259.51482, 145246.99947)). Marking it with 'has_exit'.\n",
      "34 exit points already exist\n",
      "43 exit points added\n",
      "component_3 costs assigned\n",
      "Processing component: component_4\n",
      "Exit node (-8896.59689, 153205.36205) is already part of the edge ((-8878.71948, 153202.01151), (-8896.59689, 153205.36205)). Marking it with 'has_exit'.\n",
      "Exit node (-9563.08336, 152630.40536) is already part of the edge ((-9641.13128, 152723.27561), (-9563.08336, 152630.40536)). Marking it with 'has_exit'.\n",
      "9 exit points already exist\n",
      "11 exit points added\n",
      "component_4 costs assigned\n",
      "Processing component: component_5\n",
      "4 exit points already exist\n",
      "6 exit points added\n",
      "component_5 costs assigned\n",
      "Processing component: component_6\n",
      "Exit node (-15032.51192, 154004.65843) is already part of the edge ((-15014.18668, 154002.06851), (-15032.51192, 154004.65843)). Marking it with 'has_exit'.\n",
      "Exit node (-14857.24075, 153996.39466) is already part of the edge ((-14841.81778, 153992.33571), (-14857.24075, 153996.39466)). Marking it with 'has_exit'.\n",
      "Exit node (-15124.80995, 154024.99935) is already part of the edge ((-15191.70698, 154023.82671), (-15124.80995, 154024.99935)). Marking it with 'has_exit'.\n",
      "16 exit points already exist\n",
      "23 exit points added\n",
      "component_6 costs assigned\n",
      "Processing component: component_7\n",
      "Exit node (-19724.47581, 151109.50839) is already part of the edge ((-19750.30438, 151091.13371), (-19724.47581, 151109.50839)). Marking it with 'has_exit'.\n",
      "20 exit points already exist\n",
      "17 exit points added\n",
      "component_7 costs assigned\n",
      "Processing component: component_8\n"
     ]
    }
   ],
   "source": [
    "### WORKFLOW ###\n",
    "# Define output path for aggregated component information\n",
    "#base_info_file = f'{out_directory}/info.txt'\n",
    "#write_base_info_header(base_info_file)  # Write header for summary file\n",
    "\n",
    "for name, df in components.items():\n",
    "    print(f\"Processing component: {name}\")\n",
    "\n",
    "    # Create a dedicated folder for the current component\n",
    "    component_folder = f\"{out_directory}/{name}\"\n",
    "    os.makedirs(component_folder, exist_ok=True)\n",
    "\n",
    "    # Extract key graph-related data from the component's dataframe\n",
    "    vertices, edges, attributes, exit_points = extract_boundaries_with_attributes(df)\n",
    "\n",
    "    # Save the extracted data for further use\n",
    "    store_data_for_graph(component_folder, vertices, edges, attributes, name)\n",
    "\n",
    "    # Construct the initial graph representation\n",
    "    G = create_graph(vertices, edges, attributes)\n",
    "\n",
    "    # Visualize and save the initial graph\n",
    "    plot_and_save(component_folder, G, name, prefix='0graph')\n",
    "\n",
    "    # Process exit points: determine which are contained and which need to be added\n",
    "    contained_count, to_add_count = handle_exit_points(G, exit_points)\n",
    "    print(f\"{contained_count} exit points already exist\")\n",
    "    print(f\"{to_add_count} exit points added\")\n",
    "\n",
    "    # Update and save the graph after handling exit points\n",
    "    plot_and_save(component_folder, G, name, prefix='1withexits_graph')\n",
    "\n",
    "    # Store the updated graph data, including nodes and edges with attributes\n",
    "    store_updated_graph_data(component_folder, G, name, prefix='1withexits')   \n",
    "\n",
    "    #### ASSIGNING COSTS TO EDGES ####\n",
    "\n",
    "    # Assign cost values to all edges in the graph\n",
    "    G = assign_all_costs_to_edges(G)\n",
    "\n",
    "    # Save and visualize the graph with assigned edge costs\n",
    "    store_updated_graph_data(component_folder, G, name, prefix='2withcosts')\n",
    "    plot_and_save(component_folder, G, name, prefix='2withcosts_graph')\n",
    "\n",
    "    #### MERGING SHORT EDGES ####\n",
    "\n",
    "    # Create a copy of the graph before merging short edges for comparison\n",
    "    G_before_merge = G.copy()\n",
    "        \n",
    "    # Merge edges that are shorter than the specified length threshold\n",
    "    G = merge_short_edges(G, length_threshold=1000)\n",
    "\n",
    "    # Visualize and save the updated graph after merging short edges\n",
    "    plot_and_save(component_folder, G, name, prefix='3aftermerge_graph')\n",
    "\n",
    "    # Store the updated graph data with merged edges\n",
    "    store_updated_graph_data(component_folder, G, name, prefix='3aftermerge') \n",
    "\n",
    "    # Uncomment if you want to write debug information for further analysis\n",
    "    # write_debug_infos(base_info, component_folder, name)\n",
    "\n",
    "# Once all components are processed, a summary file containing aggregated information is saved\n",
    "# print(f\"Aggregated information for all components saved in {base_info_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
