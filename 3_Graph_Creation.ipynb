{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a graph for the possible future road network\n",
    "For each component of stands that is not connected to any roads (respective: big roads), we wanna create a network of possible future road segments which strictly follow the boundaries of the forest stands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "import math\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# Import third-party libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import missingno as msno\n",
    "\n",
    "# Import geometrical and spatial libraries\n",
    "from shapely.geometry import MultiPolygon, Polygon, Point, LineString\n",
    "from shapely import wkt\n",
    "\n",
    "# Import plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input and output paths\n",
    "inpath = r\"1_Preprocessed_Data\\2_Stand_Components\\unconnected_to_roads\\2_nonsingle_inaccessible_components_with_ring_of_accessible_neighbors\"\n",
    "out_directory = r\"1_Preprocessed_Data\\3_Road_Network_Graphs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component 'component_10' loaded with 9 stands.\n",
      "Component 'component_11' loaded with 3 stands.\n",
      "Component 'component_12' loaded with 6 stands.\n",
      "Component 'component_13' loaded with 7 stands.\n",
      "Component 'component_14' loaded with 14 stands.\n",
      "Component 'component_15' loaded with 5 stands.\n",
      "Component 'component_16' loaded with 4 stands.\n",
      "Component 'component_17' loaded with 6 stands.\n",
      "Component 'component_18' loaded with 17 stands.\n",
      "Component 'component_19' loaded with 4 stands.\n",
      "Component 'component_1' loaded with 6 stands.\n",
      "Component 'component_20' loaded with 5 stands.\n",
      "Component 'component_21' loaded with 30 stands.\n",
      "Component 'component_22' loaded with 10 stands.\n",
      "Component 'component_23' loaded with 4 stands.\n",
      "Component 'component_24' loaded with 12 stands.\n",
      "Component 'component_25' loaded with 5 stands.\n",
      "Component 'component_26' loaded with 10 stands.\n",
      "Component 'component_2' loaded with 4 stands.\n",
      "Component 'component_3' loaded with 91 stands.\n",
      "Component 'component_4' loaded with 9 stands.\n",
      "Component 'component_5' loaded with 4 stands.\n",
      "Component 'component_6' loaded with 18 stands.\n",
      "Component 'component_7' loaded with 22 stands.\n",
      "Component 'component_8' loaded with 48 stands.\n",
      "Component 'component_9' loaded with 4 stands.\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary\n",
    "components = {}\n",
    "\n",
    "# List all shapefiles in the directory\n",
    "shapefiles = [f.path for f in os.scandir(inpath) if f.is_file() and f.name.endswith('.shp')]\n",
    "\n",
    "for shapefile_path in shapefiles:\n",
    "    # Extract the filename without extension\n",
    "    filename = os.path.splitext(os.path.basename(shapefile_path))[0]\n",
    "    \n",
    "    # Extract the part after \"combi_\"\n",
    "    key = filename.split('_stands')[0] if '_stands' in filename else filename\n",
    "    \n",
    "    # Load the shapefile into a GeoDataFrame\n",
    "    components[key] = gpd.read_file(shapefile_path)\n",
    "    \n",
    "    print(f\"Component '{key}' loaded with {len(components[key])} stands.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>TARGET_FID</th>\n",
       "      <th>LandUse_1</th>\n",
       "      <th>Ocupacao</th>\n",
       "      <th>ID_UG</th>\n",
       "      <th>NOME</th>\n",
       "      <th>YY_correct</th>\n",
       "      <th>XX_Correct</th>\n",
       "      <th>Altitude</th>\n",
       "      <th>Declive</th>\n",
       "      <th>...</th>\n",
       "      <th>Area</th>\n",
       "      <th>Hectares</th>\n",
       "      <th>UsoSolo20</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>HBC</th>\n",
       "      <th>CH</th>\n",
       "      <th>CBD</th>\n",
       "      <th>CC</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131</td>\n",
       "      <td>761</td>\n",
       "      <td>1</td>\n",
       "      <td>EcEc_2_3_3_Pv</td>\n",
       "      <td>840</td>\n",
       "      <td>Castelo de Paiva</td>\n",
       "      <td>152302.982524</td>\n",
       "      <td>-20400.888754</td>\n",
       "      <td>215.0</td>\n",
       "      <td>22.5796</td>\n",
       "      <td>...</td>\n",
       "      <td>73670.927386</td>\n",
       "      <td>7.367093</td>\n",
       "      <td>Eucalipto</td>\n",
       "      <td>1191.720013</td>\n",
       "      <td>73670.935166</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>POLYGON ((-20161.533 152306.823, -20213.551 15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID  TARGET_FID  LandUse_1       Ocupacao  ID_UG              NOME  \\\n",
       "0       131         761          1  EcEc_2_3_3_Pv    840  Castelo de Paiva   \n",
       "\n",
       "      YY_correct    XX_Correct  Altitude  Declive  ...          Area  \\\n",
       "0  152302.982524 -20400.888754     215.0  22.5796  ...  73670.927386   \n",
       "\n",
       "   Hectares  UsoSolo20   Shape_Leng    Shape_Area  HBC   CH  CBD   CC  \\\n",
       "0  7.367093  Eucalipto  1191.720013  73670.935166  2.9  0.0  0.0  0.0   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((-20161.533 152306.823, -20213.551 15...  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "components['component_1'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Projected CRS: PROJCRS[\"ETRS89 / Portugal TM06\",BASEGEOGCRS[\"ETRS ...>\n",
       "Name: ETRS89 / Portugal TM06\n",
       "Axis Info [cartesian]:\n",
       "- E[east]: Easting (metre)\n",
       "- N[north]: Northing (metre)\n",
       "- h[up]: Ellipsoidal height (metre)\n",
       "Area of Use:\n",
       "- undefined\n",
       "Coordinate Operation:\n",
       "- name: unnamed\n",
       "- method: Transverse Mercator\n",
       "Datum: European Terrestrial Reference System 1989\n",
       "- Ellipsoid: GRS 1980\n",
       "- Prime Meridian: Greenwich"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "components['component_1'].crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load road data\n",
    "roads = gpd.read_file(r'1_Preprocessed_Data\\1_Roads_clean\\roads_clean.shp')\n",
    "roads = roads.to_crs(components['component_1'].crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extract vertices and edges with attributes (slope, edge length) and exit points from boundaries [helper functions]\n",
    "From the boundaries of the stands, we extract all points with coordianates and additionally save the edges (lines) connecting them. \n",
    "\n",
    "Note: We only want need exterior boundaries, and NO roads along interior boundaries of a forest stand (because such interior roads would not help with connecting the stands to the existing road network).\n",
    "\n",
    "There will be helper functions for step I consider important enough to mention them seperately, even if the function might be a single line of code, it helps to beter understand the structure and what happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Snap coordinates to grid [helper function] \n",
    "Before comparing edges, snap all coordinates to a common grid (round coordinates to a fixed number of decimal places). This helps ensure that neighboring stands with slightly different coordinate representations share identical coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snap_to_grid(coord, precision):\n",
    "    \"\"\"\n",
    "    Snaps the given coordinates to the specified precision.\n",
    "\n",
    "    Parameters:\n",
    "        coord (tuple or list): A tuple or list containing the x, y (and optionally z) coordinates to be snapped.\n",
    "        precision (int): The number of decimal places to round the coordinates.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple of coordinates rounded to the specified precision.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the input is not a tuple or list, or if any coordinate is NaN or infinite.\n",
    "    \"\"\"\n",
    "    # Check if input is a tuple or list\n",
    "    if not isinstance(coord, (tuple, list)):\n",
    "        raise ValueError(\"Input must be a tuple or list of coordinates\")\n",
    "\n",
    "    # Check for NaN or infinity values\n",
    "    if any(map(lambda c: isinstance(c, (float, int)) and (math.isnan(c) or math.isinf(c)), coord)):\n",
    "        raise ValueError(\"Coordinate contains NaN or infinite values\")\n",
    "    \n",
    "    # Round coordinates to the specified precision\n",
    "    return tuple(round(c, precision) for c in coord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Calculate attributes [helper function]\n",
    "To calculate the costs, we need to know for each edge its edge length and its approximative slope.\n",
    "- *edgelength*: The length of an edge (u,v) is calculated using the Euclidean distance formula, to compute the distance between the coordinates of points u and v.\n",
    "- *slope (approx.)*: The slope of an edge is approximated by the slope (\"Declive\") of the polygon the edge belongs to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shapefile contains 2D geometries (no altitude per coordinate).\n",
      "The shapefile has an 'Altitude' column (single altitude per polygon).\n"
     ]
    }
   ],
   "source": [
    "# Check geometry dimension for the one example component\n",
    "component = next(iter(components.values()))  # Get the first component\n",
    "geometry = component.geometry.iloc[0]\n",
    "\n",
    "if geometry.has_z:\n",
    "    print(\"The shapefile contains 3D geometries with Z-values (altitudes per coordinate).\")\n",
    "else:\n",
    "    print(\"The shapefile contains 2D geometries (no altitude per coordinate).\")\n",
    "    \n",
    "    # Check for altitude attribute\n",
    "    if 'Altitude' in component.columns:\n",
    "        print(\"The shapefile has an 'Altitude' column (single altitude per polygon).\")\n",
    "    else: \n",
    "        print(\"No 'Altitude' column found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If we knew the altitude per coordinate, the slope could be approximated via the ratio of the altitude difference to the edgelength; but the edges all belong to the same polygon so we only have one single altitude per polygon (which would lead to a slope of 0). Therefore, we just take the slope (\"Declive\") of the polygon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_edge_length(u, v):\n",
    "    \"\"\"\n",
    "    Calculate the length of the edge defined by two vertices (u, v).\n",
    "\n",
    "    Parameters:\n",
    "        u (tuple): A tuple representing the coordinates (x, y) of the first vertex.\n",
    "        v (tuple): A tuple representing the coordinates (x, y) of the second vertex.\n",
    "\n",
    "    Returns:\n",
    "        float: The length of the edge between vertices u and v.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the input coordinates are not tuples or lists of length 2.\n",
    "    \"\"\"\n",
    "    # Ensure the input coordinates are valid (tuples of length 2)\n",
    "    if not (isinstance(u, (tuple, list)) and len(u) == 2) or not (isinstance(v, (tuple, list)) and len(v) == 2):\n",
    "        raise ValueError(\"Both u and v must be tuples or lists of length 2 representing coordinates.\")\n",
    "\n",
    "    # Create a LineString object to calculate the edge length\n",
    "    line = LineString([u, v])\n",
    "\n",
    "    edgelength = line.length / 1000 #line.lengh gives length in meter because we use projected CRS. divide by 1000 because meter -> km\n",
    "\n",
    "    # Return the length of the line\n",
    "    return edgelength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Extract nodes, edges, attributes [helper function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_boundaries_with_attributes(outpath, stands, precision=5):\n",
    "    \"\"\"\n",
    "    Extracts the vertices, edges, edge attributes (such as edge length and slope),\n",
    "    and exit points (intersections with roads) from polygon geometries in the input \n",
    "    stands dataset. Coordinates and intersections are snapped to a grid for precision.\n",
    "\n",
    "    Parameters:\n",
    "        stands (GeoDataFrame): A GeoDataFrame containing the stand boundaries and \n",
    "                                associated data. Each feature must have a polygon geometry.\n",
    "        precision (int, optional, default=4): The precision to which the coordinates \n",
    "                                              will be snapped when extracted (controls decimal places).\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing four elements:\n",
    "            - vertices (list of tuples): A list of unique vertices (coordinates of stand boundary points)\n",
    "            - edges (list of tuples): A list of edges (pairs of vertices)\n",
    "            - edge_attributes (list of dicts): A list of dictionaries containing edge attributes (edge length, slope)\n",
    "            - exit_points (list of tuples): A list of exit points (coordinates where stand boundaries intersect roads)\n",
    "    \"\"\"\n",
    "    boundary_points = set()  # Using set to avoid duplicate vertices\n",
    "    boundary_edges = []\n",
    "    edge_attributes = []\n",
    "    exit_points = []\n",
    "    node_to_stands = {}  # Dictionary to store which stands each node belongs to\n",
    "\n",
    "    for _, feature in stands.iterrows():\n",
    "        stand_id = feature['ID_UG']  # Unique identifier for the stand\n",
    "        geometry = feature.geometry\n",
    "        slope = feature['Declive']\n",
    "\n",
    "        if geometry.geom_type == 'Polygon':\n",
    "            # Snap coordinates for the exterior\n",
    "            exterior_coords = [snap_to_grid(coord, precision) for coord in geometry.exterior.coords]\n",
    "            boundary_points.update(exterior_coords)\n",
    "\n",
    "            # Track which nodes belong to which stands\n",
    "            for node in exterior_coords:#[:-1]:  # Ignore duplicate last point\n",
    "                if node not in node_to_stands:\n",
    "                    node_to_stands[node] = set()  # Use a set to avoid duplicates\n",
    "                node_to_stands[node].add(stand_id)\n",
    "\n",
    "            # Creating edges\n",
    "            for i in range(len(exterior_coords) - 1):\n",
    "                u, v = exterior_coords[i], exterior_coords[i + 1]\n",
    "                boundary_edges.append((u, v))\n",
    "\n",
    "                # Edge length and slope\n",
    "                edge_length = calculate_edge_length(u, v)\n",
    "                edge_attributes.append({'edgelength': edge_length,\n",
    "                                        'slope': slope,\n",
    "                                        'has_exit': False,\n",
    "                                        'has_source': False})\n",
    "\n",
    "            # Find intersections with roads (exit points)\n",
    "            stand_boundary = geometry.exterior  # Stand polygon boundary\n",
    "            for road in roads.geometry:\n",
    "                if stand_boundary.intersects(road):  # Only proceed if there is an intersection\n",
    "                    intersection = stand_boundary.intersection(road)\n",
    "                    \n",
    "                    # Process intersections\n",
    "                    if intersection.geom_type == 'Point':\n",
    "                        exit_points.append(snap_to_grid((intersection.x, intersection.y), precision))\n",
    "                    elif intersection.geom_type == 'MultiPoint':\n",
    "                        exit_points.extend([snap_to_grid((point.x, point.y), precision) for point in intersection.geoms])\n",
    "\n",
    "            # Track which exitnodes belong to which stands (exit points)\n",
    "            for exit_node in exit_points:  # For exit nodes only\n",
    "                if exit_node not in node_to_stands:\n",
    "                    node_to_stands[exit_node] = set()  # Use a set to avoid duplicates\n",
    "                    node_to_stands[exit_node].add(stand_id)            \n",
    "\n",
    "    # Convert sets to lists for easier graph storage\n",
    "    node_to_stands = {node: list(stand_ids) for node, stand_ids in node_to_stands.items()} \n",
    "\n",
    "    # Save as CSV\n",
    "    with open(f'{outpath}/node_to_stands.csv', 'w', newline='') as f:\n",
    "        csv.writer(f).writerow(['Node', 'Stand'])  # Write header\n",
    "        csv.writer(f).writerows(node_to_stands.items())  # Write data rows\n",
    "\n",
    "    return list(boundary_points), boundary_edges, edge_attributes, exit_points, node_to_stands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create the Graph\n",
    "Next, we'll use these vertices and edges to build a graph. This graph will represent the potential road network, where the roads are constrained to follow the boundaries of the forest stands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ’¾ Storing graph data [helper function] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_data_for_graph(out_path, vertices, edges, attributes, name):\n",
    "    \"\"\"\n",
    "    Saves the data for the graph (vertices, edges, and attributes) into CSV files within a specified folder.\n",
    "\n",
    "    Parameters:\n",
    "        out_path (str): The directory where the CSV files will be saved.\n",
    "        vertices (list): A list of vertex coordinates (x, y) to be saved.\n",
    "        edges (list): A list of edges, each represented by a tuple of vertices.\n",
    "        attributes (list): A list of dictionaries containing edge attributes (e.g., 'edgelength', 'slope').\n",
    "        name (str): The name of the component, used in the file naming.\n",
    "        G (networkx.Graph): The graph containing node attributes, including `is_exit`.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the folder exists\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "    name=\"\"\n",
    "\n",
    "    # File paths\n",
    "    vertices_file = os.path.join(out_path, f'nodes_{name}.csv')\n",
    "    edges_file = os.path.join(out_path, f'edges_{name}.csv')\n",
    "    attributes_file = os.path.join(out_path, f'attributes_{name}.csv')\n",
    "    edges_with_attributes_file = os.path.join(out_path, f'edges_with_attributes_{name}.csv')\n",
    "\n",
    "    # Save vertices to CSV with the 'is_exit' column\n",
    "    vertices_data = [{'x': x, 'y': y, } for x, y in vertices]\n",
    "    pd.DataFrame(vertices_data).to_csv(vertices_file, index=False)\n",
    "\n",
    "    # Save edges to CSV\n",
    "    edges_data = [(f\"({u[0]}, {u[1]})\", f\"({v[0]}, {v[1]})\") for u, v in edges]\n",
    "    pd.DataFrame(edges_data, columns=['Node1(x,y)', 'Node2(x,y)']).to_csv(edges_file, index=False)\n",
    "\n",
    "    # Save attributes to CSV\n",
    "    pd.DataFrame(attributes).to_csv(attributes_file, index=False)\n",
    "\n",
    "    # Save edges with attributes to CSV\n",
    "    edges_attributes_data = [\n",
    "        {\n",
    "            'Node1(x,y)': f\"({u[0]}, {u[1]})\",\n",
    "            'Node2(x,y)': f\"({v[0]}, {v[1]})\",\n",
    "            'edgelength': attributes['edgelength'],\n",
    "            'slope': attributes['slope'],\n",
    "            'has_exit': attributes['has_exit'],\n",
    "            'has_source': attributes['has_source']\n",
    "        }\n",
    "        for (u, v), attributes in zip(edges, attributes)\n",
    "    ]\n",
    "    pd.DataFrame(edges_attributes_data).to_csv(edges_with_attributes_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create graph and digraph from vertices, edges, attributes [helper function] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(vertices, edges, attributes, node_to_stands):\n",
    "    \"\"\"\n",
    "    Create an undirected graph using NetworkX based on the provided vertices, edges, and edge attributes.\n",
    "\n",
    "    Parameters:\n",
    "        vertices (list): A list of vertices (nodes) to be added to the graph.\n",
    "        edges (list): A list of edges represented as tuples (u, v), where u and v are vertices.\n",
    "        attributes (list): A list of dictionaries, where each dictionary contains edge attributes \n",
    "                           (such as 'weight', 'length', 'has_exit', etc.) corresponding to each edge.\n",
    "\n",
    "    Returns:\n",
    "        nx.Graph: A NetworkX Graph object containing the nodes, edges, and associated attributes.\n",
    "    \n",
    "    Example:\n",
    "        vertices = [(x1, y1), (x2, y2), (x3, y3)]\n",
    "        edges = [((x1, y1), (x2, y2)),\n",
    "                 ((x2, y2), (x3, y3))]\n",
    "        attributes = [\n",
    "            {'edgelength': 74.92801170857655, 'slope': 18.0777, 'has_exit': False},\n",
    "            {'edgelength': 61.5825216583405, 'slope': 18.0777, 'has_exit': False}\n",
    "        ]\n",
    "    \"\"\"\n",
    "\n",
    "    if len(edges) != len(attributes):\n",
    "        raise ValueError(\"The number of edges and attributes must match.\")\n",
    "\n",
    "    G = nx.Graph()\n",
    "    for node in vertices:\n",
    "        G.add_node(node, is_exit=False, is_source=False, stands=node_to_stands.get(node, [])) \n",
    "\n",
    "    for edge, attr in zip(edges, attributes):\n",
    "        u, v = edge\n",
    "        # Add the edge with the attributes\n",
    "        G.add_edge(u, v, **attr)\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot graph and store image [helper function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save(outpath, G, name, prefix):\n",
    "    \"\"\"Plots the graph 'G' along with associated geographical components and saves the plot to a file.\n",
    "\n",
    "    Parameters:\n",
    "        G (nx.Graph): The NetworkX graph object to be plotted.\n",
    "        name (str): The name of the component, used in the plot title and file naming.\n",
    "        filename (str): The path and filename where the plot will be saved.\n",
    "\n",
    "    Saves:\n",
    "        A PNG image containing:\n",
    "            - The geographical component from the 'components' GeoDataFrame.\n",
    "            - The graph 'G' overlaid with nodes and edges.\n",
    "            - A summary of node degrees, total edge length, and number of exit nodes as an annotation.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    filename=os.path.join(outpath,f'{prefix}_{name}.png')\n",
    "\n",
    "    components[name].plot(ax=plt.gca(), color='lightgray', alpha=0.5)  # Add GeoDataFrame\n",
    "    components[name].apply(lambda row: plt.annotate(text=row['ID_UG'], \n",
    "                                                xy=(row.geometry.centroid.x, row.geometry.centroid.y), \n",
    "                                                xytext=(3, 3), textcoords=\"offset points\", \n",
    "                                                fontsize=8, color='black'), axis=1)\n",
    "\n",
    "    \n",
    "    # Prepare node colors\n",
    "    nodecolor = [\n",
    "        (0, 1, 0, 0.5) if G.nodes[node].get('is_source') else (1, 0, 0, 1) if G.nodes[node].get('is_exit') else (0, 0, 1, 1)\n",
    "        for node in G.nodes()\n",
    "    ]\n",
    "\n",
    "    # Prepare edge colors\n",
    "    edgecolors = [\n",
    "        (0, 1, 0, 0.5) if G[u][v].get('has_source') else (0, 0, 1, 1)\n",
    "        for u, v in G.edges()\n",
    "    ]\n",
    "\n",
    "    nx.draw(G, pos={node: node for node in G.nodes()}, node_size=50, \n",
    "            node_color=nodecolor, edge_color=edgecolors, with_labels=False)\n",
    "    \n",
    "    # Get degree of each node\n",
    "    degree_counts = Counter(dict(G.degree()).values())\n",
    "\n",
    "    # Calculate total edge length\n",
    "    total_edge_length = sum(G[u][v].get('edgelength', 0) for u, v in G.edges())\n",
    "\n",
    "    # Calculate total costs across multiple attributes\n",
    "    # List of required attributes\n",
    "    cost_attributeskeys = ['Build5m', 'Maintain5m', 'Build10m', 'Maintain10m', 'Upgrade']\n",
    "\n",
    "    # Check if all required attributes exist in any edge\n",
    "    costattributes_exist = all(any(attr in G[u][v] for u, v in G.edges()) for attr in cost_attributeskeys)\n",
    "\n",
    "    if costattributes_exist:\n",
    "\n",
    "        # Calculate total costs if the attributes exist\n",
    "        total_costs = sum(\n",
    "            G[u][v].get('Build5', 0) + \n",
    "            G[u][v].get('Maintain5', 0) + \n",
    "            G[u][v].get('Build10', 0) + \n",
    "            G[u][v].get('Maintain10', 0) + \n",
    "            G[u][v].get('Upgrade', 0)\n",
    "            for u, v in G.edges()\n",
    "        )\n",
    "\n",
    "    # Count nodes marked as exit and source\n",
    "    exit_nodes_count = sum(1 for node in G.nodes if G.nodes[node].get('is_exit'))\n",
    "    source_nodes_count = sum(1 for node in G.nodes if G.nodes[node].get('is_source'))\n",
    "\n",
    "    # Create the overview text\n",
    "    degree_overview = \"Graph Degree Overview:\\n\"\n",
    "    for degree, count in sorted(degree_counts.items()):\n",
    "        degree_overview += f\"Nodes with degree {degree}: {count}\\n\"\n",
    "\n",
    "    degree_overview += f\"\\nNumber of Source Nodes: {source_nodes_count}\\n\"\n",
    "    degree_overview += f\"\\nNumber of Exit Nodes: {exit_nodes_count}\\n\"\n",
    "    degree_overview += f\"\\nTotal Edge Length: {total_edge_length:.2f}\\n\"\n",
    "    if costattributes_exist:\n",
    "        degree_overview += f\"Total Costs: {total_costs:.2f}\\n\"\n",
    "\n",
    "    # Add graph details to plot\n",
    "    plt.title(f\"Graph Plot for {name},\\n {len(G.nodes)} nodes\\n {len(G.edges)} edges\")\n",
    "    \n",
    "    # Add the degree overview text to the plot\n",
    "    plt.text(0.5, -0.1, degree_overview, ha='center', va='top', transform=plt.gca().transAxes, fontsize=10)\n",
    "\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')  # Save plot\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Handle exit points [helper functions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find nearest node [helper function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_node(graph, exit_points):\n",
    "    \"\"\"\n",
    "    Find the nearest nodes in the graph for a list of exit points based on Euclidean distance.\n",
    "\n",
    "    Parameters:\n",
    "        graph (nx.Graph): A NetworkX graph object containing nodes and their coordinates.\n",
    "        exit_points (list): A list of exit points, where each exit point is a tuple representing (x, y) coordinates.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with columns ['exit_point', 'nearest_neighbor_node', 'distance'],\n",
    "                      containing the exit points, their corresponding nearest nodes, and the calculated distances.\n",
    "\n",
    "    Example:\n",
    "        graph = nx.Graph()\n",
    "        exit_points = [(x1, y1), (x2, y2)]\n",
    "        result_df = find_nearest_node(graph, exit_points)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for exit_point in exit_points:\n",
    "        # Find the nearest node based on distance\n",
    "        nearest_node = min(graph.nodes, key=lambda node: np.linalg.norm(np.array(exit_point) - np.array(node)))\n",
    "        \n",
    "        # Calculate the distance to the nearest node\n",
    "        distance = np.linalg.norm(np.array(exit_point) - np.array(nearest_node))\n",
    "        \n",
    "        # Append the result\n",
    "        results.append((exit_point, nearest_node, distance))\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(results, columns=['exit_point', 'nearest_neighbor_node', 'distance'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find edges closeby [helper function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_edge(G, exit_x, exit_y):\n",
    "    \"\"\"\n",
    "    Finds the closest edge in the graph to the exit point (exit_x, exit_y).\n",
    "    Returns the edge (u, v) and the intersection point.\n",
    "    \"\"\"\n",
    "    min_dist = float('inf')\n",
    "    closest_edge = None\n",
    "    intersection_point = None\n",
    "\n",
    "    # Iterate through all edges in the graph\n",
    "    for u, v in G.edges():\n",
    "        # Get the coordinates of the nodes (assumed to be stored as node attributes)\n",
    "        ux, uy = u\n",
    "        vx, vy = v\n",
    "        \n",
    "        # Create a LineString for the edge\n",
    "        line = LineString([(ux, uy), (vx, vy)])\n",
    "\n",
    "        # Create a Point for the exit\n",
    "        exit_point = Point(exit_x, exit_y)\n",
    "\n",
    "        # Check if the exit point intersects the edge\n",
    "        if line.distance(exit_point) < min_dist:\n",
    "            min_dist = line.distance(exit_point)\n",
    "            closest_edge = (u, v)\n",
    "            # If the point is on the line, we can get the intersection point\n",
    "            if line.intersects(exit_point):\n",
    "                intersection_point = line.interpolate(line.project(exit_point))  # Exact intersection point\n",
    "\n",
    "    return closest_edge, intersection_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split at exit [helper function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_edge_at_exit(G, exit_node, exit_x, exit_y):\n",
    "    \"\"\"\n",
    "    Splits the edge in the graph that is closest to the exit node based on coordinates.\n",
    "    After splitting, ensures that the new edges have the 'has_exit' attribute if they contain the exit node.\n",
    "    Also adds the 'has_exit' attribute to the edge if the exit node is already part of it.\n",
    "\n",
    "    Parameters:\n",
    "        G (nx.Graph): The NetworkX graph containing the edges to be split.\n",
    "        exit_node (tuple): The coordinates (x, y) of the exit node to be added.\n",
    "        exit_x (float): The x-coordinate of the exit point.\n",
    "        exit_y (float): The y-coordinate of the exit point.\n",
    "\n",
    "    Actions:\n",
    "        - Identifies the closest edge to the exit point.\n",
    "        - Splits the identified edge by adding the exit node and connecting it to both vertices of the edge.\n",
    "        - Removes the original edge and adds two new edges that include the exit node.\n",
    "        - Adds the 'has_exit' attribute to the edges, whether split or not.\n",
    "    \"\"\"\n",
    "    # Find the closest edge and the intersection point\n",
    "    closest_edge, intersection_point = find_closest_edge(G, exit_x, exit_y)\n",
    "\n",
    "    if closest_edge is None:\n",
    "        print(f\"Warning: No edge found for exit point {exit_node}. Skipping split.\")\n",
    "        return\n",
    "\n",
    "    u, v = closest_edge\n",
    "\n",
    "    # If the exit_node is already part of the edge, just mark the edge with 'has_exit'\n",
    "    if exit_node == u or exit_node == v:\n",
    "        print(f\"Exit node {exit_node} is already part of the edge ({u}, {v}). Marking it with 'has_exit'.\")\n",
    "        G[u][v]['has_exit'] = True\n",
    "        return\n",
    "    \n",
    "    # Get attributes from the original edge\n",
    "    original_slope = G[u][v].get('slope', None)\n",
    "\n",
    "    # Remove the original edge\n",
    "    G.remove_edge(u, v)\n",
    "\n",
    "    # Add the exit node and split the edge\n",
    "    G.add_edge(u, exit_node)\n",
    "    G.add_edge(exit_node, v)\n",
    "\n",
    "    # Assign attributes to the new edges\n",
    "    for node1, node2 in [(u, exit_node), (exit_node, v)]:\n",
    "        G[node1][node2]['has_exit'] = True\n",
    "        G[node1][node2]['slope'] = original_slope  # Retain the slope\n",
    "        G[node1][node2]['edgelength'] = calculate_edge_length(node1, node2)  # Recalculate edge length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### handling exit points [helper function / mini workflow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_exit_points(G, exit_points, node_to_stands):\n",
    "    \"\"\"\n",
    "    Processes exit points by adding them as nodes or merging them with existing ones.\n",
    "    Also updates edge attributes to indicate if they contain an exit node.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (count of already contained exit points, count of newly added exit points).\n",
    "    \"\"\"\n",
    "    # Find nearest nodes and determine new exit points\n",
    "    exitdf = find_nearest_node(G, exit_points)\n",
    "    exitdf['newexit'] = np.where(exitdf['distance'] <= 10, exitdf['nearest_neighbor_node'], exitdf['exit_point'])\n",
    "\n",
    "    # Add exit nodes to graph\n",
    "    for node in exitdf['newexit']:\n",
    "        G.add_node(node, is_exit=True, is_source=False, stands=node_to_stands.get(node, []))  # Mark node as an exit\n",
    "\n",
    "    # Split edges at new exit points if necessary\n",
    "    for _, row in exitdf[exitdf['distance'] > 10].iterrows():\n",
    "        exit_x, exit_y = row['exit_point']\n",
    "        closest_edge, intersection_point = find_closest_edge(G, exit_x, exit_y)\n",
    "\n",
    "        if closest_edge:\n",
    "            split_edge_at_exit(G, row['newexit'], exit_x, exit_y)\n",
    "\n",
    "    # Mark edges that contain exit nodes\n",
    "    exit_nodes = set(exitdf['newexit'])  # Convert to set for fast lookup\n",
    "    for u, v in G.edges():\n",
    "        G[u][v]['has_exit'] = u in exit_nodes or v in exit_nodes  \n",
    "\n",
    "    # Return counts\n",
    "    return (exitdf['distance'] <= 10).sum(), (exitdf['distance'] > 10).sum(), G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO: Verify Exit Points (Plot with roads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¾ store updated graph data [helper function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_updated_graph_data(out_path, G, name, prefix):\n",
    "    \"\"\"\n",
    "    Saves the updated graph data (vertices, edges, exit nodes, and source nodes with attributes) into CSV files.\n",
    "\n",
    "    Parameters:\n",
    "        out_path (str): The directory where the CSV files will be saved.\n",
    "        G (networkx.Graph): The original undirected graph.\n",
    "        name (str): The name of the component, used in the file naming.\n",
    "        prefix (str): A prefix for the file names.\n",
    "    \"\"\"\n",
    "    # Ensure the folder exists\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "    \n",
    "    # File paths\n",
    "    updated_vertices_file = os.path.join(out_path, f'{prefix}_nodes.csv')\n",
    "    updated_edges_file = os.path.join(out_path, f'{prefix}_edges.csv')\n",
    "    updated_edges_with_attributes_file = os.path.join(out_path, f'{prefix}_edges_with_attributes.csv')\n",
    "    exit_nodes_file = os.path.join(out_path, f'exit_nodes.csv')\n",
    "    source_nodes_file = os.path.join(out_path, f'source_nodes.csv')\n",
    "    boundaries_file = os.path.join(out_path, f'boundaries.csv')\n",
    "\n",
    "    # Extract and save all vertices\n",
    "    vertices_data = [{'x': node[0], \n",
    "                    'y': node[1], \n",
    "                    'is_exit': G.nodes[node].get('is_exit', False), \n",
    "                    'is_source': G.nodes[node].get('is_source', False), \n",
    "                    'stands': json.dumps(G.nodes[node].get('stands', []))} for node in G.nodes]\n",
    "    pd.DataFrame(vertices_data).to_csv(updated_vertices_file, index=False)\n",
    "\n",
    "    # Extract and save exit nodes (where is_exit=True)\n",
    "    exit_nodes_data = [{'x': node[0], 'y': node[1]} \n",
    "                       for node in G.nodes if G.nodes[node].get('is_exit', False)]\n",
    "    pd.DataFrame(exit_nodes_data).to_csv(exit_nodes_file, index=False)\n",
    "\n",
    "    # Extract and save source nodes (where is_source is NOT False) with its attribute\n",
    "    source_nodes_data = [{'x': node[0], 'y': node[1], 'ID_UG': G.nodes[node]['is_source']} \n",
    "                         for node in G.nodes if G.nodes[node].get('is_source') not in [False, None]]\n",
    "    pd.DataFrame(source_nodes_data).to_csv(source_nodes_file, index=False)\n",
    "\n",
    "    # Extract and save undirected edges\n",
    "    edges_data = [(f\"({u[0]}, {u[1]})\", f\"({v[0]}, {v[1]})\") for u, v in G.edges]\n",
    "    pd.DataFrame(edges_data, columns=['Node1(x,y)', 'Node2(x,y)']).to_csv(updated_edges_file, index=False)\n",
    "\n",
    "    # Extract and save edges with attributes dynamically\n",
    "    edges_attributes_data = []\n",
    "    for u, v in G.edges:\n",
    "        edge_data = {'Node1(x,y)': f\"({u[0]}, {u[1]})\", 'Node2(x,y)': f\"({v[0]}, {v[1]})\"}\n",
    "        edge_data.update(G[u][v])  # Dynamically add all attributes\n",
    "        edges_attributes_data.append(edge_data)\n",
    "    pd.DataFrame(edges_attributes_data).to_csv(updated_edges_with_attributes_file, index=False)\n",
    "\n",
    "    print(f\"Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in {out_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate the costs associated with each road segment\n",
    "\n",
    "There are costs associated with the construction, maintenance and upgrade of roads, depending on the slope. They need to be calculated for each road segment according to their length.\n",
    "\n",
    "We name the 3 categories of slope:\n",
    "* flat (slope â‰¤ 5)\n",
    "* moderate (5 < slope < 25)\n",
    "* steep (slope â‰¥ 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Build5m  Maintain5m\n",
      "flat       2147.0     1073.50\n",
      "moderate      0.0        0.00\n",
      "steep      7514.5     2683.75\n"
     ]
    }
   ],
   "source": [
    "costs = {\n",
    "    \"flat\": {  \n",
    "        \"Build5m\": 2147,\n",
    "        \"Maintain5m\": 1073.5\n",
    "    },\n",
    "    \"moderate\": {\n",
    "        \"Build5m\": 0,\n",
    "        \"Maintain5m\": 0\n",
    "    },\n",
    "    \"steep\": {\n",
    "        \"Build5m\": 7514.5,\n",
    "        \"Maintain5m\": 2683.75\n",
    "    }\n",
    "}\n",
    "costs_df = pd.DataFrame(costs).T\n",
    "print(costs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### approximation for unknown costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Build5m</th>\n",
       "      <th>Maintain5m</th>\n",
       "      <th>Build10m</th>\n",
       "      <th>Maintain10m</th>\n",
       "      <th>Upgrade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flat</th>\n",
       "      <td>2147.0</td>\n",
       "      <td>1073.50</td>\n",
       "      <td>3220.50</td>\n",
       "      <td>1073.50</td>\n",
       "      <td>1610.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moderate</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>steep</th>\n",
       "      <td>7514.5</td>\n",
       "      <td>2683.75</td>\n",
       "      <td>11271.75</td>\n",
       "      <td>2683.75</td>\n",
       "      <td>5635.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Build5m  Maintain5m  Build10m  Maintain10m   Upgrade\n",
       "flat       2147.0     1073.50   3220.50      1073.50  1610.250\n",
       "moderate      0.0        0.00      0.00         0.00     0.000\n",
       "steep      7514.5     2683.75  11271.75      2683.75  5635.875"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "costs_df['Build10m'] = 1.5 * costs_df.Build5m\n",
    "costs_df['Maintain10m'] = costs_df.Maintain5m\n",
    "costs_df['Upgrade'] = 0.75 * costs_df.Build5m\n",
    "costs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Build5m</th>\n",
       "      <th>Maintain5m</th>\n",
       "      <th>Build10m</th>\n",
       "      <th>Maintain10m</th>\n",
       "      <th>Upgrade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flat</th>\n",
       "      <td>2147.00</td>\n",
       "      <td>1073.500</td>\n",
       "      <td>3220.500</td>\n",
       "      <td>1073.500</td>\n",
       "      <td>1610.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moderate</th>\n",
       "      <td>4830.75</td>\n",
       "      <td>1878.625</td>\n",
       "      <td>7246.125</td>\n",
       "      <td>1878.625</td>\n",
       "      <td>3623.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>steep</th>\n",
       "      <td>7514.50</td>\n",
       "      <td>2683.750</td>\n",
       "      <td>11271.750</td>\n",
       "      <td>2683.750</td>\n",
       "      <td>5635.8750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Build5m  Maintain5m   Build10m  Maintain10m    Upgrade\n",
       "flat      2147.00    1073.500   3220.500     1073.500  1610.2500\n",
       "moderate  4830.75    1878.625   7246.125     1878.625  3623.0625\n",
       "steep     7514.50    2683.750  11271.750     2683.750  5635.8750"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "costs_df.iloc[1] = (costs_df.iloc[0] + costs_df.iloc[2]) / 2\n",
    "costs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### assign the costs [helper function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_all_costs_to_edges(G, name):\n",
    "    \"\"\"\n",
    "    Assign all cost-related variables (Build5m, Maintain5m, Upgrade, Build10m, Maintain10m) to edges\n",
    "    based on slope, road type, and edge length.\n",
    "    \n",
    "    Parameters:\n",
    "    G (NetworkX graph): The graph representing the road network.\n",
    "    \n",
    "    Returns:\n",
    "    G (NetworkX graph): The graph with updated cost attributes.\n",
    "    \"\"\"\n",
    "\n",
    "    # Iterate over each edge in the graph and set the new attributes\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        if 'edgelength' in data and 'slope' in data:  # Ensure both 'edgelength' and 'slope' exist\n",
    "\n",
    "            # Determine the correct category based on slope\n",
    "            if data['slope'] <= 5:\n",
    "                category = \"flat\"\n",
    "            elif 5 < data['slope'] < 25:\n",
    "                category = \"moderate\"\n",
    "            else:  # data['slope'] >= 25\n",
    "                category = \"steep\"\n",
    "\n",
    "            # Assign costs based on the selected category\n",
    "            for column in costs_df.columns:\n",
    "                data[column] = round(data['edgelength'] * costs_df.loc[category, column])\n",
    "                \n",
    "    print(f'{name} costs assigned')\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Merge short edges to improve performance of optimisation algorithms\n",
    "\n",
    "Note: It would have been possible to merge earlier, but the cost approximization is better this way, because we have more information on the slope if we don't merge the edges before calculation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge short edges [helper function] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_edges(G, length_threshold):\n",
    "    \"\"\"\n",
    "    Merges edges in a graph G that are shorter than a given length_threshold. no exit nodes or crossing can be removed.\n",
    "    \n",
    "    Parameters:\n",
    "    G (networkx.Graph): The input graph containing nodes and edges to be merged.\n",
    "    length_threshold (float): The maximum length below which edges will be merged.\n",
    "\n",
    "    Returns:\n",
    "    networkx.Graph: The modified graph with merged edges.\n",
    "    \"\"\"\n",
    "\n",
    "    while True:\n",
    "        merged = False  # Flag to track if any merge happens in an iteration\n",
    "\n",
    "        for u, v, data_edge_uv in list(G.edges(data=True)):\n",
    "\n",
    "            if data_edge_uv.get('edgelength', float('inf')) >= length_threshold:\n",
    "                continue  # Skip if the edge is too long\n",
    "            \n",
    "            if G.nodes[v].get('is_exit', False) or G.degree[v] > 2:\n",
    "                if G.nodes[u].get('is_exit', False) or G.degree[u] > 2:\n",
    "                    continue  # Skip if v and u both are an exit node or crossing\n",
    "                else: \n",
    "                    u, v = v, u # swap\n",
    "\n",
    "            other_neighbors_of_v = [n for n in G.neighbors(v) if n != u]\n",
    "\n",
    "            # Find the shortest edge among v's neighbors\n",
    "            closest_neighbor_to_v = None\n",
    "            shortest_length_to_v = float('inf')\n",
    "\n",
    "            for n in other_neighbors_of_v:\n",
    "                if G.has_edge(v, n):\n",
    "                    edge_length = G[v][n].get('edgelength', float('inf'))\n",
    "                    if edge_length < shortest_length_to_v:\n",
    "                        shortest_length_to_v = edge_length\n",
    "                        closest_neighbor_to_v = n\n",
    "\n",
    "            # Merge the edges if a valid neighbor is found\n",
    "            if closest_neighbor_to_v is not None and not G.has_edge(u, closest_neighbor_to_v):\n",
    "                data_edge_vn = G[v][closest_neighbor_to_v]\n",
    "    \n",
    "                # Create merged edge data\n",
    "                new_data = {\n",
    "                    'edgelength': data_edge_uv['edgelength'] + data_edge_vn['edgelength'],\n",
    "                    'has_exit': data_edge_uv.get('has_exit', False) or data_edge_vn.get('has_exit', False),\n",
    "                    'Build5m': data_edge_uv.get('Build5m', 0) + data_edge_vn.get('Build5m', 0),\n",
    "                    'Maintain5m': data_edge_uv.get('Maintain5m', 0) + data_edge_vn.get('Maintain5m', 0),\n",
    "                    'Build10m': data_edge_uv.get('Build10m', 0) + data_edge_vn.get('Build10m', 0),\n",
    "                    'Maintain10m': data_edge_uv.get('Maintain10m', 0) + data_edge_vn.get('Maintain10m', 0),\n",
    "                    'Upgrade': data_edge_uv.get('Upgrade', 0) + data_edge_vn.get('Upgrade', 0),\n",
    "                }\n",
    "\n",
    "                # Add the new merged edge\n",
    "                G.add_edge(u, closest_neighbor_to_v, **new_data)\n",
    "\n",
    "                # Remove old edges\n",
    "                if G.has_edge(u, v):\n",
    "                    G.remove_edge(u, v)\n",
    "                if G.has_edge(v, closest_neighbor_to_v):\n",
    "                    G.remove_edge(v, closest_neighbor_to_v)\n",
    "                if G.has_node(v):\n",
    "                    G.remove_node(v)\n",
    "\n",
    "                merged = True  # Mark that a merge happened\n",
    "                break  # Restart iteration\n",
    "\n",
    "        if not merged:\n",
    "            break  # Stop if no merges happened in this round\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_short_edges(G, length_threshold):\n",
    "    \"\"\"\n",
    "    Merges edges in a graph G that are shorter than a given length_threshold. no exit nodes or crossing can be removed.\n",
    "    \n",
    "    Parameters:\n",
    "    G (networkx.Graph): The input graph containing nodes and edges to be merged.\n",
    "    length_threshold (float): The maximum length below which edges will be merged.\n",
    "\n",
    "    Returns:\n",
    "    networkx.Graph: The modified graph with merged edges.\n",
    "    \"\"\"\n",
    "\n",
    "    while True:\n",
    "        merged = False  # Flag to track if any merge happens in an iteration\n",
    "\n",
    "        for u, v, data_edge_uv in list(G.edges(data=True)):\n",
    "\n",
    "            if data_edge_uv.get('edgelength', float('inf')) >= length_threshold:\n",
    "                continue  # Skip if the edge is too long\n",
    "            \n",
    "            if G.nodes[v].get('is_exit', False) or G.degree[v] > 2:\n",
    "                continue  # Skip if v is an exit node or crossing\n",
    "\n",
    "            other_neighbors_of_v = [n for n in G.neighbors(v) if n != u]\n",
    "\n",
    "            # Find the shortest edge among v's neighbors\n",
    "            closest_neighbor_to_v = None\n",
    "            shortest_length_to_v = float('inf')\n",
    "\n",
    "            for n in other_neighbors_of_v:\n",
    "                if G.has_edge(v, n):\n",
    "                    edge_length = G[v][n].get('edgelength', float('inf'))\n",
    "                    if edge_length < shortest_length_to_v:\n",
    "                        shortest_length_to_v = edge_length\n",
    "                        closest_neighbor_to_v = n\n",
    "\n",
    "            # Merge the edges if a valid neighbor is found\n",
    "            if closest_neighbor_to_v is not None and not G.has_edge(u, closest_neighbor_to_v):\n",
    "                data_edge_vn = G[v][closest_neighbor_to_v]\n",
    "\n",
    "                # Create merged edge data\n",
    "                new_data = {\n",
    "                    'edgelength': data_edge_uv['edgelength'] + data_edge_vn['edgelength'],\n",
    "                    'has_exit': data_edge_uv.get('has_exit', False) or data_edge_vn.get('has_exit', False),\n",
    "                    'Build5m': data_edge_uv.get('Build5m', 0) + data_edge_vn.get('Build5m', 0),\n",
    "                    'Maintain5m': data_edge_uv.get('Maintain5m', 0) + data_edge_vn.get('Maintain5m', 0),\n",
    "                    'Build10m': data_edge_uv.get('Build10m', 0) + data_edge_vn.get('Build10m', 0),\n",
    "                    'Maintain10m': data_edge_uv.get('Maintain10m', 0) + data_edge_vn.get('Maintain10m', 0),\n",
    "                    'Upgrade': data_edge_uv.get('Upgrade', 0) + data_edge_vn.get('Upgrade', 0),\n",
    "                }\n",
    "\n",
    "                # Add the new merged edge\n",
    "                G.add_edge(u, closest_neighbor_to_v, **new_data)\n",
    "\n",
    "                # Remove old edges\n",
    "                if G.has_edge(u, v):\n",
    "                    G.remove_edge(u, v)\n",
    "                if G.has_edge(v, closest_neighbor_to_v):\n",
    "                    G.remove_edge(v, closest_neighbor_to_v)\n",
    "                if G.has_node(v):\n",
    "                    G.remove_node(v)\n",
    "\n",
    "                merged = True  # Mark that a merge happened\n",
    "                break  # Restart iteration\n",
    "\n",
    "        if not merged:\n",
    "            break  # Stop if no merges happened in this round\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### verify the result of merging [helper function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_merge(G_before_merge, G_after_merge):\n",
    "    \"\"\"\n",
    "    Verifies the merge by comparing the total sum of `edgelength` and costs \n",
    "    before and after the merge.\n",
    "\n",
    "    Parameters:\n",
    "        G_before_merge: The graph before merging.\n",
    "        G_after_merge: The graph after merging.\n",
    "    \"\"\"\n",
    "    def calculate_totals(G):\n",
    "        return {\n",
    "            'edgelength': sum(data.get('edgelength', 0) for _, _, data in G.edges(data=True)),\n",
    "            'Build5m': sum(data.get('Build5m', 0) for _, _, data in G.edges(data=True)),\n",
    "            'Maintain5m': sum(data.get('Maintain5m', 0) for _, _, data in G.edges(data=True)),\n",
    "            'Build10m': sum(data.get('Build10m', 0) for _, _, data in G.edges(data=True)),\n",
    "            'Maintain10m': sum(data.get('Maintain10m', 0) for _, _, data in G.edges(data=True)),\n",
    "            'Upgrade': sum(data.get('Upgrade', 0) for _, _, data in G.edges(data=True))\n",
    "        }\n",
    "    \n",
    "    totals_before = calculate_totals(G_before_merge)\n",
    "    totals_after = calculate_totals(G_after_merge)\n",
    "    \n",
    "    # Check for differences\n",
    "    differences = {key: round(totals_after[key] - totals_before[key], 2) for key in totals_before}\n",
    "    significant_differences = {k: v for k, v in differences.items() if v != 0}\n",
    "    \n",
    "    if significant_differences:\n",
    "        print(\"Warning: Differences detected in the following totals:\")\n",
    "        for key, value in significant_differences.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "    \n",
    "    return {\n",
    "        'deleted_edges': G_before_merge.number_of_edges() - G_after_merge.number_of_edges()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store debugging infos [helper function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_debug_infos(base_info, folder_path, name):\n",
    "    # Debugging Infos\n",
    "        total_vertices = len(vertices)\n",
    "        total_edges = len(edges)\n",
    "        #unique_road_segments = len(road_segments)\n",
    "        #merged_edges = total_edges - unique_road_segments\n",
    "\n",
    "        # Write info for the component to its individual text file\n",
    "        info_file_path = os.path.join(folder_path, f'info_{name}.txt')\n",
    "        with open(info_file_path, 'w') as info_file:\n",
    "            info_file.write(f\"Component {name} Information\\n\")\n",
    "            info_file.write(f\"----------------------------\\n\")\n",
    "            info_file.write(f\"Number of vertices: {total_vertices}\\n\")\n",
    "            info_file.write(f\"Total original edges: {total_edges}\\n\")\n",
    "            #info_file.write(f\"Unique road segments after removing duplicate (shared) edges: {unique_road_segments}\\n\")\n",
    "            #info_file.write(f\"Number of removed edges: {merged_edges}\\n\")\n",
    "            info_file.write(f\"Number of edge attributes: {len(attributes)}\\n\")\n",
    "            info_file.write(f\"Number of deleted edges due to merging of short ones: {results['deleted_edges']}\\n\")\n",
    "            info_file.write(f\"Totals Before Merge: {results['before']}\\n\")\n",
    "            info_file.write(f\"Totals After Merge: {results['after']}\\n\")\n",
    "            info_file.write(f\"Differences: {results['difference']}\\n\")\n",
    "            info_file.write(f\"Number of nodes per degree: {results['node_degrees']}\\n\")\n",
    "            info_file.write(f\"----------------------------\\n\")\n",
    "\n",
    "        # Write the aggregated summary to the base info file\n",
    "        base_info.write(f\"\\nComponent {name} Information\\n\")\n",
    "        base_info.write(f\"----------------------------\\n\")\n",
    "        base_info.write(f\"Number of vertices: {total_vertices}\\n\")\n",
    "        base_info.write(f\"Total original edges: {total_edges}\\n\")\n",
    "        #base_info.write(f\"Unique road segments after removing duplicate (shared) edges: {unique_road_segments}\\n\")\n",
    "        #base_info.write(f\"Number of removed edges: {merged_edges}\\n\")\n",
    "        base_info.write(f\"Number of edge attributes: {len(attributes)}\\n\")\n",
    "        base_info.write(f\"Number of deleted edges due to merging of short ones: {results['deleted_edges']}\\n\")\n",
    "        base_info.write(f\"Totals Before Merge: {results['before']}\\n\")\n",
    "        base_info.write(f\"Totals After Merge: {results['after']}\\n\")\n",
    "        base_info.write(f\"Differences: {results['difference']}\\n\")\n",
    "        base_info.write(f\"Number of nodes per degree: {results['node_degrees']}\\n\")\n",
    "        base_info.write(f\"----------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Add source nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create source nodes for each stand [helper function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_centroids_and_imaginary_edges(G, stands, exit_points, precision=5):\n",
    "    \"\"\"\n",
    "    Adds center point nodes (centroids) to the graph and creates edges from each \n",
    "    centroid to boundary vertices that already exist in the graph, including connecting\n",
    "    exit nodes to centroids if they lie on the polygon.\n",
    "\n",
    "    Parameters:\n",
    "        G (nx.Graph): The NetworkX graph object to which the center points and edges will be added.\n",
    "        stands (GeoDataFrame): A GeoDataFrame containing the polygon geometries of the stands.\n",
    "        exit_points (list of tuples): A list of exit points (coordinates where stand boundaries intersect roads).\n",
    "        precision (int, optional, default=5): The precision to which the coordinates \n",
    "                                              will be snapped when extracted (controls decimal places).\n",
    "\n",
    "    Returns:\n",
    "        None: Modifies the provided graph in-place by adding new nodes (centroids) and edges.\n",
    "    \"\"\"\n",
    "    for _, feature in stands.iterrows():\n",
    "        geometry = feature.geometry\n",
    "        id_ug = feature['ID_UG']  # Extract ID_UG from the stand feature\n",
    "\n",
    "        # Ensure the geometry is a polygon\n",
    "        if geometry.geom_type == 'Polygon':\n",
    "            # Get the boundary coordinates of the polygon (exterior coordinates)\n",
    "            exterior_coords = [snap_to_grid(coord, precision) for coord in geometry.exterior.coords]\n",
    "\n",
    "          # Snap the exit points to the grid\n",
    "            snapped_exit_points = [snap_to_grid(exit_point, precision) for exit_point in exit_points]\n",
    "\n",
    "            # Check if the snapped exit point is close to the boundary (within a small tolerance)\n",
    "            tolerance = 1e-5  # Define a tolerance for how close the exit point needs to be to the boundary\n",
    "\n",
    "            for exit_node in snapped_exit_points:\n",
    "                exit_point_geom = Point(exit_node)  # Convert the exit node to a Shapely Point geometry\n",
    "\n",
    "                # Check if the exit point is within the tolerance distance of the polygon boundary\n",
    "                if geometry.exterior.distance(exit_point_geom) <= tolerance:\n",
    "                    # Append the exit point to the list of exterior coordinates\n",
    "                    exterior_coords.append(exit_node)\n",
    "\n",
    "            \n",
    "            # Calculate the centroid (center point) of the polygon\n",
    "            centroid = geometry.centroid\n",
    "            centroid_coord = snap_to_grid((centroid.x, centroid.y), precision)\n",
    "\n",
    "            # Add the centroid as a new node to the graph with ID_UG as the source identifier\n",
    "            G.add_node(centroid_coord, is_exit=False, is_source=id_ug)  # Assigning ID_UG instead of True\n",
    "\n",
    "            # Create edges from the centroid to boundary vertices, only if the boundary vertex is in the graph\n",
    "            for vertex in exterior_coords:\n",
    "                if vertex in G:  # Check if the vertex already exists in the graph\n",
    "                    # Add an edge from the centroid to the boundary vertex\n",
    "                    G.add_edge(centroid_coord, vertex, has_source=True, edgelength=0, slope=None, has_exit=False)\n",
    "\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### assign costs to source node edges [helper function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_zero_costs_to_imaginary_edges(G, name):\n",
    "    \"\"\"\n",
    "    Assign zero to all cost-related variables (Build5m, Maintain5m, Upgrade, Build10m, Maintain10m) to edges\n",
    "    based on slope, road type, and edge length.\n",
    "    \"\"\"\n",
    "\n",
    "    # Iterate over each edge in the graph and set the new attributes\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        if 'has_source' in data and data.get('has_source') == True:\n",
    "\n",
    "            # Assign costs based on the selected category\n",
    "            for column in costs_df.columns:\n",
    "                data[column] = 0\n",
    "                \n",
    "    print(f'{name} zero costs assigned to imaginary edges')\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prepare CPLEX Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create digraph, create arcs, split into subsets [helper function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_digraph_split_arcs(G):\n",
    "    \"\"\"\n",
    "    Splits the arcs of a directed graph (D) into forward and backward arcs based on the original undirected graph (G).\n",
    "\n",
    "    Parameters:\n",
    "        D (networkx.DiGraph): The directed graph with bidirectional arcs.\n",
    "        G (networkx.Graph): The original undirected graph.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (forward_arcs, backward_arcs) where each is a list of edges.\n",
    "    \"\"\"\n",
    "    forward_arcs = []\n",
    "    backward_arcs = []\n",
    "\n",
    "    # Create a directed graph with bidirectional edges and preserve attributes\n",
    "    D = nx.DiGraph()\n",
    "\n",
    "    for u, v, attrs in G.edges(data=True):  # Get attributes from G\n",
    "        D.add_edge(u, v, **attrs)  # Forward edge with attributes\n",
    "        D.add_edge(v, u, **attrs)  # Reverse edge with attributes   \n",
    "\n",
    "    for u, v in G.edges:  # Only loop over edges from G\n",
    "        if D.has_edge(u, v) and D.has_edge(v, u):  # Ensure both directions exist\n",
    "            forward_arcs.append((u, v))\n",
    "            backward_arcs.append((v, u))\n",
    "\n",
    "    return forward_arcs, backward_arcs, D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_save_boundaries(outpath, G):\n",
    "    \"\"\"\n",
    "    Generates a dictionary that maps each stand (ID_UG) to a list of boundary nodes it contains\n",
    "    and stores the result in a CSV file with each ID_UG and the list of nodes on its boundaries.\n",
    "\n",
    "    Parameters:\n",
    "        outpath (str): The directory path where the output CSV file will be stored.\n",
    "        G (nx.Graph): The NetworkX graph containing nodes with 'stands' attributes.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    boundaries = {}  # Dictionary to store which nodes are part of each stand\n",
    "    \n",
    "    # Iterate over the nodes of the graph\n",
    "    for node, data in G.nodes(data=True):\n",
    "        stands = data.get('stands', [])  # List of stand IDs associated with this node\n",
    "        \n",
    "        for stand_id in stands:\n",
    "            # Initialize the list for the stand if not already present\n",
    "            if stand_id not in boundaries:\n",
    "                boundaries[stand_id] = []\n",
    "            \n",
    "            # Add this node to the list of nodes that touch the stand\n",
    "            boundaries[stand_id].append(node)\n",
    "\n",
    "    # Convert the dictionary to a list of dictionaries for easier CSV export\n",
    "    boundaries_data = []\n",
    "    for stand, nodes in boundaries.items():\n",
    "        # Convert the list of nodes to a string representation\n",
    "        nodes_str = ','.join(map(str, nodes))  # Serialize the list of nodes as a comma-separated string\n",
    "        boundaries_data.append({'ID_UG': stand, 'nodes': nodes_str})  # Store the list of nodes as a string\n",
    "\n",
    "    # Define the output file path\n",
    "    output_file = os.path.join(outpath, \"boundaries.csv\")\n",
    "\n",
    "    # Create a DataFrame from the data and save it to a CSV file\n",
    "    df = pd.DataFrame(boundaries_data)\n",
    "    df.to_csv(output_file, index=False, sep=';')  # Use semicolon as a separator\n",
    "\n",
    "    print(f\"Stand to nodes data saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_save_arcs(out_path, G):\n",
    "    \"\"\"\n",
    "    Saves directed arcs, forward arcs, and backward arcs into separate CSV files.\n",
    "\n",
    "    Parameters:\n",
    "        out_path (str): The directory where the CSV files will be saved.\n",
    "        D (networkx.DiGraph): The directed graph containing bidirectional arcs.\n",
    "        G (networkx.Graph): The original undirected graph.\n",
    "        name (str): The name of the component, used in the file naming.\n",
    "        prefix (str): A prefix for the file names.\n",
    "    \"\"\"\n",
    "    # Ensure the folder exists\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "    # File paths for arcs\n",
    "    updated_arcs_file = os.path.join(out_path, f'arcs.csv')\n",
    "    updated_arcs_with_attributes_file = os.path.join(out_path, f'arcs_with_attributes.csv')\n",
    "    forward_arcs_file = os.path.join(out_path, f'arcsforward.csv')\n",
    "    backward_arcs_file = os.path.join(out_path, f'arcsbackward.csv')\n",
    "\n",
    "    # **NEW**: Split arcs into forward and backward\n",
    "    forward_arcs, backward_arcs, D = create_digraph_split_arcs(G)\n",
    "\n",
    "    # Extract and save all directed arcs\n",
    "    arcs_data = [(f\"({u[0]}, {u[1]})\", f\"({v[0]}, {v[1]})\") for u, v in D.edges]\n",
    "    pd.DataFrame(arcs_data, columns=['Source(x,y)', 'Target(x,y)']).to_csv(updated_arcs_file, index=False)\n",
    "\n",
    "    # Extract and save directed arcs with attributes dynamically\n",
    "    arcs_attributes_data = []\n",
    "    for u, v in D.edges:\n",
    "        arc_data = {'Source(x,y)': f\"({u[0]}, {u[1]})\", 'Target(x,y)': f\"({v[0]}, {v[1]})\"}\n",
    "        arc_data.update(D[u][v])  # Dynamically add all attributes\n",
    "        arcs_attributes_data.append(arc_data)\n",
    "    pd.DataFrame(arcs_attributes_data).to_csv(updated_arcs_with_attributes_file, index=False)\n",
    "\n",
    "    # Save forward arcs\n",
    "    forward_arcs_data = [(f\"({u[0]}, {u[1]})\", f\"({v[0]}, {v[1]})\") for u, v in forward_arcs]\n",
    "    pd.DataFrame(forward_arcs_data, columns=['Source(x,y)', 'Target(x,y)']).to_csv(forward_arcs_file, index=False)\n",
    "\n",
    "    # Save backward arcs\n",
    "    backward_arcs_data = [(f\"({u[0]}, {u[1]})\", f\"({v[0]}, {v[1]})\") for u, v in backward_arcs]\n",
    "    pd.DataFrame(backward_arcs_data, columns=['Source(x,y)', 'Target(x,y)']).to_csv(backward_arcs_file, index=False)\n",
    "\n",
    "    print(f\"Arcs data saved in {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Step 1 to 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing component: component_10\n",
      "2 exit points already exist\n",
      "2 exit points added\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_10\n",
      "component_10 costs assigned\n",
      "component_10 zero costs assigned to imaginary edges\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_10\n",
      "Arcs data saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_10\n",
      "Stand to nodes data saved to 1_Preprocessed_Data\\3_Road_Network_Graphs/component_10\\boundaries.csv\n",
      "Processing component: component_11\n",
      "1 exit points already exist\n",
      "1 exit points added\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_11\n",
      "component_11 costs assigned\n",
      "component_11 zero costs assigned to imaginary edges\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_11\n",
      "Arcs data saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_11\n",
      "Stand to nodes data saved to 1_Preprocessed_Data\\3_Road_Network_Graphs/component_11\\boundaries.csv\n",
      "Processing component: component_12\n",
      "7 exit points already exist\n",
      "8 exit points added\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_12\n",
      "component_12 costs assigned\n",
      "component_12 zero costs assigned to imaginary edges\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_12\n",
      "Arcs data saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_12\n",
      "Stand to nodes data saved to 1_Preprocessed_Data\\3_Road_Network_Graphs/component_12\\boundaries.csv\n",
      "Processing component: component_13\n",
      "Exit node (-14725.76646, 148708.12995) is already part of the edge ((-14854.02958, 148755.56971), (-14725.76646, 148708.12995)). Marking it with 'has_exit'.\n",
      "Exit node (-14511.22747, 148637.70934) is already part of the edge ((-14568.27898, 148670.90301), (-14511.22747, 148637.70934)). Marking it with 'has_exit'.\n",
      "Exit node (-14482.92326, 148621.2414) is already part of the edge ((-14451.86208, 148603.16941), (-14482.92326, 148621.2414)). Marking it with 'has_exit'.\n",
      "Exit node (-14433.07574, 148589.79609) is already part of the edge ((-14451.86208, 148603.16941), (-14433.07574, 148589.79609)). Marking it with 'has_exit'.\n",
      "8 exit points already exist\n",
      "13 exit points added\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_13\n",
      "component_13 costs assigned\n",
      "component_13 zero costs assigned to imaginary edges\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_13\n",
      "Arcs data saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_13\n",
      "Stand to nodes data saved to 1_Preprocessed_Data\\3_Road_Network_Graphs/component_13\\boundaries.csv\n",
      "Processing component: component_14\n",
      "Exit node (-9984.20277, 146563.07825) is already part of the edge ((-10017.96688, 146572.53221), (-9984.20277, 146563.07825)). Marking it with 'has_exit'.\n",
      "Exit node (-9988.06853, 146375.41721) is already part of the edge ((-10006.06058, 146375.41721), (-9988.06853, 146375.41721)). Marking it with 'has_exit'.\n",
      "Exit node (-9668.512, 145677.10047) is already part of the edge ((-9645.19858, 145672.96421), (-9668.512, 145677.10047)). Marking it with 'has_exit'.\n",
      "Exit node (-10000.51986, 146251.47094) is already part of the edge ((-10171.53348, 146040.09591), (-10000.51986, 146251.47094)). Marking it with 'has_exit'.\n",
      "Exit node (-9913.6735, 145997.5426) is already part of the edge ((-9924.07008, 145978.42631), (-9913.6735, 145997.5426)). Marking it with 'has_exit'.\n",
      "Exit node (-9860.92361, 145931.46244) is already part of the edge ((-9888.35118, 145888.46781), (-9860.92361, 145931.46244)). Marking it with 'has_exit'.\n",
      "5 exit points already exist\n",
      "19 exit points added\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_14\n",
      "component_14 costs assigned\n",
      "component_14 zero costs assigned to imaginary edges\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_14\n",
      "Arcs data saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_14\n",
      "Stand to nodes data saved to 1_Preprocessed_Data\\3_Road_Network_Graphs/component_14\\boundaries.csv\n",
      "Processing component: component_15\n",
      "Exit node (-13425.68547, 151948.79471) is already part of the edge ((-13419.44358, 151970.31321), (-13425.68547, 151948.79471)). Marking it with 'has_exit'.\n",
      "3 exit points already exist\n",
      "4 exit points added\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_15\n",
      "component_15 costs assigned\n",
      "component_15 zero costs assigned to imaginary edges\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_15\n",
      "Arcs data saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_15\n",
      "Stand to nodes data saved to 1_Preprocessed_Data\\3_Road_Network_Graphs/component_15\\boundaries.csv\n",
      "Processing component: component_16\n",
      "0 exit points already exist\n",
      "1 exit points added\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_16\n",
      "component_16 costs assigned\n",
      "component_16 zero costs assigned to imaginary edges\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_16\n",
      "Arcs data saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_16\n",
      "Stand to nodes data saved to 1_Preprocessed_Data\\3_Road_Network_Graphs/component_16\\boundaries.csv\n",
      "Processing component: component_17\n",
      "Exit node (-12265.6432, 151204.889) is already part of the edge ((-12283.13698, 151212.98991), (-12265.6432, 151204.889)). Marking it with 'has_exit'.\n",
      "Exit node (-12373.66408, 151017.43164) is already part of the edge ((-12316.39918, 151023.63861), (-12373.66408, 151017.43164)). Marking it with 'has_exit'.\n",
      "Exit node (-12211.4194, 151445.35873) is already part of the edge ((-12175.53648, 151431.44301), (-12211.4194, 151445.35873)). Marking it with 'has_exit'.\n",
      "1 exit points already exist\n",
      "11 exit points added\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_17\n",
      "component_17 costs assigned\n",
      "component_17 zero costs assigned to imaginary edges\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_17\n",
      "Arcs data saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_17\n",
      "Stand to nodes data saved to 1_Preprocessed_Data\\3_Road_Network_Graphs/component_17\\boundaries.csv\n",
      "Processing component: component_18\n",
      "23 exit points already exist\n",
      "23 exit points added\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_18\n",
      "component_18 costs assigned\n",
      "component_18 zero costs assigned to imaginary edges\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_18\n",
      "Arcs data saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_18\n",
      "Stand to nodes data saved to 1_Preprocessed_Data\\3_Road_Network_Graphs/component_18\\boundaries.csv\n",
      "Processing component: component_19\n",
      "4 exit points already exist\n",
      "2 exit points added\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_19\n",
      "component_19 costs assigned\n",
      "component_19 zero costs assigned to imaginary edges\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_19\n",
      "Arcs data saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_19\n",
      "Stand to nodes data saved to 1_Preprocessed_Data\\3_Road_Network_Graphs/component_19\\boundaries.csv\n",
      "Processing component: component_1\n",
      "Exit node (-20855.40696, 152286.94596) is already part of the edge ((-20894.65738, 152294.33101), (-20855.40696, 152286.94596)). Marking it with 'has_exit'.\n",
      "6 exit points already exist\n",
      "12 exit points added\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_1\n",
      "component_1 costs assigned\n",
      "component_1 zero costs assigned to imaginary edges\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_1\n",
      "Arcs data saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_1\n",
      "Stand to nodes data saved to 1_Preprocessed_Data\\3_Road_Network_Graphs/component_1\\boundaries.csv\n",
      "Processing component: component_20\n",
      "Exit node (-10000.61717, 149694.17443) is already part of the edge ((-9976.24618, 149694.22161), (-10000.61717, 149694.17443)). Marking it with 'has_exit'.\n",
      "Exit node (-10269.17415, 149957.4208) is already part of the edge ((-10260.60268, 149968.31281), (-10269.17415, 149957.4208)). Marking it with 'has_exit'.\n",
      "2 exit points already exist\n",
      "7 exit points added\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_20\n",
      "component_20 costs assigned\n",
      "component_20 zero costs assigned to imaginary edges\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_20\n",
      "Arcs data saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_20\n",
      "Stand to nodes data saved to 1_Preprocessed_Data\\3_Road_Network_Graphs/component_20\\boundaries.csv\n",
      "Processing component: component_21\n",
      "Exit node (-18503.2236, 149519.86065) is already part of the edge ((-18553.08138, 149562.03561), (-18503.2236, 149519.86065)). Marking it with 'has_exit'.\n",
      "Exit node (-18829.90115, 149411.86516) is already part of the edge ((-18805.75758, 149406.29991), (-18829.90115, 149411.86516)). Marking it with 'has_exit'.\n",
      "Exit node (-19128.69942, 149815.47209) is already part of the edge ((-19103.88308, 149820.98701), (-19128.69942, 149815.47209)). Marking it with 'has_exit'.\n",
      "Exit node (-19666.52518, 149136.00578) is already part of the edge ((-19636.21338, 149142.39861), (-19666.52518, 149136.00578)). Marking it with 'has_exit'.\n",
      "Exit node (-18490.60597, 149526.7322) is already part of the edge ((-18480.18678, 149559.09321), (-18490.60597, 149526.7322)). Marking it with 'has_exit'.\n",
      "Exit node (-19733.36518, 149565.05353) is already part of the edge ((-19753.60688, 149559.02921), (-19733.36518, 149565.05353)). Marking it with 'has_exit'.\n",
      "Exit node (-19913.17696, 149560.30699) is already part of the edge ((-19925.05728, 149556.91261), (-19913.17696, 149560.30699)). Marking it with 'has_exit'.\n",
      "35 exit points already exist\n",
      "40 exit points added\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_21\n",
      "component_21 costs assigned\n",
      "component_21 zero costs assigned to imaginary edges\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_21\n",
      "Arcs data saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_21\n",
      "Stand to nodes data saved to 1_Preprocessed_Data\\3_Road_Network_Graphs/component_21\\boundaries.csv\n",
      "Processing component: component_22\n",
      "Exit node (-12349.08022, 148846.29724) is already part of the edge ((-12343.22728, 148867.54521), (-12349.08022, 148846.29724)). Marking it with 'has_exit'.\n",
      "6 exit points already exist\n",
      "10 exit points added\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_22\n",
      "component_22 costs assigned\n",
      "component_22 zero costs assigned to imaginary edges\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_22\n",
      "Arcs data saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_22\n",
      "Stand to nodes data saved to 1_Preprocessed_Data\\3_Road_Network_Graphs/component_22\\boundaries.csv\n",
      "Processing component: component_23\n",
      "1 exit points already exist\n",
      "5 exit points added\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_23\n",
      "component_23 costs assigned\n",
      "component_23 zero costs assigned to imaginary edges\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_23\n",
      "Arcs data saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_23\n",
      "Stand to nodes data saved to 1_Preprocessed_Data\\3_Road_Network_Graphs/component_23\\boundaries.csv\n",
      "Processing component: component_24\n",
      "Exit node (-9938.65227, 149154.81321) is already part of the edge ((-9956.90198, 149155.55691), (-9938.65227, 149154.81321)). Marking it with 'has_exit'.\n",
      "Exit node (-9799.49707, 149327.06965) is already part of the edge ((-9752.94028, 149326.58331), (-9799.49707, 149327.06965)). Marking it with 'has_exit'.\n",
      "6 exit points already exist\n",
      "18 exit points added\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_24\n",
      "component_24 costs assigned\n",
      "component_24 zero costs assigned to imaginary edges\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_24\n",
      "Arcs data saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_24\n",
      "Stand to nodes data saved to 1_Preprocessed_Data\\3_Road_Network_Graphs/component_24\\boundaries.csv\n",
      "Processing component: component_25\n",
      "Exit node (-11982.65825, 153501.88596) is already part of the edge ((-11964.83178, 153491.57111), (-11982.65825, 153501.88596)). Marking it with 'has_exit'.\n",
      "0 exit points already exist\n",
      "7 exit points added\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_25\n",
      "component_25 costs assigned\n",
      "component_25 zero costs assigned to imaginary edges\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_25\n",
      "Arcs data saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_25\n",
      "Stand to nodes data saved to 1_Preprocessed_Data\\3_Road_Network_Graphs/component_25\\boundaries.csv\n",
      "Processing component: component_26\n",
      "Exit node (-8987.80826, 154263.83146) is already part of the edge ((-9015.72998, 154269.88901), (-8987.80826, 154263.83146)). Marking it with 'has_exit'.\n",
      "16 exit points already exist\n",
      "14 exit points added\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_26\n",
      "component_26 costs assigned\n",
      "component_26 zero costs assigned to imaginary edges\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_26\n",
      "Arcs data saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_26\n",
      "Stand to nodes data saved to 1_Preprocessed_Data\\3_Road_Network_Graphs/component_26\\boundaries.csv\n",
      "Processing component: component_2\n",
      "Exit node (-17124.67922, 152350.38854) is already part of the edge ((-17075.48728, 152358.91511), (-17124.67922, 152350.38854)). Marking it with 'has_exit'.\n",
      "2 exit points already exist\n",
      "3 exit points added\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_2\n",
      "component_2 costs assigned\n",
      "component_2 zero costs assigned to imaginary edges\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_2\n",
      "Arcs data saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_2\n",
      "Stand to nodes data saved to 1_Preprocessed_Data\\3_Road_Network_Graphs/component_2\\boundaries.csv\n",
      "Processing component: component_3\n",
      "Exit node (-11298.81805, 144346.94946) is already part of the edge ((-11320.00928, 144379.32771), (-11298.81805, 144346.94946)). Marking it with 'has_exit'.\n",
      "Exit node (-11345.44256, 144244.06245) is already part of the edge ((-11372.82138, 144227.12571), (-11345.44256, 144244.06245)). Marking it with 'has_exit'.\n",
      "Exit node (-11051.44306, 144481.72032) is already part of the edge ((-11059.54818, 144474.97531), (-11051.44306, 144481.72032)). Marking it with 'has_exit'.\n",
      "Exit node (-13563.25154, 145364.09884) is already part of the edge ((-13616.96968, 145393.15941), (-13563.25154, 145364.09884)). Marking it with 'has_exit'.\n",
      "Exit node (-13759.39692, 145318.22574) is already part of the edge ((-13785.81918, 145315.53891), (-13759.39692, 145318.22574)). Marking it with 'has_exit'.\n",
      "Exit node (-13786.78596, 145304.54738) is already part of the edge ((-13785.81918, 145315.53891), (-13786.78596, 145304.54738)). Marking it with 'has_exit'.\n",
      "Exit node (-14259.51482, 145246.99947) is already part of the edge ((-14261.13518, 145233.19071), (-14259.51482, 145246.99947)). Marking it with 'has_exit'.\n",
      "36 exit points already exist\n",
      "43 exit points added\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_3\n",
      "component_3 costs assigned\n",
      "component_3 zero costs assigned to imaginary edges\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_3\n",
      "Arcs data saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_3\n",
      "Stand to nodes data saved to 1_Preprocessed_Data\\3_Road_Network_Graphs/component_3\\boundaries.csv\n",
      "Processing component: component_4\n",
      "Exit node (-8896.59689, 153205.36205) is already part of the edge ((-8878.71948, 153202.01151), (-8896.59689, 153205.36205)). Marking it with 'has_exit'.\n",
      "Exit node (-9563.08336, 152630.40536) is already part of the edge ((-9641.13128, 152723.27561), (-9563.08336, 152630.40536)). Marking it with 'has_exit'.\n",
      "9 exit points already exist\n",
      "11 exit points added\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_4\n",
      "component_4 costs assigned\n",
      "component_4 zero costs assigned to imaginary edges\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_4\n",
      "Arcs data saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_4\n",
      "Stand to nodes data saved to 1_Preprocessed_Data\\3_Road_Network_Graphs/component_4\\boundaries.csv\n",
      "Processing component: component_5\n",
      "4 exit points already exist\n",
      "6 exit points added\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_5\n",
      "component_5 costs assigned\n",
      "component_5 zero costs assigned to imaginary edges\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_5\n",
      "Arcs data saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_5\n",
      "Stand to nodes data saved to 1_Preprocessed_Data\\3_Road_Network_Graphs/component_5\\boundaries.csv\n",
      "Processing component: component_6\n",
      "Exit node (-15032.51192, 154004.65843) is already part of the edge ((-15014.18668, 154002.06851), (-15032.51192, 154004.65843)). Marking it with 'has_exit'.\n",
      "Exit node (-14857.24075, 153996.39466) is already part of the edge ((-14841.81778, 153992.33571), (-14857.24075, 153996.39466)). Marking it with 'has_exit'.\n",
      "Exit node (-15124.80995, 154024.99935) is already part of the edge ((-15191.70698, 154023.82671), (-15124.80995, 154024.99935)). Marking it with 'has_exit'.\n",
      "16 exit points already exist\n",
      "23 exit points added\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_6\n",
      "component_6 costs assigned\n",
      "component_6 zero costs assigned to imaginary edges\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_6\n",
      "Arcs data saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_6\n",
      "Stand to nodes data saved to 1_Preprocessed_Data\\3_Road_Network_Graphs/component_6\\boundaries.csv\n",
      "Processing component: component_7\n",
      "Exit node (-20530.4754, 151549.38539) is already part of the edge ((-20513.60208, 151543.31691), (-20530.4754, 151549.38539)). Marking it with 'has_exit'.\n",
      "Exit node (-20389.10448, 151498.77746) is already part of the edge ((-20374.19098, 151495.52411), (-20389.10448, 151498.77746)). Marking it with 'has_exit'.\n",
      "Exit node (-19724.47581, 151109.50839) is already part of the edge ((-19750.30438, 151091.13371), (-19724.47581, 151109.50839)). Marking it with 'has_exit'.\n",
      "Exit node (-19927.42516, 151491.87314) is already part of the edge ((-19932.37898, 151549.11241), (-19927.42516, 151491.87314)). Marking it with 'has_exit'.\n",
      "Exit node (-19870.63105, 151471.91031) is already part of the edge ((-19850.35558, 151429.83381), (-19870.63105, 151471.91031)). Marking it with 'has_exit'.\n",
      "Exit node (-19911.28055, 151479.37283) is already part of the edge ((-19926.19308, 151477.63701), (-19911.28055, 151479.37283)). Marking it with 'has_exit'.\n",
      "22 exit points already exist\n",
      "23 exit points added\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_7\n",
      "component_7 costs assigned\n",
      "component_7 zero costs assigned to imaginary edges\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_7\n",
      "Arcs data saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_7\n",
      "Stand to nodes data saved to 1_Preprocessed_Data\\3_Road_Network_Graphs/component_7\\boundaries.csv\n",
      "Processing component: component_8\n",
      "Exit node (-9824.62005, 148522.68223) is already part of the edge ((-9813.69658, 148528.02001), (-9824.62005, 148522.68223)). Marking it with 'has_exit'.\n",
      "Exit node (-8387.72104, 151633.98382) is already part of the edge ((-8257.25178, 151633.83521), (-8387.72104, 151633.98382)). Marking it with 'has_exit'.\n",
      "Exit node (-9486.2341, 149237.7909) is already part of the edge ((-9497.16298, 149226.43401), (-9486.2341, 149237.7909)). Marking it with 'has_exit'.\n",
      "Exit node (-9297.20097, 149159.6261) is already part of the edge ((-9332.35058, 149156.13771), (-9297.20097, 149159.6261)). Marking it with 'has_exit'.\n",
      "Exit node (-9837.32306, 148579.28166) is already part of the edge ((-9814.03458, 148574.01041), (-9837.32306, 148579.28166)). Marking it with 'has_exit'.\n",
      "Exit node (-10548.32915, 147694.4533) is already part of the edge ((-10538.85278, 147698.32011), (-10548.32915, 147694.4533)). Marking it with 'has_exit'.\n",
      "Exit node (-9886.92727, 148759.42132) is already part of the edge ((-9860.70768, 148717.83431), (-9886.92727, 148759.42132)). Marking it with 'has_exit'.\n",
      "Exit node (-8482.80244, 151586.28098) is already part of the edge ((-8465.05398, 151596.36531), (-8482.80244, 151586.28098)). Marking it with 'has_exit'.\n",
      "Exit node (-9766.59483, 147443.89262) is already part of the edge ((-9756.27978, 147463.44701), (-9766.59483, 147443.89262)). Marking it with 'has_exit'.\n",
      "26 exit points already exist\n",
      "37 exit points added\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_8\n",
      "component_8 costs assigned\n",
      "component_8 zero costs assigned to imaginary edges\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_8\n",
      "Arcs data saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_8\n",
      "Stand to nodes data saved to 1_Preprocessed_Data\\3_Road_Network_Graphs/component_8\\boundaries.csv\n",
      "Processing component: component_9\n",
      "10 exit points already exist\n",
      "2 exit points added\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_9\n",
      "component_9 costs assigned\n",
      "component_9 zero costs assigned to imaginary edges\n",
      "Graph data (vertices, edges, exit nodes, and source nodes with attributes) saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_9\n",
      "Arcs data saved in 1_Preprocessed_Data\\3_Road_Network_Graphs/component_9\n",
      "Stand to nodes data saved to 1_Preprocessed_Data\\3_Road_Network_Graphs/component_9\\boundaries.csv\n"
     ]
    }
   ],
   "source": [
    "### WORKFLOW ###\n",
    "# Define output path for aggregated component information\n",
    "#base_info_file = f'{out_directory}/info.txt'\n",
    "#write_base_info_header(base_info_file)  # Write header for summary file\n",
    "\n",
    "for name, df in components.items():\n",
    "    print(f\"Processing component: {name}\")\n",
    "\n",
    "    # Create a dedicated folder for the current component\n",
    "    component_folder = f\"{out_directory}/{name}\"\n",
    "    os.makedirs(component_folder, exist_ok=True)\n",
    "\n",
    "    # Extract key graph-related data from the component's dataframe\n",
    "    boundary_points, boundary_edges, attributes, exit_points, node_to_stands = extract_boundaries_with_attributes(component_folder, df, precision=5)\n",
    "\n",
    "    # Save the extracted data for further use\n",
    "    #store_data_for_graph(component_folder, boundary_points, boundary_edges, attributes, name)\n",
    "\n",
    "    # Construct the initial graph representation\n",
    "    G = create_graph(boundary_points, boundary_edges, attributes, node_to_stands)\n",
    "\n",
    "    # Visualize and save the initial graph\n",
    "    plot_and_save(component_folder, G, name, prefix='0graph')\n",
    "\n",
    "    ### EXIT POINTS ###\n",
    "\n",
    "    # Process exit points: determine which are contained and which need to be added\n",
    "    contained_count, to_add_count, G= handle_exit_points(G, exit_points, node_to_stands)\n",
    "    print(f\"{contained_count} exit points already exist\")\n",
    "    print(f\"{to_add_count} exit points added\")\n",
    "\n",
    "    # Update and save the graph after handling exit points\n",
    "    plot_and_save(component_folder, G, name, prefix='1withexits_graph')\n",
    "\n",
    "    # Store the updated graph data, including nodes and edges with attributes\n",
    "    store_updated_graph_data(component_folder, G, name, prefix='1withexits')   \n",
    "\n",
    "    #### ASSIGNING COSTS TO EDGES ####\n",
    "\n",
    "    # Assign cost values to all edges in the graph\n",
    "    G = assign_all_costs_to_edges(G, name)\n",
    "\n",
    "    # Save and visualize the graph with assigned edge costs\n",
    "    #store_updated_graph_data(component_folder, G, name, prefix='2withcosts')\n",
    "    plot_and_save(component_folder, G, name, prefix='2withcosts_graph')\n",
    "\n",
    "    #### MERGING SHORT EDGES ####\n",
    "\n",
    "    # Create a copy of the graph before merging short edges for comparison\n",
    "    G_before_merge = G.copy()\n",
    "        \n",
    "    # Merge edges that are shorter than the specified length threshold\n",
    "    G = merge_short_edges(G, length_threshold=2000)\n",
    "\n",
    "    # Visualize and save the updated graph after merging short edges\n",
    "    plot_and_save(component_folder, G, name, prefix='3aftermerge_graph')\n",
    "\n",
    "    # Store the updated graph data with merged edges\n",
    "    #store_updated_graph_data(component_folder, G, name, prefix='3aftermerge')\n",
    "\n",
    "    verify_merge(G_before_merge, G)\n",
    "\n",
    "    G = merge_edges(G,length_threshold=2000) \n",
    "\n",
    "    # Visualize and save the updated graph after merging short edges\n",
    "    plot_and_save(component_folder, G, name, prefix='3baftermerge_graph')\n",
    "\n",
    "    # Store the updated graph data with merged edges\n",
    "    #store_updated_graph_data(component_folder, G, name, prefix='3baftermerge')\n",
    "\n",
    "    verify_merge(G_before_merge, G)\n",
    "    \n",
    "    ### SOURCE NODES ###\n",
    "\n",
    "     # Extract key graph-related data from the component's dataframe\n",
    "    G = add_centroids_and_imaginary_edges(G, df, exit_points, precision=5)\n",
    "\n",
    "    # assign the zero costs\n",
    "    G = assign_zero_costs_to_imaginary_edges(G, name)\n",
    "\n",
    "    # Visualize and save the updated graph after merging short edges\n",
    "    plot_and_save(component_folder, G, name, prefix='4withsources_graph')\n",
    "\n",
    "    # Store the updated graph data with merged edges\n",
    "    store_updated_graph_data(component_folder, G, name, prefix='4withsources') \n",
    "    create_save_arcs(component_folder, G)\n",
    "\n",
    "    create_save_boundaries(component_folder, G)\n",
    "\n",
    "    # Uncomment if you want to write debug information for further analysis\n",
    "    # write_debug_infos(base_info, component_folder, name)\n",
    "\n",
    "# Once all components are processed, a summary file containing aggregated information is saved\n",
    "# print(f\"Aggregated information for all components saved in {base_info_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
