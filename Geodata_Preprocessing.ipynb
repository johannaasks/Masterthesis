{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geodata Preprocessing II - Create a graph for the possible future road network\n",
    "For each component of stands that is not connected to any roads (respective: big roads), we wanna create a network of possible future road segments which strictly follow the boundaries of the forest stands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.collections as mcoll\n",
    "import matplotlib.patches as mpatches\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "import folium\n",
    "\n",
    "import missingno as msno\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "from shapely.geometry import MultiPolygon, Polygon, Point, LineString\n",
    "from shapely import wkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set input path\n",
    "#base_folder = \"1_Preprocessed_Data/Stand_Components/unconnected_to_roads\"\n",
    "base_folder = \"1_Preprocessed_Data/Stand_Components/unconnected_to_bigroads\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component from 1_Preprocessed_Data/Stand_Components/unconnected_to_bigroads\\comp_1 loaded with 2 stands.\n",
      "Component from 1_Preprocessed_Data/Stand_Components/unconnected_to_bigroads\\comp_10 loaded with 68 stands.\n",
      "Component from 1_Preprocessed_Data/Stand_Components/unconnected_to_bigroads\\comp_11 loaded with 15 stands.\n",
      "Component from 1_Preprocessed_Data/Stand_Components/unconnected_to_bigroads\\comp_12 loaded with 4 stands.\n",
      "Component from 1_Preprocessed_Data/Stand_Components/unconnected_to_bigroads\\comp_13 loaded with 42 stands.\n",
      "Component from 1_Preprocessed_Data/Stand_Components/unconnected_to_bigroads\\comp_14 loaded with 2 stands.\n",
      "Component from 1_Preprocessed_Data/Stand_Components/unconnected_to_bigroads\\comp_15 loaded with 17 stands.\n",
      "Component from 1_Preprocessed_Data/Stand_Components/unconnected_to_bigroads\\comp_16 loaded with 3 stands.\n",
      "Component from 1_Preprocessed_Data/Stand_Components/unconnected_to_bigroads\\comp_17 loaded with 3 stands.\n",
      "Component from 1_Preprocessed_Data/Stand_Components/unconnected_to_bigroads\\comp_18 loaded with 2 stands.\n",
      "Component from 1_Preprocessed_Data/Stand_Components/unconnected_to_bigroads\\comp_19 loaded with 11 stands.\n",
      "Component from 1_Preprocessed_Data/Stand_Components/unconnected_to_bigroads\\comp_2 loaded with 103 stands.\n",
      "Component from 1_Preprocessed_Data/Stand_Components/unconnected_to_bigroads\\comp_20 loaded with 2 stands.\n",
      "Component from 1_Preprocessed_Data/Stand_Components/unconnected_to_bigroads\\comp_21 loaded with 10 stands.\n",
      "Component from 1_Preprocessed_Data/Stand_Components/unconnected_to_bigroads\\comp_22 loaded with 2 stands.\n",
      "Component from 1_Preprocessed_Data/Stand_Components/unconnected_to_bigroads\\comp_23 loaded with 2 stands.\n",
      "Component from 1_Preprocessed_Data/Stand_Components/unconnected_to_bigroads\\comp_24 loaded with 2 stands.\n",
      "Component from 1_Preprocessed_Data/Stand_Components/unconnected_to_bigroads\\comp_25 loaded with 5 stands.\n",
      "Component from 1_Preprocessed_Data/Stand_Components/unconnected_to_bigroads\\comp_26 loaded with 2 stands.\n",
      "Component from 1_Preprocessed_Data/Stand_Components/unconnected_to_bigroads\\comp_3 loaded with 2 stands.\n",
      "Component from 1_Preprocessed_Data/Stand_Components/unconnected_to_bigroads\\comp_4 loaded with 10 stands.\n",
      "Component from 1_Preprocessed_Data/Stand_Components/unconnected_to_bigroads\\comp_5 loaded with 4 stands.\n",
      "Component from 1_Preprocessed_Data/Stand_Components/unconnected_to_bigroads\\comp_6 loaded with 10 stands.\n",
      "Component from 1_Preprocessed_Data/Stand_Components/unconnected_to_bigroads\\comp_7 loaded with 3 stands.\n",
      "Component from 1_Preprocessed_Data/Stand_Components/unconnected_to_bigroads\\comp_8 loaded with 10 stands.\n",
      "Component from 1_Preprocessed_Data/Stand_Components/unconnected_to_bigroads\\comp_9 loaded with 4 stands.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "components = []\n",
    "\n",
    "# Get all subfolders in the base folder\n",
    "component_folders = [f.path for f in os.scandir(base_folder) if f.is_dir()]\n",
    "\n",
    "for component_folder in component_folders:\n",
    "    # Look for shapefiles within the component folder\n",
    "    shapefile_path = os.path.join(component_folder, f\"component_{os.path.basename(component_folder).split('_')[-1]}.shp\")\n",
    "    \n",
    "    if os.path.exists(shapefile_path):\n",
    "        # Load the shapefile into a GeoDataFrame\n",
    "        component_gdf = gpd.read_file(shapefile_path)\n",
    "        \n",
    "        # Append the GeoDataFrame to the list of components\n",
    "        components.append(component_gdf)\n",
    "        \n",
    "        print(f\"Component from {component_folder} loaded with {len(component_gdf)} stands.\")\n",
    "    else:\n",
    "        print(f\"Shapefile not found in {component_folder}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Extract vertices and edges with attributes (slope, edge length) from boundaries\n",
    "From the boundaries of the stands, we extract all points with coordianates and additionally save the edges (lines) connecting them. \n",
    "\n",
    "Note: We only want need exterior boundaries, and NO roads along interior boundaries of a forest stand (because such interior roads would not help with connecting the stands to the existing road network)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1 [helper function] Snap coordinates to grid\n",
    "Before comparing edges, snap all coordinates to a common grid (e.g., round coordinates to a fixed number of decimal places or a specific spatial resolution). This helps ensure that neighboring stands with slightly different coordinate representations share identical coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snap_to_grid(coord, precision=6):\n",
    "    return tuple(round(c, precision) for c in coord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 [helper functions] Calculate attributes\n",
    "To calculate the costs, we need to know for each edge its edge length and its approximative slope.\n",
    "- *edgelength*: The length of an edge (u,v) is calculated using the Euclidean distance formula, to compute the distance between the coordinates of points u and v.\n",
    "- *slope (approx.)*: The slope of an edge is approximated by the slope (\"Declive\") of the polygon the edge belongs to.\n",
    "\n",
    "Note: If we knew the altitude per coordinate, the slope could be approximated via the ratio of the altitude difference to the edgelength; but the edges all belong to the same polygon so we only have one single altitude per polygon (which would lead to a slope of 0). Therefore, we just take the slope (\"Declive\") of the polygon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shapefile contains 2D geometries (no altitude per coordinate).\n",
      "The shapefile has an 'Altitude' column (single altitude per polygon).\n",
      "The shapefile contains 2D geometries (no altitude per coordinate).\n",
      "The shapefile has an 'Altitude' column (single altitude per polygon).\n",
      "The shapefile contains 2D geometries (no altitude per coordinate).\n",
      "The shapefile has an 'Altitude' column (single altitude per polygon).\n",
      "The shapefile contains 2D geometries (no altitude per coordinate).\n",
      "The shapefile has an 'Altitude' column (single altitude per polygon).\n",
      "The shapefile contains 2D geometries (no altitude per coordinate).\n",
      "The shapefile has an 'Altitude' column (single altitude per polygon).\n",
      "The shapefile contains 2D geometries (no altitude per coordinate).\n",
      "The shapefile has an 'Altitude' column (single altitude per polygon).\n",
      "The shapefile contains 2D geometries (no altitude per coordinate).\n",
      "The shapefile has an 'Altitude' column (single altitude per polygon).\n",
      "The shapefile contains 2D geometries (no altitude per coordinate).\n",
      "The shapefile has an 'Altitude' column (single altitude per polygon).\n",
      "The shapefile contains 2D geometries (no altitude per coordinate).\n",
      "The shapefile has an 'Altitude' column (single altitude per polygon).\n",
      "The shapefile contains 2D geometries (no altitude per coordinate).\n",
      "The shapefile has an 'Altitude' column (single altitude per polygon).\n",
      "The shapefile contains 2D geometries (no altitude per coordinate).\n",
      "The shapefile has an 'Altitude' column (single altitude per polygon).\n",
      "The shapefile contains 2D geometries (no altitude per coordinate).\n",
      "The shapefile has an 'Altitude' column (single altitude per polygon).\n",
      "The shapefile contains 2D geometries (no altitude per coordinate).\n",
      "The shapefile has an 'Altitude' column (single altitude per polygon).\n",
      "The shapefile contains 2D geometries (no altitude per coordinate).\n",
      "The shapefile has an 'Altitude' column (single altitude per polygon).\n",
      "The shapefile contains 2D geometries (no altitude per coordinate).\n",
      "The shapefile has an 'Altitude' column (single altitude per polygon).\n",
      "The shapefile contains 2D geometries (no altitude per coordinate).\n",
      "The shapefile has an 'Altitude' column (single altitude per polygon).\n",
      "The shapefile contains 2D geometries (no altitude per coordinate).\n",
      "The shapefile has an 'Altitude' column (single altitude per polygon).\n",
      "The shapefile contains 2D geometries (no altitude per coordinate).\n",
      "The shapefile has an 'Altitude' column (single altitude per polygon).\n",
      "The shapefile contains 2D geometries (no altitude per coordinate).\n",
      "The shapefile has an 'Altitude' column (single altitude per polygon).\n",
      "The shapefile contains 2D geometries (no altitude per coordinate).\n",
      "The shapefile has an 'Altitude' column (single altitude per polygon).\n",
      "The shapefile contains 2D geometries (no altitude per coordinate).\n",
      "The shapefile has an 'Altitude' column (single altitude per polygon).\n",
      "The shapefile contains 2D geometries (no altitude per coordinate).\n",
      "The shapefile has an 'Altitude' column (single altitude per polygon).\n",
      "The shapefile contains 2D geometries (no altitude per coordinate).\n",
      "The shapefile has an 'Altitude' column (single altitude per polygon).\n",
      "The shapefile contains 2D geometries (no altitude per coordinate).\n",
      "The shapefile has an 'Altitude' column (single altitude per polygon).\n",
      "The shapefile contains 2D geometries (no altitude per coordinate).\n",
      "The shapefile has an 'Altitude' column (single altitude per polygon).\n",
      "The shapefile contains 2D geometries (no altitude per coordinate).\n",
      "The shapefile has an 'Altitude' column (single altitude per polygon).\n"
     ]
    }
   ],
   "source": [
    "# Check geometry dimension\n",
    "for component in components:\n",
    "    geometry = component.geometry.iloc[0]\n",
    "    if geometry.has_z:\n",
    "        print(\"The shapefile contains 3D geometries with Z-values (altitudes per coordinate).\")\n",
    "    else:\n",
    "        print(\"The shapefile contains 2D geometries (no altitude per coordinate).\")\n",
    "\n",
    "    # Check for altitude attribute\n",
    "    if 'Altitude' in component.columns:\n",
    "        print(\"The shapefile has an 'Altitude' column (single altitude per polygon).\")\n",
    "    else:\n",
    "        print(\"No 'Altitude' column found. Check Z-values in the geometry.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_edge_length(u,v):\n",
    "    length = LineString([u, v]).length\n",
    "    return length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3 [helper function] Extract nodes, edges, attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_boundaries_with_attributes_double_edges(stands, precision=6):\n",
    "    vertices = []\n",
    "    edges = []  # Keep all edges, including duplicates\n",
    "    edge_attributes = []\n",
    "    \n",
    "    for idx, feature in stands.iterrows():\n",
    "        geometry = feature.geometry\n",
    "        slope = feature['Declive']\n",
    "\n",
    "        if geometry.geom_type in ['Polygon', 'MultiPolygon']:\n",
    "            polygons = [geometry] if geometry.geom_type == 'Polygon' else geometry\n",
    "            for poly in polygons:\n",
    "                exterior_coords = [snap_to_grid(coord, precision) for coord in poly.exterior.coords]\n",
    "                vertices.extend(exterior_coords)\n",
    "\n",
    "                for i in range(len(exterior_coords) - 1):\n",
    "                    u, v = exterior_coords[i], exterior_coords[i + 1]\n",
    "                    edge = (u, v)  # Keep edge order as-is\n",
    "\n",
    "                    edges.append(edge)\n",
    "\n",
    "                    edgelength = calculate_edge_length(u,v)\n",
    "                    # slope is already assigned once per feature, outside loop\n",
    "\n",
    "                    edge_attributes.append({'edgelength': edgelength, 'slope': slope})\n",
    "\n",
    "    vertices = list(set(vertices))\n",
    "    return vertices, edges, edge_attributes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4 [helper function] Merge double edges to deal with shared boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_double_edges(edges, edge_attributes):\n",
    "    road_segments = []\n",
    "    road_attributes = []\n",
    "\n",
    "    # Create a dictionary to group edges\n",
    "    grouped_edges = defaultdict(list)\n",
    "    for edge, attributes in zip(edges, edge_attributes):\n",
    "        normalized_edge = tuple(sorted(edge))  # Normalize edge order\n",
    "        grouped_edges[normalized_edge].append(attributes)\n",
    "\n",
    "    # Merge attributes for each road segment\n",
    "    for edge, attributes_list in grouped_edges.items():\n",
    "        # verage the attributes\n",
    "        avg_length = sum(attr['edgelength'] for attr in attributes_list) / len(attributes_list)\n",
    "        avg_slope = sum(attr['slope'] for attr in attributes_list) / len(attributes_list)\n",
    "\n",
    "        road_segments.append(edge)\n",
    "        road_attributes.append({'edgelength': avg_length, 'slope': avg_slope})\n",
    "\n",
    "    return road_segments, road_attributes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Create the Graph\n",
    "Next, we'll use these vertices and edges to build a graph. This graph will represent the potential road network, where the roads are constrained to follow the boundaries of the forest stands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [helper function] Create graph from vertices, edges, attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(vertices, edges, attributes):\n",
    "    G = nx.Graph()\n",
    "    for vertex in vertices:\n",
    "        G.add_node(vertex)\n",
    "    for edge, attr in zip(edges, attributes):\n",
    "        u, v = edge\n",
    "        G.add_edge(u, v, **attr)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [helper function] Storing graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_graph_data(folder_path, vertices, edges, attributes, k):\n",
    "    # Ensure the folder exists\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    # Store vertices, edges, and attributes as CSV\n",
    "    vertices_file = os.path.join(folder_path, f'nodes_{k + 1}.csv')\n",
    "    edges_file = os.path.join(folder_path, f'edges_{k + 1}.csv')\n",
    "    attributes_file = os.path.join(folder_path, f'attributes_{k + 1}.csv')\n",
    "    edges_attributes_file = os.path.join(folder_path, f'edges_attributes_{k + 1}.csv')\n",
    "\n",
    "    # Save vertices to CSV with columns 'x' and 'y'\n",
    "    with open(vertices_file, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['x', 'y'])  # Write the header\n",
    "        for vertex in vertices:\n",
    "            writer.writerow(vertex)\n",
    "\n",
    "    # Save edges to CSV with columns 'u(x,y)' and 'v(x,y)'\n",
    "    with open(edges_file, 'w', newline='') as f:\n",
    "        writer = csv.writer(f, quoting=csv.QUOTE_MINIMAL)\n",
    "        writer.writerow(['Node1(x,y)', 'Node2(x,y)'])  # Write the header\n",
    "        for edge in edges:\n",
    "            u, v = edge\n",
    "            u_str = f\"({u[0]}, {u[1]})\"  # Format as (x, y)\n",
    "            v_str = f\"({v[0]}, {v[1]})\"  # Format as (x, y)\n",
    "            writer.writerow([u_str, v_str])\n",
    "\n",
    "    # Save attributes to CSV using csv.DictWriter for better column header handling\n",
    "    with open(attributes_file, 'w', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=['edgelength', 'slope'])\n",
    "        writer.writeheader()  # Write column headers\n",
    "        writer.writerows(attributes)\n",
    "\n",
    "    # Save edges with attributes to CSV\n",
    "    with open(edges_attributes_file, 'w', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames = ['Node1(x,y)', 'Node2(x,y)', 'edgelength', 'slope'])\n",
    "        writer.writeheader()\n",
    "        for edge, attribute in zip(edges, attributes):\n",
    "            u, v = edge\n",
    "            u_str = f\"({u[0]}, {u[1]})\"  # Format u coordinate as (x, y)\n",
    "            v_str = f\"({v[0]}, {v[1]})\"  # Format v coordinate as (x, y)\n",
    "            row = {\n",
    "                'Node1(x,y)': u_str,\n",
    "                'Node2(x,y)': v_str,\n",
    "                'edgelength': attribute['edgelength'],\n",
    "                'slope': attribute['slope']\n",
    "            }\n",
    "            writer.writerow(row)\n",
    "\n",
    "    #print(f\"Graph data saved for component {k + 1} in {folder_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Visualize the graph\n",
    "Visualize the graph to identify potential problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [helper function] Create and store graph plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_graph(G, component_index):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "    nx.draw(G, pos={node: node for node in G.nodes()}, node_size=50, \n",
    "            node_color=\"red\", edge_color=\"blue\", with_labels=False)\n",
    "\n",
    "    #add graph details to plot\n",
    "    plt.title(f\"Graph Plot for Component {component_index + 1},\\n {len(G.nodes)} nodes\\n {len(G.edges)} edges\")\n",
    "    \n",
    "    plt.savefig(f'{component_folder}/graph_{component_index + 1}.png', dpi=300, bbox_inches='tight')  # Save plot\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [helper function] Create and store nodes plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_nodes(vertices, component_index):\n",
    "    x_coords, y_coords = zip(*vertices) if vertices else ([], [])\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(x_coords, y_coords, color=\"blue\", marker=\"o\", s=10, label=\"Nodes\")\n",
    "    plt.xlabel(\"X Coordinate\")\n",
    "    plt.ylabel(\"Y Coordinate\")\n",
    "    plt.title(f\"Plot of Graph Nodes {component_index + 1}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    nodes_filename = f'{component_folder}/nodes_{component_index + 1}.png'\n",
    "    plt.savefig(nodes_filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow for Step 1 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component 1 info saved in 'info_1.txt'\n",
      "Component 2 info saved in 'info_2.txt'\n",
      "Component 3 info saved in 'info_3.txt'\n",
      "Component 4 info saved in 'info_4.txt'\n",
      "Component 5 info saved in 'info_5.txt'\n",
      "Component 6 info saved in 'info_6.txt'\n",
      "Component 7 info saved in 'info_7.txt'\n",
      "Component 8 info saved in 'info_8.txt'\n",
      "Component 9 info saved in 'info_9.txt'\n",
      "Component 10 info saved in 'info_10.txt'\n",
      "Component 11 info saved in 'info_11.txt'\n",
      "Component 12 info saved in 'info_12.txt'\n",
      "Component 13 info saved in 'info_13.txt'\n",
      "Component 14 info saved in 'info_14.txt'\n",
      "Component 15 info saved in 'info_15.txt'\n",
      "Component 16 info saved in 'info_16.txt'\n",
      "Component 17 info saved in 'info_17.txt'\n",
      "Component 18 info saved in 'info_18.txt'\n",
      "Component 19 info saved in 'info_19.txt'\n",
      "Component 20 info saved in 'info_20.txt'\n",
      "Component 21 info saved in 'info_21.txt'\n",
      "Component 22 info saved in 'info_22.txt'\n",
      "Component 23 info saved in 'info_23.txt'\n",
      "Component 24 info saved in 'info_24.txt'\n",
      "Component 25 info saved in 'info_25.txt'\n",
      "Component 26 info saved in 'info_26.txt'\n",
      "Aggregated information for all components saved in '1_Preprocessed_Data/Stand_Components/unconnected_to_bigroads/info.txt'\n"
     ]
    }
   ],
   "source": [
    "# Workflow\n",
    "\n",
    "# List to store all the graph data (vertices, edges, attributes)\n",
    "list_graphdata = []\n",
    "# list to store the graphs\n",
    "list_graphs =[]\n",
    "\n",
    "# Path to store the aggregated info file\n",
    "base_info_file = f'{base_folder}/info.txt'\n",
    "\n",
    "# Open the aggregated info file to write component data\n",
    "with open(base_info_file, 'w') as base_info:\n",
    "    base_info.write(\"Aggregated Information for All Components\\n\")\n",
    "    base_info.write(\"-------------------------------------------------\\n\")\n",
    "\n",
    "    # run workflow for each component\n",
    "    for k, df in enumerate(components):\n",
    "        component_folder = f\"{base_folder}/comp_{k+1}\"\n",
    "        os.makedirs(component_folder, exist_ok=True)\n",
    "\n",
    "        # Step 1: Extract edges (with duplicates allowed)\n",
    "        vertices, edges, attributes = extract_boundaries_with_attributes_double_edges(df)\n",
    "\n",
    "        # Step 2: Merge duplicate edges into road segments\n",
    "        #road_segments, attributes = merge_double_edges(edges, attributes)\n",
    "\n",
    "        # Add the extracted data to the list for further processing or visualization\n",
    "        list_graphdata.append([vertices, edges, attributes])\n",
    "\n",
    "        # Store vertices, edges, and attributes\n",
    "        store_graph_data(component_folder, vertices, edges, attributes, k)\n",
    "\n",
    "        # Step 3: Create the graph\n",
    "        G = create_graph(vertices, edges, attributes)\n",
    "        list_graphs.append(G)\n",
    "\n",
    "        # Step 4: Create and save the plot\n",
    "        plot_and_save_graph(G, k)\n",
    "\n",
    "        # Step 5: Create and store plot for only nodes\n",
    "        plot_and_save_nodes(vertices, k)\n",
    "\n",
    "        # Optionally, you can print a summary of the component without printing all the numbers:\n",
    "        print(f\"Component {k + 1} info saved in 'info_{k+1}.txt'\")\n",
    "\n",
    "# Once the loop ends, the base info file contains a summary of all components\n",
    "print(f\"Aggregated information for all components saved in '{base_info_file}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Calculate the costs associated with each road segment\n",
    "\n",
    "There are costs associated with the construction, maintenance and upgrade of roads, depending on the slope. They need to be calculated for each road segment according to their length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Build 5m  Maintain 5m  Build 10m  Maintain 10m  Upgrade\n",
      "≤ 5             2174.000      1073.00   3261.000      1630.500  1073.00\n",
      "5 < slope < 25  4830.756      1878.40   7246.134      3623.067  1878.40\n",
      "≥ 25            7514.500      2683.75  11271.750      5635.875  2683.75\n"
     ]
    }
   ],
   "source": [
    "costs = {\n",
    "    \"≤ 5\": {\n",
    "        \"Build 5m\": 2174,\n",
    "        \"Maintain 5m\": 1073,\n",
    "        \"Build 10m\": 3261,\n",
    "        \"Maintain 10m\": 1630.5,\n",
    "        \"Upgrade\": 1073\n",
    "    },\n",
    "    \"5 < slope < 25\": {\n",
    "        \"Build 5m\": 4830.756,\n",
    "        \"Maintain 5m\": 1878.4,\n",
    "        \"Build 10m\": 7246.134,\n",
    "        \"Maintain 10m\": 3623.067,\n",
    "        \"Upgrade\": 1878.4\n",
    "    },\n",
    "    \"≥ 25\": {\n",
    "        \"Build 5m\": 7514.5,\n",
    "        \"Maintain 5m\": 2683.75,\n",
    "        \"Build 10m\": 11271.75,\n",
    "        \"Maintain 10m\": 5635.875,\n",
    "        \"Upgrade\": 2683.75\n",
    "    }\n",
    "}\n",
    "costs_df = pd.DataFrame(costs).T\n",
    "print(costs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [helper function] assign the costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_all_costs_to_edges(G):\n",
    "    \"\"\"\n",
    "    Assign all cost-related variables (Build5m, Maintain5m, Upgrade, Build10m, Maintain10m) to edges\n",
    "    based on slope, road type, and edge length.\n",
    "    \n",
    "    Parameters:\n",
    "    G (NetworkX graph): The graph representing the road network.\n",
    "    \n",
    "    Returns:\n",
    "    G (NetworkX graph): The graph with updated cost attributes.\n",
    "    \"\"\"\n",
    "    # Iterate over each edge in the graph and set the new attributes\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        if 'edgelength' in data and 'slope' in data:  # Ensure both 'edgelength' and 'slope' exist\n",
    "            # For 5m roads\n",
    "            if data['slope'] <= 5:\n",
    "                data['Build5m'] = data['edgelength'] * costs[\"≤ 5\"]['Build 5m']\n",
    "                data['Maintain5m'] = data['edgelength'] * costs[\"≤ 5\"]['Maintain 5m']\n",
    "                data['Build10m'] = data['edgelength'] * costs[\"≤ 5\"]['Build 10m']\n",
    "                data['Maintain10m'] = data['edgelength'] * costs[\"≤ 5\"]['Maintain 10m']\n",
    "                data['Upgrade'] = data['edgelength'] * costs[\"≤ 5\"]['Upgrade']\n",
    "            elif 5 < data['slope'] < 25:\n",
    "                data['Build5m'] = data['edgelength'] * costs[\"5 < slope < 25\"]['Build 5m']\n",
    "                data['Maintain5m'] = data['edgelength'] * costs[\"5 < slope < 25\"]['Maintain 5m']\n",
    "                data['Build10m'] = data['edgelength'] * costs[\"5 < slope < 25\"]['Build 10m']\n",
    "                data['Maintain10m'] = data['edgelength'] * costs[\"5 < slope < 25\"]['Maintain 10m']\n",
    "                data['Upgrade'] = data['edgelength'] * costs[\"5 < slope < 25\"]['Upgrade']\n",
    "            else:\n",
    "                data['Build5m'] = data['edgelength'] * costs[\"≥ 25\"]['Build 5m']\n",
    "                data['Maintain5m'] = data['edgelength'] * costs[\"≥ 25\"]['Maintain 5m']\n",
    "                data['Build10m'] = data['edgelength'] * costs[\"≥ 25\"]['Build 10m']\n",
    "                data['Maintain10m'] = data['edgelength'] * costs[\"≥ 25\"]['Maintain 10m']\n",
    "                data['Upgrade'] = data['edgelength'] * costs[\"≥ 25\"]['Upgrade']\n",
    "                \n",
    "    #print(f'component {k+1} costs assigned')\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TO DO: verify the correct assignment of costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edgelength</th>\n",
       "      <th>slope</th>\n",
       "      <th>Build5m</th>\n",
       "      <th>Maintain5m</th>\n",
       "      <th>Build10m</th>\n",
       "      <th>Maintain10m</th>\n",
       "      <th>Upgrade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edge</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>((-10208.2222, 145932.3706), (-10235.0624, 145882.3053))</th>\n",
       "      <td>56.806079</td>\n",
       "      <td>31.5762</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>((-10208.2222, 145932.3706), (-10261.6462, 145932.586))</th>\n",
       "      <td>53.424434</td>\n",
       "      <td>31.5762</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    edgelength    slope  \\\n",
       "Edge                                                                      \n",
       "((-10208.2222, 145932.3706), (-10235.0624, 1458...   56.806079  31.5762   \n",
       "((-10208.2222, 145932.3706), (-10261.6462, 1459...   53.424434  31.5762   \n",
       "\n",
       "                                                   Build5m Maintain5m  \\\n",
       "Edge                                                                    \n",
       "((-10208.2222, 145932.3706), (-10235.0624, 1458...    None       None   \n",
       "((-10208.2222, 145932.3706), (-10261.6462, 1459...    None       None   \n",
       "\n",
       "                                                   Build10m Maintain10m  \\\n",
       "Edge                                                                      \n",
       "((-10208.2222, 145932.3706), (-10235.0624, 1458...     None        None   \n",
       "((-10208.2222, 145932.3706), (-10261.6462, 1459...     None        None   \n",
       "\n",
       "                                                   Upgrade  \n",
       "Edge                                                        \n",
       "((-10208.2222, 145932.3706), (-10235.0624, 1458...    None  \n",
       "((-10208.2222, 145932.3706), (-10261.6462, 1459...    None  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the edge attributes\n",
    "# Create a list of dictionaries where each dictionary corresponds to the edge attributes\n",
    "edge_data = []\n",
    "\n",
    "# Iterate over the edges and their attributes in the graph\n",
    "for u, v, data in G.edges(data=True):\n",
    "    edge_data.append({\n",
    "        'Edge': (u, v),\n",
    "        'edgelength': data.get('edgelength'),\n",
    "        'slope': data.get('slope'),\n",
    "        'Build5m': data.get('Build5m'),\n",
    "        'Maintain5m': data.get('Maintain5m'),\n",
    "        'Build10m': data.get('Build10m'),\n",
    "        'Maintain10m': data.get('Maintain10m'),\n",
    "        'Upgrade': data.get('Upgrade')\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "edge_df = pd.DataFrame(edge_data)\n",
    "\n",
    "# Optionally, you can set 'Edge' as the index\n",
    "edge_df.set_index('Edge', inplace=True)\n",
    "\n",
    "edge_df.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [helper function] store edge data with costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_edges_costs(folder_path, edges_costs, k):\n",
    "    # Ensure the folder exists\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    edges_costs_file = os.path.join(folder_path, f'edges_attributes_costs_{k + 1}.csv')\n",
    "    \n",
    "    with open(edges_costs_file, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # Write the header\n",
    "        writer.writerow([\"Node1\", \"Node2\", \"edgelength\", \"slope\", \"Build5m\", \"Maintain5m\", \n",
    "                        \"Build10m\", \"Maintain10m\", \"Upgrade\"])\n",
    "\n",
    "        # Write each edge's data\n",
    "        for node1, node2, attributes in edges_costs:\n",
    "            writer.writerow([node1, node2, \n",
    "                     round(attributes.get('edgelength'),3),\n",
    "                     round(attributes.get('slope'),1), \n",
    "                     round(attributes.get('Build5m', 0), 2), \n",
    "                     round(attributes.get('Maintain5m', 0), 2), \n",
    "                     round(attributes.get('Build10m', 0), 2), \n",
    "                     round(attributes.get('Maintain10m', 0), 2), \n",
    "                     round(attributes.get('Upgrade', 0), 2)])\n",
    "\n",
    "\n",
    "    #print(f\"Edges with costs stored for component {k + 1} in {folder_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Merge short edges to improve performance of optimisation algorithms\n",
    "\n",
    "Note: It would have been possible to merge earlier, but the cost approximization is better this way, because we have more information on the slope if we don't merge the edges before calculation. DO WE??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [helper function] merge short edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_short_edges(G, length_threshold):\n",
    "    while True:\n",
    "        # Track if any merge occurs in this iteration\n",
    "        merged = False\n",
    "\n",
    "        # Iterate over a static list of edges\n",
    "        for u, v, data_uv in list(G.edges(data=True)):\n",
    "            if data_uv.get('edgelength', float('inf')) < length_threshold:\n",
    "                neighbors = list(G.neighbors(v))\n",
    "\n",
    "                # Only proceed if the node has exactly 2 neighbors\n",
    "                if G.degree[v] == 2:\n",
    "                    shortest_length = float('inf')\n",
    "                    shortest_neighbor = None\n",
    "\n",
    "                    # Find the shortest neighbor to merge\n",
    "                    for n in neighbors:\n",
    "                        if n != u and G.degree[n]==2 and G[v][n].get('edgelength', float('inf')) < shortest_length:\n",
    "                            shortest_length = G[v][n]['edgelength']\n",
    "                            shortest_neighbor = n\n",
    "\n",
    "                    # If a shortest neighbor is found, perform the merge\n",
    "                    if shortest_neighbor is not None:\n",
    "                        # Edge data for second edge\n",
    "                        data_vn = G[v][shortest_neighbor]\n",
    "\n",
    "                        # Compute merged properties\n",
    "                        new_length = data_uv['edgelength'] + data_vn['edgelength']\n",
    "                        avg_slope = (\n",
    "                            (data_uv['slope'] * data_uv['edgelength'] + data_vn['slope'] * data_vn['edgelength'])\n",
    "                            / new_length\n",
    "                        )\n",
    "                        new_data = {\n",
    "                            'edgelength': new_length,\n",
    "                            'slope': avg_slope,\n",
    "                            'Build5m': data_uv.get('Build5m', 0) + data_vn.get('Build5m', 0),\n",
    "                            'Maintain5m': data_uv.get('Maintain5m', 0) + data_vn.get('Maintain5m', 0),\n",
    "                            'Build10m': data_uv.get('Build10m', 0) + data_vn.get('Build10m', 0),\n",
    "                            'Maintain10m': data_uv.get('Maintain10m', 0) + data_vn.get('Maintain10m', 0),\n",
    "                            'Upgrade': data_uv.get('Upgrade', 0) + data_vn.get('Upgrade', 0),\n",
    "                        }\n",
    "\n",
    "                        # Add merged edge\n",
    "                        G.add_edge(u, shortest_neighbor, **new_data)\n",
    "\n",
    "                        # Remove old edges only if they exist\n",
    "                        if G.has_edge(u, v):\n",
    "                            G.remove_edge(u, v)\n",
    "                        if G.has_edge(v, shortest_neighbor):\n",
    "                            G.remove_edge(v, shortest_neighbor)\n",
    "\n",
    "                        # Mark as merged and break out to restart\n",
    "                        merged = True\n",
    "                        break\n",
    "\n",
    "            if merged:\n",
    "                break\n",
    "\n",
    "        # If no merges were performed, we're done\n",
    "        if not merged:\n",
    "            break\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [helper function] store edges and costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_edges_costs_merged(folder_path, edges_costs, k):\n",
    "    # Ensure the folder exists\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    edges_costs_file = os.path.join(folder_path, f'edges_attributes_costs_merged_{k + 1}.csv')\n",
    "    \n",
    "    with open(edges_costs_file, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # Write the header\n",
    "        writer.writerow([\"Node1\", \"Node2\", \"edgelength\", \"slope\", \"Build5m\", \"Maintain5m\", \n",
    "                        \"Build10m\", \"Maintain10m\", \"Upgrade\"])\n",
    "\n",
    "        # Write each edge's data\n",
    "        for node1, node2, attributes in edges_costs:\n",
    "            writer.writerow([node1, node2, \n",
    "                     round(attributes.get('edgelength'),3),\n",
    "                     round(attributes.get('slope'),1), \n",
    "                     round(attributes.get('Build5m', 0), 2), \n",
    "                     round(attributes.get('Maintain5m', 0), 2), \n",
    "                     round(attributes.get('Build10m', 0), 2), \n",
    "                     round(attributes.get('Maintain10m', 0), 2), \n",
    "                     round(attributes.get('Upgrade', 0), 2)])\n",
    "\n",
    "\n",
    "    #print(f\"Merged saved for component {k + 1} in {folder_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [helper function] test the result of merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_merge(G_before_merge, G_after_merge):\n",
    "    \"\"\"\n",
    "    Verifies the merge by comparing the total sum of `edgelength` and costs \n",
    "    before and after the merge, and calculates the weighted average slope.\n",
    "\n",
    "    Parameters:\n",
    "        G_before_merge: The graph before merging.\n",
    "        G_after_merge: The graph after merging.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with sums and weighted averages before and after the merge.\n",
    "    \"\"\"\n",
    "    def calculate_totals_and_weighted_slope(G):\n",
    "        total_edgelength = sum(data.get('edgelength', 0) for _, _, data in G.edges(data=True))\n",
    "        total_slope_weighted = sum(\n",
    "            data.get('slope', 0) * data.get('edgelength', 0) for _, _, data in G.edges(data=True)\n",
    "        )\n",
    "        totals = {\n",
    "            'edgelength': total_edgelength,\n",
    "            'weighted_avg_slope': total_slope_weighted / total_edgelength if total_edgelength > 0 else 0,\n",
    "            'Build5m': sum(data.get('Build5m', 0) for _, _, data in G.edges(data=True)),\n",
    "            'Maintain5m': sum(data.get('Maintain5m', 0) for _, _, data in G.edges(data=True)),\n",
    "            'Build10m': sum(data.get('Build10m', 0) for _, _, data in G.edges(data=True)),\n",
    "            'Maintain10m': sum(data.get('Maintain10m', 0) for _, _, data in G.edges(data=True)),\n",
    "            'Upgrade': sum(data.get('Upgrade', 0) for _, _, data in G.edges(data=True))     }\n",
    "        return totals\n",
    "\n",
    "\n",
    "    # Calculate totals and weighted average slopes for both graphs\n",
    "    totals_before_merge = calculate_totals_and_weighted_slope(G_before_merge)\n",
    "    totals_after_merge = calculate_totals_and_weighted_slope(G_after_merge)\n",
    "\n",
    "    # Compare totals\n",
    "    results = {\n",
    "        'before': totals_before_merge,\n",
    "        'after': totals_after_merge,\n",
    "        'difference': {key: round(totals_after_merge[key] - totals_before_merge[key],2) for key in totals_before_merge},\n",
    "        'deleted_edges' : {'removed edges': G_before_merge.number_of_edges() - G_after_merge.number_of_edges()}\n",
    "    }\n",
    "\n",
    "    from collections import Counter\n",
    "    def calculate_node_degrees(G):\n",
    "        return dict(Counter(dict(G.degree()).values()))\n",
    "\n",
    "    # Calculate node degrees for both graphs\n",
    "    node_degrees_before_merge = calculate_node_degrees(G_before_merge)\n",
    "    node_degrees_after_merge = calculate_node_degrees(G_after_merge)\n",
    "\n",
    "    # Include node degrees in the results\n",
    "    results['node_degrees'] = {\n",
    "        'before': node_degrees_before_merge,\n",
    "        'after': node_degrees_after_merge,\n",
    "        'difference': {degree: node_degrees_after_merge.get(degree, 0) - node_degrees_before_merge.get(degree, 0) \n",
    "                        for degree in set(node_degrees_before_merge) | set(node_degrees_after_merge)}\n",
    "    }\n",
    "\n",
    "\n",
    "    # Print results\n",
    "    # print(\"Totals Before Merge:\", results['before'])\n",
    "    # print(\"Totals After Merge:\", results['after'])\n",
    "    # print(\"Differences:\", results['deleted_edges'], results['difference'])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [helper function] Store debugging infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_debug_infos(base_info, folder_path, k):\n",
    "    # Debugging Infos\n",
    "        total_vertices = len(vertices)\n",
    "        total_edges = len(edges)\n",
    "        unique_road_segments = len(road_segments)\n",
    "        merged_edges = total_edges - unique_road_segments\n",
    "\n",
    "        # Write info for the component to its individual text file\n",
    "        info_file_path = os.path.join(folder_path, f'info_{k+1}.txt')\n",
    "        with open(info_file_path, 'w') as info_file:\n",
    "            info_file.write(f\"Component {k+1} Information\\n\")\n",
    "            info_file.write(f\"----------------------------\\n\")\n",
    "            info_file.write(f\"Number of vertices: {total_vertices}\\n\")\n",
    "            info_file.write(f\"Total original edges: {total_edges}\\n\")\n",
    "            info_file.write(f\"Unique road segments after removing duplicate (shared) edges: {unique_road_segments}\\n\")\n",
    "            info_file.write(f\"Number of removed edges: {merged_edges}\\n\")\n",
    "            info_file.write(f\"Number of edge attributes: {len(attributes)}\\n\")\n",
    "            info_file.write(f\"Number of deleted edges due to merging of short ones: {results['deleted_edges']}\\n\")\n",
    "            info_file.write(f\"Totals Before Merge: {results['before']}\\n\")\n",
    "            info_file.write(f\"Totals After Merge: {results['after']}\\n\")\n",
    "            info_file.write(f\"Differences: {results['difference']}\\n\")\n",
    "            info_file.write(f\"Number of nodes per degree: {results['node_degrees']}\\n\")\n",
    "            info_file.write(f\"----------------------------\\n\")\n",
    "\n",
    "        # Write the aggregated summary to the base info file\n",
    "        base_info.write(f\"\\nComponent {k+1} Information\\n\")\n",
    "        base_info.write(f\"----------------------------\\n\")\n",
    "        base_info.write(f\"Number of vertices: {total_vertices}\\n\")\n",
    "        base_info.write(f\"Total original edges: {total_edges}\\n\")\n",
    "        base_info.write(f\"Unique road segments after removing duplicate (shared) edges: {unique_road_segments}\\n\")\n",
    "        base_info.write(f\"Number of removed edges: {merged_edges}\\n\")\n",
    "        base_info.write(f\"Number of edge attributes: {len(attributes)}\\n\")\n",
    "        base_info.write(f\"Number of deleted edges due to merging of short ones: {results['deleted_edges']}\\n\")\n",
    "        base_info.write(f\"Totals Before Merge: {results['before']}\\n\")\n",
    "        base_info.write(f\"Totals After Merge: {results['after']}\\n\")\n",
    "        base_info.write(f\"Differences: {results['difference']}\\n\")\n",
    "        base_info.write(f\"Number of nodes per degree: {results['node_degrees']}\\n\")\n",
    "        base_info.write(f\"----------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated information for all components saved in 1_Preprocessed_Data/Stand_Components/unconnected_to_bigroads/info.txt\n"
     ]
    }
   ],
   "source": [
    "# Workflow\n",
    "\n",
    "# List to store all the graph data (vertices, edges, attributes)\n",
    "#list_graphdata = []\n",
    "# list to store the graphs\n",
    "#list_graphs =[]\n",
    "\n",
    "# Path to store the aggregated info file\n",
    "base_info_file = f'{base_folder}/info.txt'\n",
    "\n",
    "# Open the aggregated info file to write component data\n",
    "with open(base_info_file, 'w') as base_info:\n",
    "    base_info.write(\"Aggregated Information for All Components\\n\")\n",
    "    base_info.write(\"-------------------------------------------------\\n\")\n",
    "\n",
    "    # run workflow for each component\n",
    "    for k, df in enumerate(components):\n",
    "        \n",
    "        # path to store data for each component\n",
    "        component_folder = f\"{base_folder}/comp_{k+1}\"\n",
    "        os.makedirs(component_folder, exist_ok=True)\n",
    "\n",
    "        # Step 1: Extract edges (with duplicates allowed)\n",
    "        vertices, edges, attributes = extract_boundaries_with_attributes_double_edges(df)\n",
    "\n",
    "        # Step 2: Merge duplicate edges into road segments\n",
    "        road_segments, attributes = merge_double_edges(edges, attributes)\n",
    "\n",
    "        # Add the extracted data to the list for further processing or visualization\n",
    "        #list_graphdata.append([vertices, edges, attributes])\n",
    "\n",
    "        # Store vertices, edges, and attributes\n",
    "        store_graph_data(component_folder, vertices, edges, attributes, k)\n",
    "\n",
    "        # Step 3: Create the graph\n",
    "        G = create_graph(vertices, edges, attributes)\n",
    "        #list_graphs.append(G)\n",
    "\n",
    "        ### VISUALIZATION\n",
    "\n",
    "        # Step 4: Create and save the plot\n",
    "        plot_and_save_graph(G, k)\n",
    "\n",
    "        # Step 5: Create and store plot for only nodes\n",
    "        plot_and_save_nodes(vertices, k)\n",
    "\n",
    "        #### ASSIGNING COSTS TO EDGES\n",
    "\n",
    "        # Step 6. Assign the costs\n",
    "        G = assign_all_costs_to_edges(G)\n",
    "        #list_graphs[k] = G\n",
    "\n",
    "        # Step 7. store the data with costs\n",
    "        edges_costs = list(G.edges(data=True))\n",
    "        store_edges_costs(component_folder, edges_costs, k)\n",
    "\n",
    "        #### MERGE SHORT EDGES TOGETHER\n",
    "\n",
    "        G_before_merge = G.copy()\n",
    "        \n",
    "        # Merge short edges with length < threshold\n",
    "        G = merge_short_edges(G, length_threshold=49)\n",
    "        \n",
    "        # store the data with costs\n",
    "        edges_costs = list(G.edges(data=True))\n",
    "        store_edges_costs_merged(component_folder, edges_costs, k)\n",
    "\n",
    "        # Verify the merge\n",
    "        results = verify_merge(G_before_merge, G)\n",
    "\n",
    "        write_debug_infos(base_info, component_folder, k)\n",
    "\n",
    "    # Once the loop ends, the base info file contains a summary of all components\n",
    "    print(f\"Aggregated information for all components saved in {base_info_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
